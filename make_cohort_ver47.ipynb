{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAIN] Loading cohort: cohort\\cohort_ver46_with_cci.csv\n",
      "[MAIN] Cohort rows: 1930\n",
      "[MAIN] 'icu_stay_id' 컬럼을 'stay_id'로 사용합니다.\n",
      "[HFRS] Loading diagnoses_icd...\n",
      "[HFRS] diagnoses_icd rows: 6364488\n",
      "[HFRS] diagnoses_icd rows (in cohort): 27892\n",
      "[HFRS] Loading HFRS ICD map: D:\\University\\3-2\\1Data_Analytics\\team\\DA_git\\DA_STEMI\\ref\\HFRS_code.csv\n",
      "[HFRS] Map rows: 109\n",
      "[HFRS] Mapped HFRS rows: 2745\n",
      "[HFRS] Example rows:\n",
      "    hadm_id  hfrs_score hfrs_category\n",
      "0  20082514         1.2           lt5\n",
      "1  20090653         4.1           lt5\n",
      "2  20090705         6.4          5_15\n",
      "3  20102387         2.2           lt5\n",
      "4  20121113         2.5           lt5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 366\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[MAIN] Saved:\u001b[39m\u001b[38;5;124m\"\u001b[39m, OUTPUT_PATH)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 366\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 305\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    303\u001b[0m sofa_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     sofa_scores \u001b[38;5;241m=\u001b[39m \u001b[43mload_sofa_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSOFA_SCORES_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m     sofa_scores \u001b[38;5;241m=\u001b[39m add_sofa_subscores(sofa_scores)\n\u001b[0;32m    307\u001b[0m     sofa_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 214\u001b[0m, in \u001b[0;36mload_sofa_scores\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_sofa_scores\u001b[39m(path: Path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    SOFA 점수 파일 로드 및 컬럼 정리.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m      - sofa_resp, sofa_coag, sofa_liver, sofa_cardio, sofa_cns, sofa_renal\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SOFA] Loading SOFA scores: \u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    215\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path)\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# 컬럼 이름 보정 예시\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# ============================================\n",
    "# 0. 경로 설정\n",
    "# ============================================\n",
    "BASE_DIR = Path(\".\")\n",
    "\n",
    "# 입력 코호트 (CCI까지 포함된 버전)\n",
    "COHORT_PATH = BASE_DIR / \"cohort\" / \"cohort_ver46_with_cci.csv\"\n",
    "\n",
    "# MIMIC-IV diagnoses_icd\n",
    "DIAGNOSES_PATH = (\n",
    "    BASE_DIR\n",
    "    / \"..\"\n",
    "    / \"..\"\n",
    "    / \"data\"\n",
    "    / \"MIMIC4-hosp-icu\"\n",
    "    / \"diagnoses_icd.csv\"\n",
    ")\n",
    "\n",
    "# HFRS ICD 매핑 파일 (HFRS_code.csv 사용)\n",
    "# ref/HFRS_code.csv 위치에 두기\n",
    "HFRS_MAP_PATH = BASE_DIR / \"ref\" / \"HFRS_code.csv\"\n",
    "\n",
    "# SOFA 점수 파일 (stay_id별 첫 24h/최대 SOFA + 서브스코어)\n",
    "SOFA_SCORES_PATH = (\n",
    "    BASE_DIR\n",
    "    / \"..\"\n",
    "    / \"..\"\n",
    "    / \"data\"\n",
    "    / \"MIMIC4-derived\"\n",
    "    / \"sofa_icu_scores.csv\"\n",
    ")\n",
    "\n",
    "# 출력 코호트\n",
    "OUTPUT_PATH = BASE_DIR / \"cohort\" / \"cohort_ver47_with_cci_hfrs_sofa.csv\"\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 1. 공통 유틸: ICD 코드 정규화\n",
    "# ============================================\n",
    "def normalize_icd(code: str) -> str:\n",
    "    \"\"\"\n",
    "    ICD 코드에서 공백 제거, 대문자 변환, '.' 제거.\n",
    "    접두(prefix) 매칭용 정규화 함수.\n",
    "    \"\"\"\n",
    "    if pd.isna(code):\n",
    "        return \"\"\n",
    "    s = str(code).strip().upper().replace(\".\", \"\")\n",
    "    return s\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. HFRS 계산 관련 함수\n",
    "# ============================================\n",
    "def load_hfrs_map(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    HFRS_code.csv 형식의 HFRS ICD 매핑 파일 로드 및 정규화.\n",
    "    기대 컬럼:\n",
    "      - icd_code\n",
    "      - points\n",
    "\n",
    "    내부적으로:\n",
    "      - icd_code_prefix (→ icd_code)\n",
    "      - weight (→ points)\n",
    "      - icd_version (모두 10으로 설정)\n",
    "    \"\"\"\n",
    "    print(f\"[HFRS] Loading HFRS ICD map: {path.resolve()}\")\n",
    "\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"HFRS ICD map not found at: {path.resolve()}\")\n",
    "\n",
    "    hfrs_map = pd.read_csv(path)\n",
    "\n",
    "    # 컬럼 이름을 기존 로직에 맞게 변환\n",
    "    if \"icd_code\" not in hfrs_map.columns or \"points\" not in hfrs_map.columns:\n",
    "        raise ValueError(\"HFRS_code.csv에는 'icd_code', 'points' 컬럼이 필요합니다.\")\n",
    "\n",
    "    hfrs_map = hfrs_map.rename(\n",
    "        columns={\n",
    "            \"icd_code\": \"icd_code_prefix\",\n",
    "            \"points\": \"weight\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # HFRS는 ICD-10 기반으로 간주\n",
    "    hfrs_map[\"icd_version\"] = 10\n",
    "\n",
    "    # 정규화된 prefix\n",
    "    hfrs_map[\"icd_code_prefix_norm\"] = (\n",
    "        hfrs_map[\"icd_code_prefix\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()\n",
    "        .str.replace(\".\", \"\", regex=False)\n",
    "    )\n",
    "\n",
    "    print(\"[HFRS] Map rows:\", len(hfrs_map))\n",
    "    return hfrs_map\n",
    "\n",
    "\n",
    "def map_icd_to_hfrs(dx_df: pd.DataFrame, hfrs_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    diagnoses_icd 서브셋에 대해 HFRS 매핑을 적용해\n",
    "    hadm_id - icd_code_norm - weight 테이블을 생성.\n",
    "\n",
    "    dx_df: columns - hadm_id, icd_version, icd_code_norm\n",
    "    hfrs_map: columns - icd_version, icd_code_prefix_norm, weight\n",
    "    \"\"\"\n",
    "    dx_work = dx_df[[\"hadm_id\", \"icd_version\", \"icd_code_norm\"]].copy()\n",
    "    results = []\n",
    "\n",
    "    # prefix 길이 (길이가 긴 prefix부터 시도)\n",
    "    for plen in [5, 4, 3]:\n",
    "        tmp = dx_work.copy()\n",
    "        tmp[\"prefix\"] = tmp[\"icd_code_norm\"].str[:plen]\n",
    "\n",
    "        map_sub = hfrs_map.copy()\n",
    "        map_sub[\"prefix\"] = map_sub[\"icd_code_prefix_norm\"].str[:plen]\n",
    "\n",
    "        merged = tmp.merge(\n",
    "            map_sub[[\"icd_version\", \"prefix\", \"weight\"]],\n",
    "            on=[\"icd_version\", \"prefix\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "\n",
    "        # 동일 hadm_id / 코드에 대한 중복 제거\n",
    "        merged = merged[[\"hadm_id\", \"icd_code_norm\", \"weight\"]].drop_duplicates()\n",
    "        results.append(merged)\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame(columns=[\"hadm_id\", \"icd_code_norm\", \"weight\"])\n",
    "\n",
    "    mapped = pd.concat(results, ignore_index=True).drop_duplicates()\n",
    "    return mapped\n",
    "\n",
    "\n",
    "def compute_hfrs_for_cohort(cohort: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    코호트(hadm_id 기준)에 대해 HFRS 점수와 카테고리를 계산해\n",
    "    hadm_id - hfrs_score - hfrs_category 테이블을 반환.\n",
    "    \"\"\"\n",
    "    print(\"[HFRS] Loading diagnoses_icd...\")\n",
    "    dx = pd.read_csv(DIAGNOSES_PATH)\n",
    "    print(\"[HFRS] diagnoses_icd rows:\", len(dx))\n",
    "\n",
    "    hadm_ids = cohort[\"hadm_id\"].unique()\n",
    "    dx_sub = dx[dx[\"hadm_id\"].isin(hadm_ids)].copy()\n",
    "    print(\"[HFRS] diagnoses_icd rows (in cohort):\", len(dx_sub))\n",
    "\n",
    "    # ICD 정규화\n",
    "    dx_sub[\"icd_code_norm\"] = dx_sub[\"icd_code\"].apply(normalize_icd)\n",
    "\n",
    "    # HFRS 매핑 로드\n",
    "    hfrs_map = load_hfrs_map(HFRS_MAP_PATH)\n",
    "\n",
    "    # ICD → HFRS weight 매핑\n",
    "    dx_hfrs = map_icd_to_hfrs(dx_sub, hfrs_map)\n",
    "    print(\"[HFRS] Mapped HFRS rows:\", len(dx_hfrs))\n",
    "\n",
    "    if dx_hfrs.empty:\n",
    "        # 매핑이 하나도 안 된 경우\n",
    "        hfrs_table = pd.DataFrame({\"hadm_id\": hadm_ids})\n",
    "        hfrs_table[\"hfrs_score\"] = 0.0\n",
    "    else:\n",
    "        # hadm_id별 HFRS 점수 = 해당 admission ICD들의 weight 합\n",
    "        hfrs_table = (\n",
    "            dx_hfrs.groupby(\"hadm_id\", as_index=False)[\"weight\"]\n",
    "            .sum()\n",
    "            .rename(columns={\"weight\": \"hfrs_score\"})\n",
    "        )\n",
    "\n",
    "    # 카테고리화: <5 / 5–15 / >15\n",
    "    def categorize_hfrs(score: float) -> str:\n",
    "        \"\"\"\n",
    "        Hospital Frailty Risk Score 카테고리:\n",
    "          - score < 5       → \"lt5\"\n",
    "          - 5 <= score <=15 → \"5_15\"\n",
    "          - score > 15      → \"gt15\"\n",
    "        \"\"\"\n",
    "        if pd.isna(score):\n",
    "            return \"lt5\"\n",
    "        s = float(score)\n",
    "        if s < 5:\n",
    "            return \"lt5\"\n",
    "        elif 5 <= s <= 15:\n",
    "            return \"5_15\"\n",
    "        else:\n",
    "            return \"gt15\"\n",
    "\n",
    "    hfrs_table[\"hfrs_category\"] = hfrs_table[\"hfrs_score\"].apply(categorize_hfrs)\n",
    "\n",
    "    print(\"[HFRS] Example rows:\")\n",
    "    print(hfrs_table.head())\n",
    "\n",
    "    return hfrs_table\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. SOFA 점수 병합 (첫 24시간, 최대, 서브스코어)\n",
    "# ============================================\n",
    "def load_sofa_scores(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    SOFA 점수 파일 로드 및 컬럼 정리.\n",
    "\n",
    "    기대 컬럼:\n",
    "      - stay_id\n",
    "      - sofa_icu_adm_score (ICU 입실 후 첫 24h SOFA 총점)\n",
    "      - sofa_icu_max_score (ICU 체류 중 최대 SOFA 총점)\n",
    "      - sofa_resp, sofa_coag, sofa_liver, sofa_cardio, sofa_cns, sofa_renal\n",
    "    \"\"\"\n",
    "    print(f\"[SOFA] Loading SOFA scores: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # 컬럼 이름 보정 예시\n",
    "    if \"sofa_icu_adm_score\" not in df.columns and \"sofa_24hours\" in df.columns:\n",
    "        df = df.rename(columns={\"sofa_24hours\": \"sofa_icu_adm_score\"})\n",
    "    if \"sofa_icu_max_score\" not in df.columns and \"sofa_max\" in df.columns:\n",
    "        df = df.rename(columns={\"sofa_max\": \"sofa_icu_max_score\"})\n",
    "\n",
    "    required_cols = [\n",
    "        \"stay_id\",\n",
    "        \"sofa_icu_adm_score\",\n",
    "        \"sofa_icu_max_score\",\n",
    "        \"sofa_resp\",\n",
    "        \"sofa_coag\",\n",
    "        \"sofa_liver\",\n",
    "        \"sofa_cardio\",\n",
    "        \"sofa_cns\",\n",
    "        \"sofa_renal\",\n",
    "    ]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"SOFA 파일에 필요한 컬럼이 없습니다: {missing}\")\n",
    "\n",
    "    # stay_id 중복이 있다면 최대값 기준으로 집계\n",
    "    agg_dict = {\n",
    "        \"sofa_icu_adm_score\": \"max\",\n",
    "        \"sofa_icu_max_score\": \"max\",\n",
    "        \"sofa_resp\": \"max\",\n",
    "        \"sofa_coag\": \"max\",\n",
    "        \"sofa_liver\": \"max\",\n",
    "        \"sofa_cardio\": \"max\",\n",
    "        \"sofa_cns\": \"max\",\n",
    "        \"sofa_renal\": \"max\",\n",
    "    }\n",
    "    df_agg = df.groupby(\"stay_id\", as_index=False).agg(agg_dict)\n",
    "\n",
    "    print(\"[SOFA] Aggregated rows:\", len(df_agg))\n",
    "    print(df_agg.head())\n",
    "    return df_agg\n",
    "\n",
    "\n",
    "def add_sofa_subscores(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    서브스코어 6개(호흡/혈액/간/심혈관/신경/신장)를\n",
    "    하나의 JSON 문자열 컬럼 'sofa_subscores'로 묶는다.\n",
    "    \"\"\"\n",
    "    organ_cols = [\n",
    "        \"sofa_resp\",\n",
    "        \"sofa_coag\",\n",
    "        \"sofa_liver\",\n",
    "        \"sofa_cardio\",\n",
    "        \"sofa_cns\",\n",
    "        \"sofa_renal\",\n",
    "    ]\n",
    "\n",
    "    def make_json(row):\n",
    "        data = {k: row[k] for k in organ_cols}\n",
    "        return json.dumps(data)\n",
    "\n",
    "    df[\"sofa_subscores\"] = df.apply(make_json, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. 메인 파이프라인\n",
    "# ============================================\n",
    "def main():\n",
    "    # 4-1. 코호트 로드\n",
    "    print(\"[MAIN] Loading cohort:\", COHORT_PATH)\n",
    "    cohort = pd.read_csv(COHORT_PATH)\n",
    "    print(\"[MAIN] Cohort rows:\", len(cohort))\n",
    "\n",
    "    if \"hadm_id\" not in cohort.columns:\n",
    "        raise ValueError(\"코호트에 'hadm_id' 컬럼이 없습니다.\")\n",
    "\n",
    "    # 4-2. ICU stay id 정리: icu_stay_id → stay_id\n",
    "    if \"stay_id\" in cohort.columns:\n",
    "        print(\"[MAIN] Cohort already has 'stay_id' 컬럼을 사용합니다.\")\n",
    "    elif \"icu_stay_id\" in cohort.columns:\n",
    "        print(\"[MAIN] 'icu_stay_id' 컬럼을 'stay_id'로 사용합니다.\")\n",
    "        cohort[\"stay_id\"] = cohort[\"icu_stay_id\"]\n",
    "    else:\n",
    "        raise ValueError(\"코호트에 'stay_id' 또는 'icu_stay_id' 컬럼이 없습니다. SOFA 병합 불가.\")\n",
    "\n",
    "    # 4-3. HFRS 계산 (hadm_id 기준)\n",
    "    hfrs_table = compute_hfrs_for_cohort(cohort)\n",
    "\n",
    "    # 4-4. SOFA 점수 로드 및 서브스코어 JSON 생성 (파일이 없으면 스킵)\n",
    "    sofa_scores = None\n",
    "    try:\n",
    "        sofa_scores = load_sofa_scores(SOFA_SCORES_PATH)\n",
    "        sofa_scores = add_sofa_subscores(sofa_scores)\n",
    "        sofa_available = True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[SOFA] SOFA 파일을 찾을 수 없습니다: {SOFA_SCORES_PATH.resolve()}\")\n",
    "        print(\"[SOFA] SOFA 병합을 건너뛰고, 관련 컬럼은 NaN으로 채웁니다.\")\n",
    "        sofa_available = False\n",
    "\n",
    "    # 4-5. 코호트에 HFRS merge (hadm_id 기준)\n",
    "    cohort = cohort.merge(\n",
    "        hfrs_table[[\"hadm_id\", \"hfrs_score\", \"hfrs_category\"]],\n",
    "        on=\"hadm_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # hfrs_score 결측 → 0.0, hfrs_category 결측 → \"lt5\"\n",
    "    cohort[\"hfrs_score\"] = cohort[\"hfrs_score\"].fillna(0.0)\n",
    "    cohort[\"hfrs_category\"] = cohort[\"hfrs_category\"].fillna(\"lt5\")\n",
    "\n",
    "    # 4-6. 코호트에 SOFA merge (stay_id 기준) – 파일 있을 때만\n",
    "    if sofa_available:\n",
    "        cohort = cohort.merge(\n",
    "            sofa_scores[\n",
    "                [\n",
    "                    \"stay_id\",\n",
    "                    \"sofa_icu_adm_score\",\n",
    "                    \"sofa_icu_max_score\",\n",
    "                    \"sofa_subscores\",\n",
    "                ]\n",
    "            ],\n",
    "            on=\"stay_id\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "    else:\n",
    "        # 컬럼만 만들어 두기\n",
    "        cohort[\"sofa_icu_adm_score\"] = pd.NA\n",
    "        cohort[\"sofa_icu_max_score\"] = pd.NA\n",
    "        cohort[\"sofa_subscores\"] = pd.NA\n",
    "\n",
    "    print(\"[MAIN] Final cohort shape:\", cohort.shape)\n",
    "    print(\n",
    "        cohort[\n",
    "            [\n",
    "                \"hadm_id\",\n",
    "                \"hfrs_score\",\n",
    "                \"hfrs_category\",\n",
    "                \"stay_id\",\n",
    "                \"sofa_icu_adm_score\",\n",
    "                \"sofa_icu_max_score\",\n",
    "                \"sofa_subscores\",\n",
    "            ]\n",
    "        ].head()\n",
    "    )\n",
    "\n",
    "    # 4-7. 저장\n",
    "    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cohort.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8\")\n",
    "    print(\"[MAIN] Saved:\", OUTPUT_PATH)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5/xo6jnr2yE8KVCd3yAf3",
   "mount_file_id": "1f51IyTSTgI7CXc93F407An-tCAsao0N3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
