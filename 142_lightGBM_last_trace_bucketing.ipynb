{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15670f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAIN] PPM 데이터가 이미 존재합니다: ./cohort\\cohort_ver142_ppm_prefix_next_event.csv\n",
      "[LOAD] 음수 time 제거: 24991 -> 24991 rows\n",
      "[LOAD] PPM 데이터 로딩 완료: 24991 rows, 1869 hadm_id\n",
      "[LOAD] next_event_id 고유 개수: 13\n",
      "\n",
      "=== time_to_next_min 분포 (raw) ===\n",
      "count    2.499100e+04\n",
      "mean     2.014538e+03\n",
      "std      1.161987e+05\n",
      "min      0.000000e+00\n",
      "50%      8.100000e+01\n",
      "90%      1.440000e+03\n",
      "99%      8.736903e+03\n",
      "99.9%    4.778485e+04\n",
      "max      1.448079e+07\n",
      "Name: time_to_next_min, dtype: float64\n",
      "\n",
      "=== time_since_start_min 분포 (raw) ===\n",
      "count    2.499100e+04\n",
      "mean     2.040683e+04\n",
      "std      5.081532e+05\n",
      "min      0.000000e+00\n",
      "50%      6.110000e+02\n",
      "90%      5.558000e+03\n",
      "99%      2.929445e+04\n",
      "99.9%    1.086022e+07\n",
      "max      1.633377e+07\n",
      "Name: time_since_start_min, dtype: float64\n",
      "\n",
      "[TRIM] 극단값 제거 기준:\n",
      "  - time_to_next_min <= 43200 분 (~30일)\n",
      "  - time_since_start_min <= 43200 분 (~30일)\n",
      "[TRIM] 극단값 제거: 24991 -> 24832 rows (제거: 159)\n",
      "\n",
      "=== time_to_next_min 분포 (trimmed) ===\n",
      "count    24832.000000\n",
      "mean       573.512138\n",
      "std       1676.927713\n",
      "min          0.000000\n",
      "50%         80.000000\n",
      "90%       1418.000000\n",
      "99%       8051.800000\n",
      "99.9%    18991.526400\n",
      "max      41997.000000\n",
      "Name: time_to_next_min, dtype: float64\n",
      "\n",
      "=== time_since_start_min 분포 (trimmed) ===\n",
      "count    24832.000000\n",
      "mean      2020.633524\n",
      "std       4164.794255\n",
      "min          0.000000\n",
      "50%        604.000000\n",
      "90%       5309.000000\n",
      "99%      21981.657167\n",
      "99.9%    38034.704000\n",
      "max      42786.000000\n",
      "Name: time_since_start_min, dtype: float64\n",
      "[SPLIT] train hadm_id: 1306, rows: 17389\n",
      "[SPLIT] val   hadm_id: 280, rows: 3733\n",
      "[SPLIT] test  hadm_id: 280, rows: 3710\n",
      "\n",
      "[BUCKET] current_event 기준 버킷 개수: 11\n",
      "[BUCKET] 버킷 목록: ['ANTI_PLT_ADMIN', 'ANTI_PLT_ORDER', 'ECG_STEMI_FLAG', 'ECG_TAKEN', 'ED_ARRIVAL', 'ED_DEPARTURE', 'ICU_INTIME', 'ICU_OUTTIME', 'PCI_START', 'TROP_POSITIVE', 'TROP_TAKEN']\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ANTI_PLT_ADMIN'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 1903, val rows: 406, test rows: 362\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [1 2]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 2\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 0.415234\ttrain's multi_error: 0.202312\tval's multi_logloss: 0.451048\tval's multi_error: 0.187192\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's multi_logloss: 0.509631\ttrain's multi_error: 0.21072\tval's multi_logloss: 0.477226\tval's multi_error: 0.184729\n",
      "[TRAIN] 최적 반복 수: 1\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ANTI_PLT_ADMIN.txt\n",
      "[TRAIN][REG] 경고: 회귀 타깃 값이 모두 동일합니다. 회귀 모델을 학습할 수 없습니다. 스킵합니다.\n",
      "\n",
      "[EVAL] 버킷 'ANTI_PLT_ADMIN' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.7983425414364641\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 1.0\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        73\n",
      "           1     0.7983    1.0000    0.8879       289\n",
      "\n",
      "    accuracy                         0.7983       362\n",
      "   macro avg     0.3992    0.5000    0.4439       362\n",
      "weighted avg     0.6374    0.7983    0.7088       362\n",
      "\n",
      "[EVAL][REG] 모델이 없습니다. 스킵합니다.\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ANTI_PLT_ORDER'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 1902, val rows: 406, test rows: 362\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [ 1  2  3  4  5  6  8  9 10 11 12 13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 12\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 1.28237\ttrain's multi_error: 0.444795\tval's multi_logloss: 1.81021\tval's multi_error: 0.669951\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttrain's multi_logloss: 1.67043\ttrain's multi_error: 0.554154\tval's multi_logloss: 1.86384\tval's multi_error: 0.667488\n",
      "[TRAIN] 최적 반복 수: 14\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ANTI_PLT_ORDER.txt\n",
      "\n",
      "[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l2: 2.97783e+06\ttrain's l1: 783.46\tval's l2: 1.89916e+06\tval's l1: 774.896\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttrain's l2: 3.28132e+06\ttrain's l1: 836.73\tval's l2: 1.87144e+06\tval's l1: 790.706\n",
      "[TRAIN] 최적 반복 수: 21\n",
      "[SAVE] 회귀 모델 저장: ./cohort\\lgbm_ver142_time_to_next_bucket_ANTI_PLT_ORDER.txt\n",
      "\n",
      "[EVAL] 버킷 'ANTI_PLT_ORDER' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.3259668508287293\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 0.7154696132596685\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2000    0.0714    0.1053        28\n",
      "           1     0.2782    0.5068    0.3592        73\n",
      "           2     0.0000    0.0000    0.0000         3\n",
      "           3     0.5932    0.8750    0.7071        40\n",
      "           4     0.0000    0.0000    0.0000        16\n",
      "           5     0.3049    0.2809    0.2924        89\n",
      "           6     0.0000    0.0000    0.0000         2\n",
      "           7     0.0000    0.0000    0.0000         7\n",
      "           8     0.0000    0.0000    0.0000        22\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "          10     0.5556    0.2273    0.3226        22\n",
      "          11     0.2090    0.2373    0.2222        59\n",
      "\n",
      "    accuracy                         0.3260       362\n",
      "   macro avg     0.1784    0.1832    0.1674       362\n",
      "weighted avg     0.2799    0.3260    0.2864       362\n",
      "\n",
      "\n",
      "[EVAL][REG] Test MAE (min) : 861.9107530529021\n",
      "[EVAL][REG] Test RMSE (min): 1721.832975088339\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ECG_STEMI_FLAG'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 1463, val rows: 322, test rows: 336\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [5 6]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 2\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 0.00593057\ttrain's multi_error: 0.00136705\tval's multi_logloss: 0.00114017\tval's multi_error: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's multi_logloss: 0.010382\ttrain's multi_error: 0.00136705\tval's multi_logloss: 0.00136799\tval's multi_error: 0\n",
      "[TRAIN] 최적 반복 수: 1\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ECG_STEMI_FLAG.txt\n",
      "[TRAIN][REG] 경고: 회귀 타깃 값이 모두 동일합니다. 회귀 모델을 학습할 수 없습니다. 스킵합니다.\n",
      "\n",
      "[EVAL] 버킷 'ECG_STEMI_FLAG' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 1.0\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 1.0\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     1.0000    1.0000    1.0000       336\n",
      "\n",
      "    accuracy                         1.0000       336\n",
      "   macro avg     1.0000    1.0000    1.0000       336\n",
      "weighted avg     1.0000    1.0000    1.0000       336\n",
      "\n",
      "[EVAL][REG] 모델이 없습니다. 스킵합니다.\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ECG_TAKEN'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 5071, val rows: 1028, test rows: 1107\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [ 1  3  4  5  6  7  8  9 10 11 12 13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 12\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 1.08237\ttrain's multi_error: 0.401499\tval's multi_logloss: 1.4609\tval's multi_error: 0.559339\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttrain's multi_logloss: 1.22189\ttrain's multi_error: 0.438178\tval's multi_logloss: 1.49889\tval's multi_error: 0.554475\n",
      "[TRAIN] 최적 반복 수: 30\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ECG_TAKEN.txt\n",
      "\n",
      "[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l2: 2.59309e+06\ttrain's l1: 642.195\tval's l2: 2.01877e+06\tval's l1: 655.434\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttrain's l2: 2.62786e+06\ttrain's l1: 647.92\tval's l2: 2.00857e+06\tval's l1: 655.958\n",
      "[TRAIN] 최적 반복 수: 44\n",
      "[SAVE] 회귀 모델 저장: ./cohort\\lgbm_ver142_time_to_next_bucket_ECG_TAKEN.txt\n",
      "\n",
      "[EVAL] 버킷 'ECG_TAKEN' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.4968383017163505\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 0.8482384823848238\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2727    0.1059    0.1525        85\n",
      "           1     0.0000    0.0000    0.0000         9\n",
      "           2     0.7155    0.9326    0.8098        89\n",
      "           3     0.3810    0.0889    0.1441        90\n",
      "           4     0.3956    0.5552    0.4620       290\n",
      "           5     0.0000    0.0000    0.0000         1\n",
      "           6     0.6178    0.7886    0.6929       246\n",
      "           7     0.5000    0.0714    0.1250        14\n",
      "           8     0.0000    0.0000    0.0000        58\n",
      "           9     0.0000    0.0000    0.0000         3\n",
      "          10     0.5319    0.4167    0.4673        60\n",
      "          11     0.4157    0.4259    0.4207       162\n",
      "\n",
      "    accuracy                         0.4968      1107\n",
      "   macro avg     0.3192    0.2821    0.2729      1107\n",
      "weighted avg     0.4463    0.4968    0.4520      1107\n",
      "\n",
      "\n",
      "[EVAL][REG] Test MAE (min) : 625.8953729732506\n",
      "[EVAL][REG] Test RMSE (min): 1419.6395040741315\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ED_ARRIVAL'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 1307, val rows: 282, test rows: 280\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [ 1  3  4  5  6  7  8 11 12 13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 10\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 0.932121\ttrain's multi_error: 0.41469\tval's multi_logloss: 0.906494\tval's multi_error: 0.393617\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttrain's multi_logloss: 0.963154\ttrain's multi_error: 0.417751\tval's multi_logloss: 0.919619\tval's multi_error: 0.390071\n",
      "[TRAIN] 최적 반복 수: 14\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ED_ARRIVAL.txt\n",
      "\n",
      "[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l2: 30119.9\ttrain's l1: 72.6632\tval's l2: 38184.9\tval's l1: 64.732\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttrain's l2: 30312.6\ttrain's l1: 73.2208\tval's l2: 38324.2\tval's l1: 64.1526\n",
      "[TRAIN] 최적 반복 수: 26\n",
      "[SAVE] 회귀 모델 저장: ./cohort\\lgbm_ver142_time_to_next_bucket_ED_ARRIVAL.txt\n",
      "\n",
      "[EVAL] 버킷 'ED_ARRIVAL' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.6035714285714285\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 0.9928571428571429\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         1\n",
      "           3     0.6343    0.7351    0.6810       151\n",
      "           4     0.5524    0.5370    0.5446       108\n",
      "           6     0.0000    0.0000    0.0000        19\n",
      "           9     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.6036       280\n",
      "   macro avg     0.2373    0.2544    0.2451       280\n",
      "weighted avg     0.5551    0.6036    0.5773       280\n",
      "\n",
      "\n",
      "[EVAL][REG] Test MAE (min) : 68.4862959184813\n",
      "[EVAL][REG] Test RMSE (min): 115.76513574136402\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ED_DEPARTURE'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 1278, val rows: 275, test rows: 273\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [ 1  3  4  5  6  9 11 12 13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 9\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 0.998552\ttrain's multi_error: 0.350548\tval's multi_logloss: 1.33519\tval's multi_error: 0.48\n",
      "[100]\ttrain's multi_logloss: 0.765901\ttrain's multi_error: 0.247261\tval's multi_logloss: 1.38013\tval's multi_error: 0.469091\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttrain's multi_logloss: 0.998552\ttrain's multi_error: 0.350548\tval's multi_logloss: 1.33519\tval's multi_error: 0.48\n",
      "[TRAIN] 최적 반복 수: 50\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ED_DEPARTURE.txt\n",
      "\n",
      "[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l2: 2.80847e+06\ttrain's l1: 651.249\tval's l2: 1.79404e+06\tval's l1: 677.112\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's l2: 3.15753e+06\ttrain's l1: 730.616\tval's l2: 1.64935e+06\tval's l1: 691.629\n",
      "[TRAIN] 최적 반복 수: 23\n",
      "[SAVE] 회귀 모델 저장: ./cohort\\lgbm_ver142_time_to_next_bucket_ED_DEPARTURE.txt\n",
      "\n",
      "[EVAL] 버킷 'ED_DEPARTURE' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.5567765567765568\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 0.8388278388278388\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2963    0.2353    0.2623        34\n",
      "           2     0.9474    1.0000    0.9730        36\n",
      "           3     0.0000    0.0000    0.0000        13\n",
      "           4     0.2727    0.0833    0.1277        36\n",
      "           5     0.5495    0.9174    0.6873       109\n",
      "           7     0.0000    0.0000    0.0000        23\n",
      "           8     0.6250    0.2273    0.3333        22\n",
      "\n",
      "    accuracy                         0.5568       273\n",
      "   macro avg     0.3844    0.3519    0.3405       273\n",
      "weighted avg     0.4675    0.5568    0.4791       273\n",
      "\n",
      "\n",
      "[EVAL][REG] Test MAE (min) : 736.0797332966954\n",
      "[EVAL][REG] Test RMSE (min): 1516.862130473202\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ICU_INTIME'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 660, val rows: 128, test rows: 150\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [ 1  3  4  5  6 10 11 12 13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 9\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 1.1515\ttrain's multi_error: 0.443939\tval's multi_logloss: 1.51001\tval's multi_error: 0.601562\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttrain's multi_logloss: 1.15781\ttrain's multi_error: 0.44697\tval's multi_logloss: 1.51173\tval's multi_error: 0.601562\n",
      "[TRAIN] 최적 반복 수: 49\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ICU_INTIME.txt\n",
      "\n",
      "[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l2: 1.51641e+06\ttrain's l1: 450.9\tval's l2: 243112\tval's l1: 315.259\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttrain's l2: 1.55686e+06\ttrain's l1: 463.089\tval's l2: 239664\tval's l1: 319.314\n",
      "[TRAIN] 최적 반복 수: 32\n",
      "[SAVE] 회귀 모델 저장: ./cohort\\lgbm_ver142_time_to_next_bucket_ICU_INTIME.txt\n",
      "\n",
      "[EVAL] 버킷 'ICU_INTIME' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.35333333333333333\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 0.7466666666666667\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        16\n",
      "           1     0.0000    0.0000    0.0000         2\n",
      "           2     0.0000    0.0000    0.0000         1\n",
      "           3     0.0000    0.0000    0.0000        11\n",
      "           4     0.3810    0.5714    0.4571        56\n",
      "           5     0.4615    0.5000    0.4800        12\n",
      "           7     0.3421    0.3824    0.3611        34\n",
      "           8     0.2500    0.1111    0.1538        18\n",
      "\n",
      "    accuracy                         0.3533       150\n",
      "   macro avg     0.1793    0.1956    0.1815       150\n",
      "weighted avg     0.2867    0.3533    0.3094       150\n",
      "\n",
      "\n",
      "[EVAL][REG] Test MAE (min) : 514.9268361946541\n",
      "[EVAL][REG] Test RMSE (min): 1308.4565241135163\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'ICU_OUTTIME'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 532, val rows: 109, test rows: 119\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [ 1  3  4  5  6  9 11 12 13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 9\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 0.9048\ttrain's multi_error: 0.327068\tval's multi_logloss: 1.05091\tval's multi_error: 0.385321\n",
      "[100]\ttrain's multi_logloss: 0.691787\ttrain's multi_error: 0.238722\tval's multi_logloss: 1.01858\tval's multi_error: 0.330275\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttrain's multi_logloss: 0.76286\ttrain's multi_error: 0.272556\tval's multi_logloss: 1.02269\tval's multi_error: 0.330275\n",
      "[TRAIN] 최적 반복 수: 80\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_ICU_OUTTIME.txt\n",
      "\n",
      "[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l2: 7.68635e+06\ttrain's l1: 1737.8\tval's l2: 4.41117e+06\tval's l1: 1555\n",
      "[100]\ttrain's l2: 7.08566e+06\ttrain's l1: 1671.99\tval's l2: 4.46003e+06\tval's l1: 1533.22\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttrain's l2: 7.64205e+06\ttrain's l1: 1732.46\tval's l2: 4.39777e+06\tval's l1: 1550.16\n",
      "[TRAIN] 최적 반복 수: 53\n",
      "[SAVE] 회귀 모델 저장: ./cohort\\lgbm_ver142_time_to_next_bucket_ICU_OUTTIME.txt\n",
      "\n",
      "[EVAL] 버킷 'ICU_OUTTIME' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.48739495798319327\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 0.7394957983193278\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         9\n",
      "           1     0.0000    0.0000    0.0000         1\n",
      "           2     0.7500    0.8667    0.8041        45\n",
      "           3     0.0000    0.0000    0.0000        12\n",
      "           4     0.3654    0.5938    0.4524        32\n",
      "           5     0.0000    0.0000    0.0000         8\n",
      "           8     0.0000    0.0000    0.0000        12\n",
      "\n",
      "    accuracy                         0.4874       119\n",
      "   macro avg     0.1593    0.2086    0.1795       119\n",
      "weighted avg     0.3819    0.4874    0.4257       119\n",
      "\n",
      "\n",
      "[EVAL][REG] Test MAE (min) : 2739.186028170271\n",
      "[EVAL][REG] Test RMSE (min): 5094.906588464653\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'PCI_START'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 59, val rows: 12, test rows: 7\n",
      "[BUCKET] row 수가 부족하여 스킵합니다. (MIN_TRAIN_ROWS_PER_BUCKET=100)\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'TROP_POSITIVE'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 654, val rows: 146, test rows: 140\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 1\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "[TRAIN][CLASS] 경고: 클래스 수가 1개라 분류 모델을 학습할 수 없습니다. 스킵합니다.\n",
      "[TRAIN][REG] 경고: 회귀 타깃 값이 모두 동일합니다. 회귀 모델을 학습할 수 없습니다. 스킵합니다.\n",
      "\n",
      "[EVAL] 버킷 'TROP_POSITIVE' 평가 결과\n",
      "[EVAL][CLASS] 모델이 없습니다. 스킵합니다.\n",
      "[EVAL][REG] 모델이 없습니다. 스킵합니다.\n",
      "\n",
      "================================================================================\n",
      "[BUCKET] 현재 버킷: 'TROP_TAKEN'\n",
      "================================================================================\n",
      "[BUCKET] train rows: 2560, val rows: 619, test rows: 574\n",
      "[FEATURE] 사용 feature 컬럼: ['prefix_len', 'time_since_start_min', 'full_trace_len', 'current_event_id', 'prefix_events_str']\n",
      "[FEATURE] 분류 target 원래 클래스: [ 1  3  4  5  6  7  8  9 10 11 12 13]\n",
      "[FEATURE] 분류 target 재매핑 클래스 수: 12\n",
      "[FEATURE] 회귀 target 클리핑 상한 (min): 43200\n",
      "\n",
      "[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's multi_logloss: 1.15643\ttrain's multi_error: 0.431641\tval's multi_logloss: 1.50145\tval's multi_error: 0.610662\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttrain's multi_logloss: 1.16175\ttrain's multi_error: 0.435156\tval's multi_logloss: 1.49949\tval's multi_error: 0.610662\n",
      "[TRAIN] 최적 반복 수: 49\n",
      "[SAVE] 분류 모델 저장: ./cohort\\lgbm_ver142_next_event_bucket_TROP_TAKEN.txt\n",
      "\n",
      "[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's l2: 1.68856e+06\ttrain's l1: 593.653\tval's l2: 2.31379e+06\tval's l1: 684.252\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttrain's l2: 1.75005e+06\ttrain's l1: 601.388\tval's l2: 2.3117e+06\tval's l1: 682.294\n",
      "[TRAIN] 최적 반복 수: 37\n",
      "[SAVE] 회귀 모델 저장: ./cohort\\lgbm_ver142_time_to_next_bucket_TROP_TAKEN.txt\n",
      "\n",
      "[EVAL] 버킷 'TROP_TAKEN' 평가 결과\n",
      "\n",
      "[EVAL][CLASS] Test Top-1 Accuracy : 0.3780487804878049\n",
      "[EVAL][CLASS] Test Top-3 Accuracy : 0.8292682926829268\n",
      "\n",
      "[EVAL][CLASS] Classification Report (Top-1 기준):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3421    0.3362    0.3391       116\n",
      "           1     0.0000    0.0000    0.0000         8\n",
      "           2     0.8095    0.7727    0.7907        44\n",
      "           3     1.0000    0.0250    0.0488        40\n",
      "           4     0.3381    0.5975    0.4318       159\n",
      "           6     0.4000    0.3333    0.3636         6\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.0000    0.0000    0.0000        28\n",
      "           9     0.0000    0.0000    0.0000         3\n",
      "          10     0.0000    0.0000    0.0000         1\n",
      "          11     0.3594    0.2930    0.3228       157\n",
      "\n",
      "    accuracy                         0.3780       574\n",
      "   macro avg     0.2954    0.2143    0.2088       574\n",
      "weighted avg     0.3970    0.3780    0.3443       574\n",
      "\n",
      "\n",
      "[EVAL][REG] Test MAE (min) : 651.9049561099382\n",
      "[EVAL][REG] Test RMSE (min): 1819.610582734821\n",
      "\n",
      "[INFO] Last-State Bucketing 기반 LightGBM PPM 베이스라인 학습 및 평가 완료.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ==============================\n",
    "# 0. 경로 및 기본 설정\n",
    "# ==============================\n",
    "\n",
    "# 140 이벤트 로그 (새로운 full event log)\n",
    "INPUT_EVENT_LOG_PATH = \"./cohort/cohort_ver140_event_log.csv\"\n",
    "\n",
    "# 142 결과물 저장\n",
    "OUTPUT_DIR = \"./cohort\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CLEAN_EVENT_LOG_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver142_event_log_clean.csv\")\n",
    "EVENT_ID_MAP_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver142_event_id_map.csv\")\n",
    "PPM_DATA_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver142_ppm_prefix_next_event.csv\")\n",
    "\n",
    "# LightGBM 모델 파일 포맷 (버킷별로 저장)\n",
    "MODEL_NEXT_EVENT_FMT = os.path.join(OUTPUT_DIR, \"lgbm_ver142_next_event_bucket_{bucket}.txt\")\n",
    "MODEL_TIME_TO_NEXT_FMT = os.path.join(OUTPUT_DIR, \"lgbm_ver142_time_to_next_bucket_{bucket}.txt\")\n",
    "\n",
    "# 공통 설정\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.15   # 전체 hadm_id 중 15% test\n",
    "VAL_SIZE = 0.15    # 전체 hadm_id 중 15% validation (나머지 70% train)\n",
    "\n",
    "# trace 필터링 기준\n",
    "MIN_EVENTS_PER_CASE = 2\n",
    "MAX_EPISODE_DAYS = 365          # 한 입원(hadm) 동안 365일 이상이면 이상치로 제거\n",
    "\n",
    "# 회귀 타깃에서 허용할 최대 gap (분) - 클리핑용\n",
    "# ex) 30일 = 30 * 24 * 60\n",
    "MAX_TIME_TO_NEXT_MIN = 30 * 24 * 60\n",
    "\n",
    "# 분석/학습용 극단값 제거 기준 (트리밍용)\n",
    "# time_to_next_min, time_since_start_min 모두 30일 이내만 사용\n",
    "MAX_TIME_TO_NEXT_TRIM_MIN = 30 * 24 * 60       # 30일\n",
    "MAX_TIME_SINCE_START_TRIM_MIN = 30 * 24 * 60   # 30일\n",
    "\n",
    "# 버킷 학습 최소 row 수 (너무 작은 버킷은 건너뜀)\n",
    "MIN_TRAIN_ROWS_PER_BUCKET = 100\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 1. 공통 유틸\n",
    "# ==============================\n",
    "\n",
    "def _to_datetime(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _sanitize_bucket_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    파일 이름에 쓸 수 있도록 bucket 문자열을 정리.\n",
    "    알파벳/숫자 이외는 '_'로 치환.\n",
    "    \"\"\"\n",
    "    s = str(name)\n",
    "    return re.sub(r\"[^0-9A-Za-z]+\", \"_\", s)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. 이벤트 로그 로딩\n",
    "# ==============================\n",
    "\n",
    "def load_event_log(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Event Log CSV 로딩.\n",
    "    필수 컬럼:\n",
    "      - case_id\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - event_name\n",
    "      - timestamp\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"입력 이벤트 로그 파일을 찾을 수 없습니다: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    required_cols = [\"case_id\", \"subject_id\", \"hadm_id\", \"event_name\", \"timestamp\"]\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"입력 이벤트 로그에 '{c}' 컬럼이 없습니다. 현재 컬럼: {list(df.columns)}\")\n",
    "\n",
    "    df = _to_datetime(df, \"timestamp\")\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[\"timestamp\"])\n",
    "    print(f\"[LOAD] timestamp NaT 제거: {before} -> {len(df)} rows\")\n",
    "\n",
    "    # 전역 정렬\n",
    "    df = df.sort_values(by=[\"hadm_id\", \"timestamp\", \"event_name\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"[LOAD] Event Log 로딩 완료: {len(df)} rows, {df['hadm_id'].nunique()} hadm_id\")\n",
    "    print(f\"[LOAD] event_name 분포:\\n{df['event_name'].value_counts()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. 1차 시간 sanity 체크\n",
    "#    - episode 길이만 필터 (연도 이상치는 허용)\n",
    "# ==============================\n",
    "\n",
    "def sanity_filter_time(raw_events: pd.DataFrame,\n",
    "                       max_episode_days: int = MAX_EPISODE_DAYS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1차 시간 sanity 체크:\n",
    "      - hadm_id별 timestamp span이 max_episode_days를 초과하면 제거\n",
    "      - 연도 이상치는 허용 (연도 범위 필터는 적용하지 않음)\n",
    "    \"\"\"\n",
    "    df = raw_events.copy()\n",
    "\n",
    "    # hadm_id별 episode 길이 계산\n",
    "    span = df.groupby(\"hadm_id\")[\"timestamp\"].agg([\"min\", \"max\"])\n",
    "    span[\"duration_days\"] = (span[\"max\"] - span[\"min\"]).dt.total_seconds() / 86400.0\n",
    "\n",
    "    long_span = span[span[\"duration_days\"] > max_episode_days]\n",
    "    good_hadm = span[span[\"duration_days\"] <= max_episode_days].index\n",
    "\n",
    "    print(f\"[TIME] episode 길이 통계 (일 단위):\")\n",
    "    print(span[\"duration_days\"].describe())\n",
    "\n",
    "    if len(long_span) > 0:\n",
    "        print(f\"[TIME] episode 길이>{max_episode_days}일 hadm_id 수: {len(long_span)}\")\n",
    "    else:\n",
    "        print(f\"[TIME] episode 길이>{max_episode_days}일 hadm_id 없음\")\n",
    "\n",
    "    df = df[df[\"hadm_id\"].isin(good_hadm)].copy()\n",
    "    df = df.sort_values(by=[\"hadm_id\", \"timestamp\", \"event_name\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"[TIME] 시간 sanity 필터 후 rows: {len(df)}, hadm_id: {df['hadm_id'].nunique()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. Event Log 클린업\n",
    "#    - 시작 기준: ED_ARRIVAL > ED_ARRIVAL_SURR > 첫 이벤트\n",
    "#    - DISCHARGE/DEATH 이후 제거\n",
    "#    - 너무 짧은 trace 제거\n",
    "# ==============================\n",
    "\n",
    "def clean_event_log(raw_events: pd.DataFrame,\n",
    "                    min_events_per_case: int = MIN_EVENTS_PER_CASE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    hadm_id 단위로 다음 규칙 적용:\n",
    "\n",
    "      1) 시작 기준 이벤트:\n",
    "         - 우선순위 1: ED_ARRIVAL\n",
    "         - 우선순위 2: ED_ARRIVAL_SURR\n",
    "         - 둘 다 없으면: 해당 hadm의 첫 timestamp\n",
    "\n",
    "      2) DISCHARGE/DEATH 이후 이벤트 제거\n",
    "         - 둘 다 있으면 더 이른 시점을 기준으로 자름\n",
    "\n",
    "      3) 남은 이벤트 수가 min_events_per_case 미만이면 제거\n",
    "    \"\"\"\n",
    "    keep_groups = []\n",
    "    dropped_too_short = 0\n",
    "\n",
    "    # 통계용 카운트\n",
    "    cnt_start_ed       = 0  # ED_ARRIVAL 기준 시작\n",
    "    cnt_start_ed_surr  = 0  # ED_ARRIVAL_SURR 기준 시작\n",
    "    cnt_start_first    = 0  # 첫 이벤트 기준 시작\n",
    "\n",
    "    for hadm_id, g in raw_events.groupby(\"hadm_id\"):\n",
    "        g = g.sort_values([\"timestamp\", \"event_name\"]).copy()\n",
    "        subject_id = g[\"subject_id\"].iloc[0]\n",
    "        case_id = g[\"case_id\"].iloc[0]\n",
    "\n",
    "        # 1) 시작 시각 결정\n",
    "        is_ed      = (g[\"event_name\"] == \"ED_ARRIVAL\")\n",
    "        is_ed_surr = (g[\"event_name\"] == \"ED_ARRIVAL_SURR\")\n",
    "\n",
    "        if is_ed.any():\n",
    "            start_time = g.loc[is_ed, \"timestamp\"].min()\n",
    "            cnt_start_ed += 1\n",
    "        elif is_ed_surr.any():\n",
    "            start_time = g.loc[is_ed_surr, \"timestamp\"].min()\n",
    "            cnt_start_ed_surr += 1\n",
    "        else:\n",
    "            start_time = g[\"timestamp\"].min()\n",
    "            cnt_start_first += 1\n",
    "\n",
    "        g = g[g[\"timestamp\"] >= start_time].copy()\n",
    "\n",
    "        # 2) DISCHARGE/DEATH 이후 제거\n",
    "        is_end = g[\"event_name\"].isin([\"DISCHARGE\", \"DEATH\"])\n",
    "        if is_end.any():\n",
    "            end_time = g.loc[is_end, \"timestamp\"].min()\n",
    "            g = g[g[\"timestamp\"] <= end_time].copy()\n",
    "\n",
    "        # 3) 최소 이벤트 개수 체크\n",
    "        if len(g) < min_events_per_case:\n",
    "            dropped_too_short += 1\n",
    "            continue\n",
    "\n",
    "        g[\"subject_id\"] = subject_id\n",
    "        g[\"case_id\"] = case_id\n",
    "        keep_groups.append(g)\n",
    "\n",
    "    if not keep_groups:\n",
    "        print(\"[CLEAN] 남아 있는 trace가 없습니다.\")\n",
    "        print(f\"[CLEAN] 원본 hadm_id 수: {raw_events['hadm_id'].nunique()}\")\n",
    "        print(f\"[CLEAN] 이벤트 수<{min_events_per_case}로 제거된 hadm_id 수: {dropped_too_short}\")\n",
    "        return pd.DataFrame(columns=raw_events.columns)\n",
    "\n",
    "    clean_df = pd.concat(keep_groups, ignore_index=True)\n",
    "    clean_df = clean_df.sort_values(\n",
    "        by=[\"hadm_id\", \"timestamp\", \"event_name\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\n[CLEAN] === 요약 ===\")\n",
    "    print(f\"원본 hadm_id 수: {raw_events['hadm_id'].nunique()}\")\n",
    "    print(f\"최종 남은 hadm_id 수: {clean_df['hadm_id'].nunique()}\")\n",
    "    print(f\"최종 이벤트 row 수: {len(clean_df)}\")\n",
    "    print(f\"이벤트 수<{min_events_per_case}로 제거된 hadm_id 수: {dropped_too_short}\")\n",
    "    print(\"\\n[CLEAN] 시작 기준 통계 (hadm 단위):\")\n",
    "    print(f\"  ED_ARRIVAL 기준 시작 hadm 수       : {cnt_start_ed}\")\n",
    "    print(f\"  ED_ARRIVAL_SURR 기준 시작 hadm 수  : {cnt_start_ed_surr}\")\n",
    "    print(f\"  첫 이벤트 기준 시작 hadm 수        : {cnt_start_first}\")\n",
    "\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. event_name ↔ event_id 매핑\n",
    "# ==============================\n",
    "\n",
    "def build_event_id_map(events: pd.DataFrame) -> pd.DataFrame:\n",
    "    unique_events = sorted(events[\"event_name\"].unique())\n",
    "    event_id_map = pd.DataFrame({\n",
    "        \"event_name\": unique_events,\n",
    "        \"event_id\": range(1, len(unique_events) + 1)\n",
    "    })\n",
    "    print(f\"[MAP] 이벤트 종류 개수: {len(unique_events)}\")\n",
    "    return event_id_map\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. PPM prefix–next_event 데이터셋 생성\n",
    "# ==============================\n",
    "\n",
    "def build_ppm_prefix_dataset(clean_events: pd.DataFrame,\n",
    "                             event_id_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PPM용 prefix–next_event 데이터셋 생성.\n",
    "\n",
    "    출력 컬럼:\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - case_id\n",
    "      - prefix_len\n",
    "      - prefix_events_str\n",
    "      - current_event\n",
    "      - current_event_id\n",
    "      - next_event\n",
    "      - next_event_id\n",
    "      - time_since_start_min\n",
    "      - time_to_next_min\n",
    "      - full_trace_len\n",
    "\n",
    "    last-state bucketing을 위해 current_event를 나중에 bucket 키로 사용.\n",
    "    \"\"\"\n",
    "    name_to_id = dict(zip(event_id_map[\"event_name\"], event_id_map[\"event_id\"]))\n",
    "    records = []\n",
    "\n",
    "    for hadm_id, g in clean_events.groupby(\"hadm_id\"):\n",
    "        g = g.sort_values([\"timestamp\", \"event_name\"]).copy()\n",
    "        subject_id = g[\"subject_id\"].iloc[0]\n",
    "        case_id = g[\"case_id\"].iloc[0] if \"case_id\" in g.columns else hadm_id\n",
    "\n",
    "        events = list(g[\"event_name\"])\n",
    "        times = list(g[\"timestamp\"])\n",
    "        full_trace_len = len(events)\n",
    "\n",
    "        if full_trace_len < 2:\n",
    "            continue\n",
    "\n",
    "        first_time = times[0]\n",
    "\n",
    "        for i in range(full_trace_len - 1):\n",
    "            prefix_seq = events[: i + 1]\n",
    "            prefix_len = len(prefix_seq)\n",
    "            current_event = events[i]\n",
    "            next_event = events[i + 1]\n",
    "\n",
    "            prefix_end_time = times[i]\n",
    "            next_time = times[i + 1]\n",
    "\n",
    "            time_since_start_min = (prefix_end_time - first_time).total_seconds() / 60.0\n",
    "            time_to_next_min = (next_time - prefix_end_time).total_seconds() / 60.0\n",
    "\n",
    "            # 음수/NaN 방어\n",
    "            if time_since_start_min < 0 or time_to_next_min < 0:\n",
    "                continue\n",
    "\n",
    "            prefix_str = \">\".join(prefix_seq)\n",
    "\n",
    "            rec = {\n",
    "                \"subject_id\": subject_id,\n",
    "                \"hadm_id\": hadm_id,\n",
    "                \"case_id\": case_id,\n",
    "                \"prefix_len\": prefix_len,\n",
    "                \"prefix_events_str\": prefix_str,\n",
    "                \"current_event\": current_event,\n",
    "                \"current_event_id\": name_to_id.get(current_event, -1),\n",
    "                \"next_event\": next_event,\n",
    "                \"next_event_id\": name_to_id.get(next_event, -1),\n",
    "                \"time_since_start_min\": time_since_start_min,\n",
    "                \"time_to_next_min\": time_to_next_min,\n",
    "                \"full_trace_len\": full_trace_len,\n",
    "            }\n",
    "            records.append(rec)\n",
    "\n",
    "    ppm_df = pd.DataFrame(records)\n",
    "    print(f\"[PPM] prefix–next_event row 수: {len(ppm_df)}\")\n",
    "    print(f\"[PPM] hadm_id 수: {ppm_df['hadm_id'].nunique() if not ppm_df.empty else 0}\")\n",
    "\n",
    "    if len(ppm_df) > 0:\n",
    "        print(\"\\n[PPM] time_to_next_min 분포 (raw):\")\n",
    "        print(ppm_df[\"time_to_next_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n",
    "        print(\"\\n[PPM] time_since_start_min 분포 (raw):\")\n",
    "        print(ppm_df[\"time_since_start_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n",
    "\n",
    "    return ppm_df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 7. ver142 cohort 구축 main\n",
    "# ==============================\n",
    "\n",
    "def build_ver142_cohort():\n",
    "    # 1) 140 event log 로딩\n",
    "    raw_events = load_event_log(INPUT_EVENT_LOG_PATH)\n",
    "\n",
    "    # 2) 1차 시간 sanity 필터 (episode 길이 기준)\n",
    "    time_filtered = sanity_filter_time(raw_events)\n",
    "\n",
    "    # 3) Clean: ED/ED_SURR 기준 시작, DISCHARGE/DEATH까지, 너무 짧은 trace 제거\n",
    "    clean_events = clean_event_log(time_filtered, min_events_per_case=MIN_EVENTS_PER_CASE)\n",
    "\n",
    "    if clean_events.empty:\n",
    "        print(\"[MAIN] clean_events가 비어 있습니다. 이전 단계 이벤트 생성 로직을 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 4) 클린 이벤트 로그 저장 (ver142)\n",
    "    clean_events.to_csv(CLEAN_EVENT_LOG_PATH, index=False)\n",
    "    print(f\"[SAVE] 클린 이벤트 로그 저장: {CLEAN_EVENT_LOG_PATH}\")\n",
    "\n",
    "    # 5) event_name ↔ event_id 매핑 생성 및 저장\n",
    "    event_id_map = build_event_id_map(clean_events)\n",
    "    event_id_map.to_csv(EVENT_ID_MAP_PATH, index=False)\n",
    "    print(f\"[SAVE] 이벤트 ID 매핑 저장: {EVENT_ID_MAP_PATH}\")\n",
    "\n",
    "    # 6) PPM prefix–next_event 데이터셋 생성 및 저장\n",
    "    ppm_df = build_ppm_prefix_dataset(clean_events, event_id_map)\n",
    "    ppm_df.to_csv(PPM_DATA_PATH, index=False)\n",
    "    print(f\"[SAVE] PPM prefix–next_event 데이터셋 저장: {PPM_DATA_PATH}\")\n",
    "\n",
    "    print(\"\\n[INFO] ver142 cohort 구축 완료.\")\n",
    "    print(f\"  - clean event log : {CLEAN_EVENT_LOG_PATH}\")\n",
    "    print(f\"  - event_id map    : {EVENT_ID_MAP_PATH}\")\n",
    "    print(f\"  - PPM dataset     : {PPM_DATA_PATH}\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 8. PPM 데이터 로딩 (모델용, 극단값 트리밍 포함)\n",
    "# ==============================\n",
    "\n",
    "def load_ppm_dataset(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    required_cols = [\n",
    "        \"subject_id\",\n",
    "        \"hadm_id\",\n",
    "        \"case_id\",\n",
    "        \"prefix_len\",\n",
    "        \"prefix_events_str\",\n",
    "        \"current_event\",\n",
    "        \"current_event_id\",\n",
    "        \"next_event\",\n",
    "        \"next_event_id\",\n",
    "        \"time_since_start_min\",\n",
    "        \"time_to_next_min\",\n",
    "        \"full_trace_len\",\n",
    "    ]\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"PPM 데이터셋에 '{c}' 컬럼이 없습니다. 현재 컬럼: {list(df.columns)}\")\n",
    "\n",
    "    # 1) NaN / 음수 제거\n",
    "    df = df.dropna(subset=[\"next_event_id\", \"time_since_start_min\", \"time_to_next_min\"])\n",
    "\n",
    "    before = len(df)\n",
    "    df = df[(df[\"time_since_start_min\"] >= 0) & (df[\"time_to_next_min\"] >= 0)]\n",
    "    print(f\"[LOAD] 음수 time 제거: {before} -> {len(df)} rows\")\n",
    "\n",
    "    print(f\"[LOAD] PPM 데이터 로딩 완료: {len(df)} rows, {df['hadm_id'].nunique()} hadm_id\")\n",
    "    print(f\"[LOAD] next_event_id 고유 개수: {df['next_event_id'].nunique()}\")\n",
    "\n",
    "    # 2) 극단값 제거 전 분포\n",
    "    print(\"\\n=== time_to_next_min 분포 (raw) ===\")\n",
    "    print(df[\"time_to_next_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n",
    "    print(\"\\n=== time_since_start_min 분포 (raw) ===\")\n",
    "    print(df[\"time_since_start_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n",
    "\n",
    "    # 3) 극단값 제거 (30일 초과 row 제거)\n",
    "    before_trim = len(df)\n",
    "    df = df[\n",
    "        (df[\"time_to_next_min\"] <= MAX_TIME_TO_NEXT_TRIM_MIN) &\n",
    "        (df[\"time_since_start_min\"] <= MAX_TIME_SINCE_START_TRIM_MIN)\n",
    "    ].copy()\n",
    "    after_trim = len(df)\n",
    "\n",
    "    print(f\"\\n[TRIM] 극단값 제거 기준:\")\n",
    "    print(f\"  - time_to_next_min <= {MAX_TIME_TO_NEXT_TRIM_MIN} 분 (~30일)\")\n",
    "    print(f\"  - time_since_start_min <= {MAX_TIME_SINCE_START_TRIM_MIN} 분 (~30일)\")\n",
    "    print(f\"[TRIM] 극단값 제거: {before_trim} -> {after_trim} rows (제거: {before_trim - after_trim})\")\n",
    "\n",
    "    # 4) 극단값 제거 후 분포\n",
    "    if len(df) > 0:\n",
    "        print(\"\\n=== time_to_next_min 분포 (trimmed) ===\")\n",
    "        print(df[\"time_to_next_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n",
    "        print(\"\\n=== time_since_start_min 분포 (trimmed) ===\")\n",
    "        print(df[\"time_since_start_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n",
    "    else:\n",
    "        print(\"[TRIM] 모든 row가 제거되었습니다. 극단값 기준을 다시 조정해야 합니다.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 9. hadm_id 기준 Train / Val / Test Split\n",
    "# ==============================\n",
    "\n",
    "def split_by_hadm(df: pd.DataFrame,\n",
    "                  test_size: float = TEST_SIZE,\n",
    "                  val_size: float = VAL_SIZE,\n",
    "                  random_state: int = RANDOM_STATE):\n",
    "    unique_hadm = df[\"hadm_id\"].drop_duplicates().values\n",
    "\n",
    "    hadm_train_val, hadm_test = train_test_split(\n",
    "        unique_hadm, test_size=test_size, random_state=random_state, shuffle=True\n",
    "    )\n",
    "    val_ratio = val_size / (1.0 - test_size)\n",
    "    hadm_train, hadm_val = train_test_split(\n",
    "        hadm_train_val, test_size=val_ratio, random_state=random_state, shuffle=True\n",
    "    )\n",
    "\n",
    "    def _subset(hadm_ids):\n",
    "        return df[df[\"hadm_id\"].isin(hadm_ids)].copy()\n",
    "\n",
    "    df_train = _subset(hadm_train)\n",
    "    df_val = _subset(hadm_val)\n",
    "    df_test = _subset(hadm_test)\n",
    "\n",
    "    print(f\"[SPLIT] train hadm_id: {len(hadm_train)}, rows: {len(df_train)}\")\n",
    "    print(f\"[SPLIT] val   hadm_id: {len(hadm_val)}, rows: {len(df_val)}\")\n",
    "    print(f\"[SPLIT] test  hadm_id: {len(hadm_test)}, rows: {len(df_test)}\")\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 10. Feature 구성\n",
    "# ==============================\n",
    "\n",
    "def build_feature_matrices(df_train: pd.DataFrame,\n",
    "                           df_val: pd.DataFrame,\n",
    "                           df_test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    LightGBM에 넣을 feature matrix와 label 벡터 생성.\n",
    "    - 분류: next_event_id (버킷 내에서 0-index로 재매핑)\n",
    "    - 회귀: time_to_next_min (상한 클리핑 후 사용)\n",
    "    \"\"\"\n",
    "    # 1) 수치/범주형 feature 정의\n",
    "    num_cols = [\"prefix_len\", \"time_since_start_min\", \"full_trace_len\"]\n",
    "    cat_cols = [\"current_event_id\", \"prefix_events_str\"]\n",
    "\n",
    "    for c in cat_cols:\n",
    "        for df in [df_train, df_val, df_test]:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "    feature_cols = num_cols + cat_cols\n",
    "\n",
    "    X_train = df_train[feature_cols]\n",
    "    X_val = df_val[feature_cols]\n",
    "    X_test = df_test[feature_cols]\n",
    "\n",
    "    # 2) 분류 타깃: 버킷 내에서 0 ~ (num_class-1)로 재매핑\n",
    "    #    예: bucket에 next_event_id {1, 4, 7, 13}만 있다면\n",
    "    #        → {0, 1, 2, 3}으로 다시 매핑\n",
    "    original_classes = np.sort(df_train[\"next_event_id\"].unique())\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(original_classes)}\n",
    "\n",
    "    def _map_labels(s: pd.Series) -> np.ndarray:\n",
    "        return s.map(class_to_idx).astype(int).values\n",
    "\n",
    "    y_train_cls = _map_labels(df_train[\"next_event_id\"])\n",
    "    y_val_cls = _map_labels(df_val[\"next_event_id\"])\n",
    "    y_test_cls = _map_labels(df_test[\"next_event_id\"])\n",
    "\n",
    "    # 3) 회귀 타깃: 지나치게 큰 값은 클리핑\n",
    "    def _clip_time_to_next(arr):\n",
    "        return np.minimum(arr, MAX_TIME_TO_NEXT_MIN)\n",
    "\n",
    "    y_train_reg = _clip_time_to_next(df_train[\"time_to_next_min\"].values)\n",
    "    y_val_reg = _clip_time_to_next(df_val[\"time_to_next_min\"].values)\n",
    "    y_test_reg = _clip_time_to_next(df_test[\"time_to_next_min\"].values)\n",
    "\n",
    "    print(f\"[FEATURE] 사용 feature 컬럼: {feature_cols}\")\n",
    "    print(f\"[FEATURE] 분류 target 원래 클래스: {original_classes}\")\n",
    "    print(f\"[FEATURE] 분류 target 재매핑 클래스 수: {len(original_classes)}\")\n",
    "    print(f\"[FEATURE] 회귀 target 클리핑 상한 (min): {MAX_TIME_TO_NEXT_MIN}\")\n",
    "\n",
    "    return (\n",
    "        X_train, X_val, X_test,\n",
    "        y_train_cls, y_val_cls, y_test_cls,\n",
    "        y_train_reg, y_val_reg, y_test_reg,\n",
    "        num_cols, cat_cols\n",
    "    )\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 11. LightGBM 학습 함수들\n",
    "# ==============================\n",
    "\n",
    "def train_lgbm_classifier(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    num_cols, cat_cols,\n",
    "    model_path: str\n",
    "):\n",
    "    num_class = len(np.unique(y_train))\n",
    "    if num_class < 2:\n",
    "        print(f\"[TRAIN][CLASS] 경고: 클래스 수가 {num_class}개라 분류 모델을 학습할 수 없습니다. 스킵합니다.\")\n",
    "        return None\n",
    "\n",
    "    train_data = lgb.Dataset(\n",
    "        X_train,\n",
    "        label=y_train,\n",
    "        categorical_feature=cat_cols,\n",
    "        free_raw_data=False\n",
    "    )\n",
    "    val_data = lgb.Dataset(\n",
    "        X_val,\n",
    "        label=y_val,\n",
    "        categorical_feature=cat_cols,\n",
    "        free_raw_data=False\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": num_class,\n",
    "        \"metric\": [\"multi_logloss\", \"multi_error\"],\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"max_depth\": -1,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"min_data_in_leaf\": 30,\n",
    "        \"lambda_l2\": 1.0,\n",
    "        \"verbosity\": -1,\n",
    "        \"force_col_wise\": True,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "    print(\"\\n[TRAIN] LightGBM 분류 모델 학습 시작 (next_event_id)...\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"val\"],\n",
    "        num_boost_round=500,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=50),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    best_iter = model.best_iteration\n",
    "    if best_iter is None or best_iter == 0:\n",
    "        if hasattr(model, \"current_iteration\") and model.current_iteration() is not None:\n",
    "            best_iter = model.current_iteration()\n",
    "        else:\n",
    "            best_iter = model.num_trees()\n",
    "\n",
    "    print(f\"[TRAIN] 최적 반복 수: {best_iter}\")\n",
    "    model.save_model(model_path)\n",
    "    print(f\"[SAVE] 분류 모델 저장: {model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lgbm_regressor(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    num_cols, cat_cols,\n",
    "    model_path: str\n",
    "):\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        print(\"[TRAIN][REG] 경고: 회귀 타깃 값이 모두 동일합니다. 회귀 모델을 학습할 수 없습니다. 스킵합니다.\")\n",
    "        return None\n",
    "\n",
    "    train_data = lgb.Dataset(\n",
    "        X_train,\n",
    "        label=y_train,\n",
    "        categorical_feature=cat_cols,\n",
    "        free_raw_data=False\n",
    "    )\n",
    "    val_data = lgb.Dataset(\n",
    "        X_val,\n",
    "        label=y_val,\n",
    "        categorical_feature=cat_cols,\n",
    "        free_raw_data=False\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": [\"l2\", \"l1\"],\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"max_depth\": -1,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"min_data_in_leaf\": 30,\n",
    "        \"lambda_l2\": 1.0,\n",
    "        \"verbosity\": -1,\n",
    "        \"force_col_wise\": True,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "    print(\"\\n[TRAIN] LightGBM 회귀 모델 학습 시작 (time_to_next_min)...\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"val\"],\n",
    "        num_boost_round=500,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=50),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    best_iter = model.best_iteration\n",
    "    if best_iter is None or best_iter == 0:\n",
    "        if hasattr(model, \"current_iteration\") and model.current_iteration() is not None:\n",
    "            best_iter = model.current_iteration()\n",
    "        else:\n",
    "            best_iter = model.num_trees()\n",
    "\n",
    "    print(f\"[TRAIN] 최적 반복 수: {best_iter}\")\n",
    "    model.save_model(model_path)\n",
    "    print(f\"[SAVE] 회귀 모델 저장: {model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 12. 평가 함수\n",
    "# ==============================\n",
    "\n",
    "def _get_best_iter(model: lgb.Booster) -> int:\n",
    "    best_iter = getattr(model, \"best_iteration\", None)\n",
    "    if best_iter is None or best_iter == 0:\n",
    "        if hasattr(model, \"current_iteration\") and model.current_iteration() is not None:\n",
    "            best_iter = model.current_iteration()\n",
    "        else:\n",
    "            best_iter = model.num_trees()\n",
    "    return best_iter\n",
    "\n",
    "\n",
    "def eval_classifier(model, X_test, y_test):\n",
    "    if model is None:\n",
    "        print(\"[EVAL][CLASS] 모델이 없습니다. 스킵합니다.\")\n",
    "        return\n",
    "\n",
    "    num_iter = _get_best_iter(model)\n",
    "    prob = model.predict(X_test, num_iteration=num_iter)\n",
    "\n",
    "    y_pred = np.argmax(prob, axis=1)\n",
    "    acc_top1 = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    top3 = np.argsort(prob, axis=1)[:, -3:]\n",
    "    correct_top3 = np.any(top3 == y_test.reshape(-1, 1), axis=1)\n",
    "    acc_top3 = correct_top3.mean()\n",
    "\n",
    "    print(\"\\n[EVAL][CLASS] Test Top-1 Accuracy :\", acc_top1)\n",
    "    print(\"[EVAL][CLASS] Test Top-3 Accuracy :\", acc_top3)\n",
    "    print(\"\\n[EVAL][CLASS] Classification Report (Top-1 기준):\")\n",
    "    print(classification_report(y_test, y_pred, digits=4, zero_division=0))\n",
    "\n",
    "\n",
    "def eval_regressor(model, X_test, y_test):\n",
    "    if model is None:\n",
    "        print(\"[EVAL][REG] 모델이 없습니다. 스킵합니다.\")\n",
    "        return\n",
    "\n",
    "    num_iter = _get_best_iter(model)\n",
    "    pred = model.predict(X_test, num_iteration=num_iter)\n",
    "    mae = np.mean(np.abs(pred - y_test))\n",
    "    rmse = np.sqrt(np.mean((pred - y_test) ** 2))\n",
    "\n",
    "    print(\"\\n[EVAL][REG] Test MAE (min) :\", mae)\n",
    "    print(\"[EVAL][REG] Test RMSE (min):\", rmse)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 13. 전체 MAIN (Last-State Bucketing)\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    # 1) ver142 cohort 구축 (필요 시 한 번만 실행)\n",
    "    if not os.path.exists(PPM_DATA_PATH):\n",
    "        print(\"[MAIN] ver142 PPM 데이터가 없어 cohort를 먼저 구축합니다.\")\n",
    "        build_ver142_cohort()\n",
    "    else:\n",
    "        print(f\"[MAIN] PPM 데이터가 이미 존재합니다: {PPM_DATA_PATH}\")\n",
    "\n",
    "    # 2) PPM 데이터 로딩 (극단값 제거 포함)\n",
    "    df = load_ppm_dataset(PPM_DATA_PATH)\n",
    "\n",
    "    # 3) hadm_id 기준 Train/Val/Test split (글로벌 기준 1번만 수행)\n",
    "    df_train, df_val, df_test = split_by_hadm(df)\n",
    "\n",
    "    # 4) Last-State Bucketing: current_event 기준으로 버킷 구성\n",
    "    buckets = sorted(df[\"current_event\"].unique())\n",
    "    print(f\"\\n[BUCKET] current_event 기준 버킷 개수: {len(buckets)}\")\n",
    "    print(\"[BUCKET] 버킷 목록:\", buckets)\n",
    "\n",
    "    for bucket in buckets:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[BUCKET] 현재 버킷: '{bucket}'\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # 버킷별 서브셋 (current_event == bucket)\n",
    "        train_b = df_train[df_train[\"current_event\"] == bucket].copy()\n",
    "        val_b   = df_val[df_val[\"current_event\"] == bucket].copy()\n",
    "        test_b  = df_test[df_test[\"current_event\"] == bucket].copy()\n",
    "\n",
    "        print(f\"[BUCKET] train rows: {len(train_b)}, val rows: {len(val_b)}, test rows: {len(test_b)}\")\n",
    "\n",
    "        # 데이터가 너무 적으면 스킵\n",
    "        if len(train_b) < MIN_TRAIN_ROWS_PER_BUCKET or len(val_b) == 0 or len(test_b) == 0:\n",
    "            print(f\"[BUCKET] row 수가 부족하여 스킵합니다. (MIN_TRAIN_ROWS_PER_BUCKET={MIN_TRAIN_ROWS_PER_BUCKET})\")\n",
    "            continue\n",
    "\n",
    "        # 5) Feature / Label 구성 (버킷 서브셋 기준)\n",
    "        (\n",
    "            X_train, X_val, X_test,\n",
    "            y_train_cls, y_val_cls, y_test_cls,\n",
    "            y_train_reg, y_val_reg, y_test_reg,\n",
    "            num_cols, cat_cols\n",
    "        ) = build_feature_matrices(train_b, val_b, test_b)\n",
    "\n",
    "        bucket_safe = _sanitize_bucket_name(bucket)\n",
    "        cls_model_path = MODEL_NEXT_EVENT_FMT.format(bucket=bucket_safe)\n",
    "        reg_model_path = MODEL_TIME_TO_NEXT_FMT.format(bucket=bucket_safe)\n",
    "\n",
    "        # 6) 분류 모델 학습 (next_event_id)\n",
    "        cls_model = train_lgbm_classifier(\n",
    "            X_train, y_train_cls,\n",
    "            X_val, y_val_cls,\n",
    "            num_cols, cat_cols,\n",
    "            cls_model_path\n",
    "        )\n",
    "\n",
    "        # 7) 회귀 모델 학습 (time_to_next_min)\n",
    "        reg_model = train_lgbm_regressor(\n",
    "            X_train, y_train_reg,\n",
    "            X_val, y_val_reg,\n",
    "            num_cols, cat_cols,\n",
    "            reg_model_path\n",
    "        )\n",
    "\n",
    "        # 8) Test 평가\n",
    "        print(f\"\\n[EVAL] 버킷 '{bucket}' 평가 결과\")\n",
    "        eval_classifier(cls_model, X_test, y_test_cls)\n",
    "        eval_regressor(reg_model, X_test, y_test_reg)\n",
    "\n",
    "    print(\"\\n[INFO] Last-State Bucketing 기반 LightGBM PPM 베이스라인 학습 및 평가 완료.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a4768e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] 음수 time 제거: 24991 -> 24991 rows\n",
      "[LOAD] PPM 데이터 로딩 완료: 24991 rows, 1869 hadm_id\n",
      "[LOAD] next_event_id 고유 개수: 13\n",
      "\n",
      "=== time_to_next_min 분포 (raw) ===\n",
      "count    2.499100e+04\n",
      "mean     2.014538e+03\n",
      "std      1.161987e+05\n",
      "min      0.000000e+00\n",
      "50%      8.100000e+01\n",
      "90%      1.440000e+03\n",
      "99%      8.736903e+03\n",
      "99.9%    4.778485e+04\n",
      "max      1.448079e+07\n",
      "Name: time_to_next_min, dtype: float64\n",
      "\n",
      "=== time_since_start_min 분포 (raw) ===\n",
      "count    2.499100e+04\n",
      "mean     2.040683e+04\n",
      "std      5.081532e+05\n",
      "min      0.000000e+00\n",
      "50%      6.110000e+02\n",
      "90%      5.558000e+03\n",
      "99%      2.929445e+04\n",
      "99.9%    1.086022e+07\n",
      "max      1.633377e+07\n",
      "Name: time_since_start_min, dtype: float64\n",
      "\n",
      "[TRIM] 극단값 제거 기준:\n",
      "  - time_to_next_min <= 43200 분 (~30일)\n",
      "  - time_since_start_min <= 43200 분 (~30일)\n",
      "[TRIM] 극단값 제거: 24991 -> 24832 rows (제거: 159)\n",
      "\n",
      "=== time_to_next_min 분포 (trimmed) ===\n",
      "count    24832.000000\n",
      "mean       573.512138\n",
      "std       1676.927713\n",
      "min          0.000000\n",
      "50%         80.000000\n",
      "90%       1418.000000\n",
      "99%       8051.800000\n",
      "99.9%    18991.526400\n",
      "max      41997.000000\n",
      "Name: time_to_next_min, dtype: float64\n",
      "\n",
      "=== time_since_start_min 분포 (trimmed) ===\n",
      "count    24832.000000\n",
      "mean      2020.633524\n",
      "std       4164.794255\n",
      "min          0.000000\n",
      "50%        604.000000\n",
      "90%       5309.000000\n",
      "99%      21981.657167\n",
      "99.9%    38034.704000\n",
      "max      42786.000000\n",
      "Name: time_since_start_min, dtype: float64\n",
      "=== time_to_next_min (trimmed) ===\n",
      "count    24832.000000\n",
      "mean       573.512138\n",
      "std       1676.927713\n",
      "min          0.000000\n",
      "50%         80.000000\n",
      "90%       1418.000000\n",
      "99%       8051.800000\n",
      "99.9%    18991.526400\n",
      "max      41997.000000\n",
      "Name: time_to_next_min, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = load_ppm_dataset(PPM_DATA_PATH)\n",
    "\n",
    "print(\"=== time_to_next_min (trimmed) ===\")\n",
    "print(df[\"time_to_next_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9464605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== time_since_start_min (trimmed) ===\n",
      "count    24832.000000\n",
      "mean      2020.633524\n",
      "std       4164.794255\n",
      "min          0.000000\n",
      "50%        604.000000\n",
      "90%       5309.000000\n",
      "99%      21981.657167\n",
      "99.9%    38034.704000\n",
      "max      42786.000000\n",
      "Name: time_since_start_min, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== time_since_start_min (trimmed) ===\")\n",
    "print(df[\"time_since_start_min\"].describe(percentiles=[0.5, 0.9, 0.99, 0.999]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d4a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
