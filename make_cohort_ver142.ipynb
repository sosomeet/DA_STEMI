{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] Event Log 로딩 완료: 1499 rows, 78 unique hadm_id\n",
      "[CLEAN] 남아 있는 trace가 없습니다.\n",
      "[SAVE] 클린 이벤트 로그 저장: ./cohort\\cohort_ver142_event_log_clean.csv\n",
      "[PPM] 이벤트 종류 개수: 0\n",
      "[SAVE] 이벤트 ID 매핑 저장: ./cohort\\cohort_ver142_event_id_map.csv\n",
      "[PPM] prefix–next_event row 수: 0\n",
      "[SAVE] PPM prefix–next_event 데이터셋 저장: ./cohort\\cohort_ver142_ppm_prefix_next_event.csv\n",
      "\n",
      "[INFO] ver 142 PPM 준비 단계 완료.\n",
      "  - 클린 이벤트 로그: ./cohort\\cohort_ver142_event_log_clean.csv\n",
      "  - 이벤트 ID 매핑:   ./cohort\\cohort_ver142_event_id_map.csv\n",
      "  - PPM 데이터셋:     ./cohort\\cohort_ver142_ppm_prefix_next_event.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# 0. 경로 및 기본 설정\n",
    "# ==============================\n",
    "\n",
    "INPUT_EVENT_LOG_PATH = \"./cohort/cohort_ver141_for_PPM_only_ed_arrived.csv\"\n",
    "OUTPUT_DIR = \"./cohort\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CLEAN_EVENT_LOG_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver142_event_log_clean.csv\")\n",
    "EVENT_ID_MAP_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver142_event_id_map.csv\")\n",
    "PPM_DATA_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver142_ppm_prefix_next_event.csv\")\n",
    "\n",
    "# 너무 짧은 trace 제거 기준 (필요 없으면 1로 낮춰도 됨)\n",
    "MIN_EVENTS_PER_CASE = 2\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 1. 공통 유틸\n",
    "# ==============================\n",
    "\n",
    "def _to_datetime(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. 이벤트 로그 로딩\n",
    "# ==============================\n",
    "\n",
    "def load_event_log(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Event Log CSV 로딩.\n",
    "    필수 컬럼:\n",
    "      - case_id\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - event_name\n",
    "      - timestamp\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"입력 이벤트 로그 파일을 찾을 수 없습니다: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    required_cols = [\"case_id\", \"subject_id\", \"hadm_id\", \"event_name\", \"timestamp\"]\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"입력 이벤트 로그에 '{c}' 컬럼이 없습니다. 현재 컬럼: {list(df.columns)}\")\n",
    "\n",
    "    df = _to_datetime(df, \"timestamp\")\n",
    "    df = df.dropna(subset=[\"timestamp\"])\n",
    "\n",
    "    df = df.sort_values(\n",
    "        by=[\"hadm_id\", \"timestamp\", \"event_name\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(f\"[LOAD] Event Log 로딩 완료: {len(df)} rows, {df['hadm_id'].nunique()} hadm_id\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. Event Log 클린업\n",
    "#    - ED_ARRIVAL 이전 제거\n",
    "#    - DISCHARGE/DEATH 이후 제거\n",
    "#    - 너무 짧은 trace 제거\n",
    "# ==============================\n",
    "\n",
    "def clean_event_log(raw_events: pd.DataFrame,\n",
    "                    min_events_per_case: int = MIN_EVENTS_PER_CASE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    hadm_id 단위로 다음 규칙 적용:\n",
    "      1) 가장 이른 ED_ARRIVAL 이전 이벤트 제거\n",
    "         - ED_ARRIVAL이 전혀 없으면 해당 hadm_id는 제거\n",
    "      2) DISCHARGE/DEATH 이후 이벤트 제거\n",
    "         - 둘 다 있으면 더 이른 시점을 기준으로 잘라냄\n",
    "      3) 남은 이벤트 수가 min_events_per_case 미만이면 제거\n",
    "    \"\"\"\n",
    "    keep_groups = []\n",
    "    dropped_no_ed = 0\n",
    "    dropped_too_short = 0\n",
    "\n",
    "    for hadm_id, g in raw_events.groupby(\"hadm_id\"):\n",
    "        g = g.sort_values([\"timestamp\", \"event_name\"]).copy()\n",
    "        subject_id = g[\"subject_id\"].iloc[0]\n",
    "        case_id = g[\"case_id\"].iloc[0]\n",
    "\n",
    "        # 1) ED_ARRIVAL 이후만 유지\n",
    "        is_ed = (g[\"event_name\"] == \"ED_ARRIVAL\")\n",
    "        if not is_ed.any():\n",
    "            dropped_no_ed += 1\n",
    "            continue\n",
    "\n",
    "        first_ed_time = g.loc[is_ed, \"timestamp\"].min()\n",
    "        g = g[g[\"timestamp\"] >= first_ed_time].copy()\n",
    "\n",
    "        # 2) DISCHARGE/DEATH 이후 제거\n",
    "        is_end = g[\"event_name\"].isin([\"DISCHARGE\", \"DEATH\"])\n",
    "        if is_end.any():\n",
    "            end_time = g.loc[is_end, \"timestamp\"].min()\n",
    "            g = g[g[\"timestamp\"] <= end_time].copy()\n",
    "\n",
    "        # 3) 최소 이벤트 개수 체크\n",
    "        if len(g) < min_events_per_case:\n",
    "            dropped_too_short += 1\n",
    "            continue\n",
    "\n",
    "        g[\"subject_id\"] = subject_id\n",
    "        g[\"case_id\"] = case_id\n",
    "        keep_groups.append(g)\n",
    "\n",
    "    if not keep_groups:\n",
    "        print(\"[CLEAN] 남아 있는 trace가 없습니다.\")\n",
    "        return pd.DataFrame(columns=raw_events.columns)\n",
    "\n",
    "    clean_df = pd.concat(keep_groups, ignore_index=True)\n",
    "    clean_df = clean_df.sort_values(\n",
    "        by=[\"hadm_id\", \"timestamp\", \"event_name\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(f\"[CLEAN] 원본 hadm_id 수: {raw_events['hadm_id'].nunique()}\")\n",
    "    print(f\"[CLEAN] ED_ARRIVAL 없음으로 제거된 hadm_id 수: {dropped_no_ed}\")\n",
    "    print(f\"[CLEAN] 이벤트 수<{min_events_per_case}로 제거된 hadm_id 수: {dropped_too_short}\")\n",
    "    print(f\"[CLEAN] 최종 남은 hadm_id 수: {clean_df['hadm_id'].nunique()}\")\n",
    "    print(f\"[CLEAN] 최종 이벤트 row 수: {len(clean_df)}\")\n",
    "\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. event_name ↔ event_id 매핑\n",
    "# ==============================\n",
    "\n",
    "def build_event_id_map(events: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    event_name을 정수 ID로 매핑하는 테이블 생성.\n",
    "    \"\"\"\n",
    "    unique_events = sorted(events[\"event_name\"].unique())\n",
    "    event_id_map = pd.DataFrame({\n",
    "        \"event_name\": unique_events,\n",
    "        \"event_id\": range(1, len(unique_events) + 1)\n",
    "    })\n",
    "    print(f\"[MAP] 이벤트 종류 개수: {len(unique_events)}\")\n",
    "    return event_id_map\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. PPM prefix–next_event 데이터셋 생성\n",
    "# ==============================\n",
    "\n",
    "def build_ppm_prefix_dataset(clean_events: pd.DataFrame,\n",
    "                             event_id_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PPM용 prefix–next_event 데이터셋 생성.\n",
    "\n",
    "    출력 컬럼:\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - case_id\n",
    "      - prefix_len\n",
    "      - prefix_events_str\n",
    "      - current_event\n",
    "      - current_event_id\n",
    "      - next_event\n",
    "      - next_event_id\n",
    "      - time_since_start_min\n",
    "      - time_to_next_min\n",
    "      - full_trace_len\n",
    "    \"\"\"\n",
    "    name_to_id = dict(zip(event_id_map[\"event_name\"], event_id_map[\"event_id\"]))\n",
    "    records = []\n",
    "\n",
    "    for hadm_id, g in clean_events.groupby(\"hadm_id\"):\n",
    "        g = g.sort_values([\"timestamp\", \"event_name\"]).copy()\n",
    "        subject_id = g[\"subject_id\"].iloc[0]\n",
    "        case_id = g[\"case_id\"].iloc[0] if \"case_id\" in g.columns else hadm_id\n",
    "\n",
    "        events = list(g[\"event_name\"])\n",
    "        times = list(g[\"timestamp\"])\n",
    "        full_trace_len = len(events)\n",
    "\n",
    "        if full_trace_len < 2:\n",
    "            continue\n",
    "\n",
    "        first_time = times[0]\n",
    "\n",
    "        for i in range(full_trace_len - 1):\n",
    "            prefix_seq = events[: i + 1]\n",
    "            prefix_len = len(prefix_seq)\n",
    "            current_event = events[i]\n",
    "            next_event = events[i + 1]\n",
    "\n",
    "            prefix_end_time = times[i]\n",
    "            next_time = times[i + 1]\n",
    "\n",
    "            time_since_start_min = (prefix_end_time - first_time).total_seconds() / 60.0\n",
    "            time_to_next_min = (next_time - prefix_end_time).total_seconds() / 60.0\n",
    "\n",
    "            prefix_str = \">\".join(prefix_seq)\n",
    "\n",
    "            rec = {\n",
    "                \"subject_id\": subject_id,\n",
    "                \"hadm_id\": hadm_id,\n",
    "                \"case_id\": case_id,\n",
    "                \"prefix_len\": prefix_len,\n",
    "                \"prefix_events_str\": prefix_str,\n",
    "                \"current_event\": current_event,\n",
    "                \"current_event_id\": name_to_id.get(current_event, -1),\n",
    "                \"next_event\": next_event,\n",
    "                \"next_event_id\": name_to_id.get(next_event, -1),\n",
    "                \"time_since_start_min\": time_since_start_min,\n",
    "                \"time_to_next_min\": time_to_next_min,\n",
    "                \"full_trace_len\": full_trace_len,\n",
    "            }\n",
    "            records.append(rec)\n",
    "\n",
    "    ppm_df = pd.DataFrame(records)\n",
    "    print(f\"[PPM] prefix–next_event row 수: {len(ppm_df)}\")\n",
    "    return ppm_df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. MAIN (142 cohort 구축)\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    # 1) 원본 이벤트 로그 로딩 (141 버전)\n",
    "    raw_events = load_event_log(INPUT_EVENT_LOG_PATH)\n",
    "\n",
    "    # 2) Clean: ED_ARRIVAL 이후 ~ DISCHARGE/DEATH까지, 너무 짧은 trace 제거\n",
    "    clean_events = clean_event_log(raw_events, min_events_per_case=MIN_EVENTS_PER_CASE)\n",
    "\n",
    "    if clean_events.empty:\n",
    "        print(\"[MAIN] clean_events가 비어 있습니다. 이전 단계(140/141) 이벤트 생성 로직을 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 3) 클린 이벤트 로그 저장 (ver142)\n",
    "    clean_events.to_csv(CLEAN_EVENT_LOG_PATH, index=False)\n",
    "    print(f\"[SAVE] 클린 이벤트 로그 저장: {CLEAN_EVENT_LOG_PATH}\")\n",
    "\n",
    "    # 4) event_name ↔ event_id 매핑 생성 및 저장\n",
    "    event_id_map = build_event_id_map(clean_events)\n",
    "    event_id_map.to_csv(EVENT_ID_MAP_PATH, index=False)\n",
    "    print(f\"[SAVE] 이벤트 ID 매핑 저장: {EVENT_ID_MAP_PATH}\")\n",
    "\n",
    "    # 5) PPM prefix–next_event 데이터셋 생성 및 저장\n",
    "    ppm_df = build_ppm_prefix_dataset(clean_events, event_id_map)\n",
    "    ppm_df.to_csv(PPM_DATA_PATH, index=False)\n",
    "    print(f\"[SAVE] PPM prefix–next_event 데이터셋 저장: {PPM_DATA_PATH}\")\n",
    "\n",
    "    print(\"\\n[INFO] ver142 cohort 구축 완료.\")\n",
    "    print(f\"  - clean event log : {CLEAN_EVENT_LOG_PATH}\")\n",
    "    print(f\"  - event_id map    : {EVENT_ID_MAP_PATH}\")\n",
    "    print(f\"  - PPM dataset     : {PPM_DATA_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2444b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
