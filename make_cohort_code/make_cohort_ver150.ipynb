{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] cohort_ver183_add_delay_missing_flag.csv 로딩 중...\n",
      "[LOAD] event_log_stemi_all.csv 로딩 중...\n",
      "[LOAD] chartevents_ver50.csv 로딩 중 (HR/BP 전용)...\n",
      "[INFO] 이벤트 수: 40817 (hadm_id 1929개)\n",
      "[FEAT] hadm_id별 이벤트 기반 feature 계산 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26256\\510583964.py:198: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ev_feat = event_log.groupby(\"hadm_id\", group_keys=False).apply(build_features_per_admission)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FEAT] current_heart_rate 계산 중...\n",
      "[FEAT] current_mean_bp 계산 중...\n",
      "[DONE] 최종 event-level 테이블: 40817 rows, 38 columns\n",
      "[SAVE] ./../cohort\\cohort_verXXX_event_level_full.csv 에 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------\n",
    "# 0. 경로 및 상수 설정\n",
    "# ----------------------------------------\n",
    "BASE_DIR = \"./../cohort\"\n",
    "\n",
    "COHORT_PATH      = os.path.join(BASE_DIR, \"cohort_ver183_add_delay_missing_flag.csv\")\n",
    "EVENT_LOG_PATH   = os.path.join(BASE_DIR, \"event_log_stemi_all.csv\")\n",
    "CHARTEVENTS_PATH = os.path.join(BASE_DIR, \"chartevents_ver50.csv\")\n",
    "\n",
    "# EOS 토큰 ID (다음 이벤트가 없는 마지막 이벤트의 target_next_evt)\n",
    "EOS_ID = 0\n",
    "\n",
    "# event_name → current_event_id 매핑 (cohort_ver127와 동일 매핑)\n",
    "EVENT_ID_MAP = {\n",
    "    \"ED_ARRIVAL\":      1,\n",
    "    \"ECG_STEMI_FLAG\":  2,\n",
    "    \"ECG_TAKEN\":       3,\n",
    "    \"TROP_POSITIVE\":   4,\n",
    "    \"TROP_TAKEN\":      5,\n",
    "    \"ANTI_PLT_ADMIN\":  6,\n",
    "    \"ANTI_PLT_ORDER\":  7,\n",
    "    \"PCI_START\":       8,\n",
    "    \"ED_DEPARTURE\":    9,\n",
    "    \"DEATH\":          10,\n",
    "    \"DISCHARGE\":      11,\n",
    "    \"ICU_INTIME\":     12,\n",
    "    \"ICU_OUTTIME\":    13,\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. 데이터 로딩\n",
    "# ----------------------------------------\n",
    "print(\"[LOAD] cohort_ver183_add_delay_missing_flag.csv 로딩 중...\")\n",
    "cohort = pd.read_csv(COHORT_PATH)\n",
    "\n",
    "print(\"[LOAD] event_log_stemi_all.csv 로딩 중...\")\n",
    "event_log = pd.read_csv(EVENT_LOG_PATH, parse_dates=[\"timestamp\"])\n",
    "\n",
    "print(\"[LOAD] chartevents_ver50.csv 로딩 중 (HR/BP 전용)...\")\n",
    "chartevents = pd.read_csv(CHARTEVENTS_PATH, parse_dates=[\"charttime\"])\n",
    "\n",
    "# 타입 정리\n",
    "cohort[\"hadm_id\"]   = cohort[\"hadm_id\"].astype(\"int64\")\n",
    "cohort[\"subject_id\"] = cohort[\"subject_id\"].astype(\"int64\")\n",
    "\n",
    "event_log[\"hadm_id\"]   = event_log[\"hadm_id\"].astype(\"int64\")\n",
    "event_log[\"subject_id\"] = event_log[\"subject_id\"].astype(\"int64\")\n",
    "\n",
    "chartevents[\"hadm_id\"] = chartevents[\"hadm_id\"].astype(\"int64\")\n",
    "\n",
    "# cohort 안에 있는 hadm_id만 사용\n",
    "event_log = event_log[event_log[\"hadm_id\"].isin(cohort[\"hadm_id\"])].copy()\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. 이벤트 필터링 및 current_event_id 매핑\n",
    "# ----------------------------------------\n",
    "event_log = event_log[event_log[\"event_name\"].isin(EVENT_ID_MAP.keys())].copy()\n",
    "event_log[\"current_event_id\"] = event_log[\"event_name\"].map(EVENT_ID_MAP)\n",
    "\n",
    "# 정렬 (hadm_id, timestamp, event_id 기준)\n",
    "event_log = event_log.sort_values([\"hadm_id\", \"timestamp\", \"current_event_id\"])\n",
    "\n",
    "print(f\"[INFO] 이벤트 수: {len(event_log)} (hadm_id {event_log['hadm_id'].nunique()}개)\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. hadm_id별 이벤트 시퀀스 기반 feature 계산\n",
    "#    (17~31, 35~38, 34 포함)\n",
    "# ----------------------------------------\n",
    "def build_features_per_admission(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    한 hadm_id 내에서:\n",
    "    - prefix_len / time_since_ed / time_since_last / is_night\n",
    "    - cum_ecg_cnt / cum_stemi_cnt / cum_trop_cnt\n",
    "    - stemi_flag / trop_pos_flag\n",
    "    - last_trop / run_max_trop / trop_trend\n",
    "    - pci_status (0/1)\n",
    "    - time_since_start_min\n",
    "    - target_next_evt / target_time_to_next\n",
    "    - target_mortality / target_remain_los\n",
    "    를 계산한다.\n",
    "    \"\"\"\n",
    "    g = g.sort_values(\"timestamp\").copy()\n",
    "\n",
    "    # 17. prefix_len\n",
    "    g[\"prefix_len\"] = np.arange(1, len(g) + 1)\n",
    "\n",
    "    # ED_ARRIVAL 기준 시간\n",
    "    ed_mask = g[\"event_name\"] == \"ED_ARRIVAL\"\n",
    "    if ed_mask.any():\n",
    "        ed_time = g.loc[ed_mask, \"timestamp\"].iloc[0]\n",
    "    else:\n",
    "        ed_time = g[\"timestamp\"].min()\n",
    "\n",
    "    # 18. time_since_ed (분 단위, 0 이하일 경우 0으로 클램핑)\n",
    "    g[\"time_since_ed\"] = (g[\"timestamp\"] - ed_time).dt.total_seconds() / 60.0\n",
    "    g.loc[g[\"time_since_ed\"] < 0, \"time_since_ed\"] = 0.0\n",
    "\n",
    "    # 19. time_since_last (분 단위, 첫 이벤트는 0)\n",
    "    g[\"time_since_last\"] = g[\"timestamp\"].diff().dt.total_seconds() / 60.0\n",
    "    g[\"time_since_last\"] = g[\"time_since_last\"].fillna(0.0)\n",
    "\n",
    "    # 20. is_night (22~07시)\n",
    "    hours = g[\"timestamp\"].dt.hour\n",
    "    g[\"is_night\"] = ((hours >= 22) | (hours <= 7)).astype(int)\n",
    "\n",
    "    # 21~23. 누적 카운트\n",
    "    g[\"cum_ecg_cnt\"]   = (g[\"event_name\"] == \"ECG_TAKEN\").cumsum()\n",
    "    g[\"cum_stemi_cnt\"] = (g[\"event_name\"] == \"ECG_STEMI_FLAG\").cumsum()\n",
    "    g[\"cum_trop_cnt\"]  = (g[\"event_name\"] == \"TROP_TAKEN\").cumsum()\n",
    "\n",
    "    # 24. stemi_flag (첫 ECG_STEMI_FLAG 이후 1)\n",
    "    if (g[\"event_name\"] == \"ECG_STEMI_FLAG\").any():\n",
    "        first_stemi_time = g.loc[g[\"event_name\"] == \"ECG_STEMI_FLAG\", \"timestamp\"].iloc[0]\n",
    "        g[\"stemi_flag\"] = (g[\"timestamp\"] >= first_stemi_time).astype(int)\n",
    "    else:\n",
    "        g[\"stemi_flag\"] = 0\n",
    "\n",
    "    # 25. trop_pos_flag (첫 TROP_POSITIVE 이후 1)\n",
    "    if (g[\"event_name\"] == \"TROP_POSITIVE\").any():\n",
    "        first_pos_trop_time = g.loc[g[\"event_name\"] == \"TROP_POSITIVE\", \"timestamp\"].iloc[0]\n",
    "        g[\"trop_pos_flag\"] = (g[\"timestamp\"] >= first_pos_trop_time).astype(int)\n",
    "    else:\n",
    "        g[\"trop_pos_flag\"] = 0\n",
    "\n",
    "    # 26~28. Troponin 관련 값 (attributes JSON에서 valuenum 추출)\n",
    "    trop_mask = g[\"event_name\"].isin([\"TROP_TAKEN\", \"TROP_POSITIVE\"])\n",
    "    trop_vals = pd.Series(index=g.index, dtype=\"float64\")\n",
    "\n",
    "    if trop_mask.any():\n",
    "        def extract_valuenum(attr_str):\n",
    "            if not isinstance(attr_str, str) or not attr_str.strip():\n",
    "                return np.nan\n",
    "            try:\n",
    "                d = json.loads(attr_str)\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "            v = d.get(\"valuenum\")\n",
    "            try:\n",
    "                return float(v) if v is not None else np.nan\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "\n",
    "        trop_vals.loc[trop_mask] = g.loc[trop_mask, \"attributes\"].map(extract_valuenum)\n",
    "\n",
    "    g[\"trop_value\"] = trop_vals\n",
    "\n",
    "    # 26. last_trop: 직전 Troponin 수치 (없으면 0)\n",
    "    g[\"last_trop\"] = g[\"trop_value\"].ffill().fillna(0.0)\n",
    "\n",
    "    # 27. run_max_trop: 현재까지 최대 Troponin 수치\n",
    "    g[\"run_max_trop\"] = g[\"last_trop\"].cummax()\n",
    "\n",
    "    # 28. trop_trend: current_trop - prev_trop (첫 검사는 0)\n",
    "    g[\"trop_trend\"] = g[\"last_trop\"] - g[\"last_trop\"].shift(1).fillna(0.0)\n",
    "\n",
    "    # 29. pci_status: 0/1 (PCI_START 발생 전 0, 이후 1)\n",
    "    if (g[\"event_name\"] == \"PCI_START\").any():\n",
    "        first_pci_time = g.loc[g[\"event_name\"] == \"PCI_START\", \"timestamp\"].iloc[0]\n",
    "        g[\"pci_status\"] = (g[\"timestamp\"] >= first_pci_time).astype(int)\n",
    "    else:\n",
    "        g[\"pci_status\"] = 0\n",
    "\n",
    "    # 30. time_since_start_min: 첫 이벤트 이후 경과 시간(분)\n",
    "    first_time = g[\"timestamp\"].min()\n",
    "    g[\"time_since_start_min\"] = (g[\"timestamp\"] - first_time).dt.total_seconds() / 60.0\n",
    "\n",
    "    # 36. target_next_evt: 다음 이벤트의 current_event_id, 없으면 EOS_ID\n",
    "    g[\"target_next_evt\"] = g[\"current_event_id\"].shift(-1)\n",
    "    g[\"target_next_evt\"] = g[\"target_next_evt\"].fillna(EOS_ID).astype(int)\n",
    "\n",
    "    # 37. target_time_to_next: 다음 이벤트까지 시간(분), 마지막은 0\n",
    "    diff_next = g[\"timestamp\"].shift(-1) - g[\"timestamp\"]\n",
    "    g[\"target_time_to_next\"] = diff_next.dt.total_seconds() / 60.0\n",
    "    g[\"target_time_to_next\"] = g[\"target_time_to_next\"].fillna(0.0)\n",
    "\n",
    "    # 35. target_mortality: DEATH 이벤트 존재 여부\n",
    "    death_flag = int((g[\"event_name\"] == \"DEATH\").any())\n",
    "    g[\"target_mortality\"] = death_flag\n",
    "\n",
    "    # 38. target_remain_los: dischtime - current_time (일 단위)\n",
    "    if (g[\"event_name\"] == \"DISCHARGE\").any():\n",
    "        dischtime = g.loc[g[\"event_name\"] == \"DISCHARGE\", \"timestamp\"].iloc[0]\n",
    "    elif (g[\"event_name\"] == \"DEATH\").any():\n",
    "        dischtime = g.loc[g[\"event_name\"] == \"DEATH\", \"timestamp\"].iloc[0]\n",
    "    else:\n",
    "        dischtime = g[\"timestamp\"].max()\n",
    "\n",
    "    g[\"target_remain_los\"] = (dischtime - g[\"timestamp\"]).dt.total_seconds() / 60.0 / 24.0\n",
    "\n",
    "    return g\n",
    "\n",
    "print(\"[FEAT] hadm_id별 이벤트 기반 feature 계산 중...\")\n",
    "ev_feat = event_log.groupby(\"hadm_id\", group_keys=False).apply(build_features_per_admission)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. HR / BP 붙이기 (32, 33)\n",
    "#    - hadm_id별로 나눠서 merge_asof(prev/next) 후 평균\n",
    "# ----------------------------------------\n",
    "hr = chartevents[chartevents[\"variable_name\"] == \"heart_rate\"][\n",
    "    [\"hadm_id\", \"charttime\", \"valuenum\"]\n",
    "].copy()\n",
    "bp = chartevents[chartevents[\"variable_name\"] == \"mean_bp\"][\n",
    "    [\"hadm_id\", \"charttime\", \"valuenum\"]\n",
    "].copy()\n",
    "\n",
    "def attach_signal_mean_prev_next(df_events: pd.DataFrame,\n",
    "                                 df_signal: pd.DataFrame,\n",
    "                                 out_col: str,\n",
    "                                 time_col_evt: str = \"timestamp\",\n",
    "                                 time_col_sig: str = \"charttime\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    각 hadm_id에 대해:\n",
    "    - 이벤트 시각 기준 직전 값(prev)과 직후 값(next)을 merge_asof로 가져온 뒤\n",
    "    - 둘의 평균을 out_col로 계산 (한쪽만 있으면 그 값 사용)\n",
    "    \"\"\"\n",
    "    pieces = []\n",
    "\n",
    "    for hadm_id, sub_evt in df_events.groupby(\"hadm_id\"):\n",
    "        sub_evt = sub_evt.sort_values(time_col_evt).copy()\n",
    "        sig = df_signal[df_signal[\"hadm_id\"] == hadm_id].sort_values(time_col_sig)\n",
    "\n",
    "        if sig.empty:\n",
    "            sub_evt[out_col] = np.nan\n",
    "        else:\n",
    "            left = sub_evt[[time_col_evt]].rename(columns={time_col_evt: \"t\"})\n",
    "            right = sig[[time_col_sig, \"valuenum\"]].rename(columns={time_col_sig: \"t\"})\n",
    "\n",
    "            prev = pd.merge_asof(\n",
    "                left,\n",
    "                right,\n",
    "                on=\"t\",\n",
    "                direction=\"backward\"\n",
    "            )[\"valuenum\"]\n",
    "\n",
    "            nxt = pd.merge_asof(\n",
    "                left,\n",
    "                right,\n",
    "                on=\"t\",\n",
    "                direction=\"forward\"\n",
    "            )[\"valuenum\"]\n",
    "\n",
    "            sub_evt[out_col] = pd.concat([prev, nxt], axis=1).mean(axis=1, skipna=True)\n",
    "\n",
    "        pieces.append(sub_evt[[out_col]])\n",
    "\n",
    "    out = pd.concat(pieces)\n",
    "    return out[out_col]\n",
    "\n",
    "print(\"[FEAT] current_heart_rate 계산 중...\")\n",
    "ev_feat = ev_feat.sort_values([\"hadm_id\", \"timestamp\"])\n",
    "ev_feat[\"current_heart_rate\"] = attach_signal_mean_prev_next(ev_feat, hr, \"current_heart_rate\")\n",
    "\n",
    "print(\"[FEAT] current_mean_bp 계산 중...\")\n",
    "ev_feat[\"current_mean_bp\"] = attach_signal_mean_prev_next(ev_feat, bp, \"current_mean_bp\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5. static cohort(1~16)와 이벤트 feature 병합\n",
    "# ----------------------------------------\n",
    "# event 쪽 subject_id는 버리고 cohort의 subject_id 사용\n",
    "ev_feat_for_merge = ev_feat.drop(columns=[\"subject_id\"], errors=\"ignore\").copy()\n",
    "ev_feat_for_merge[\"hadm_id\"] = ev_feat_for_merge[\"hadm_id\"].astype(\"int64\")\n",
    "\n",
    "final = ev_feat_for_merge.merge(cohort, on=\"hadm_id\", how=\"left\")\n",
    "\n",
    "# missing_flag 컬럼 이름 정리\n",
    "final = final.rename(columns={\n",
    "    \"door_to_ecg_missing\":  \"door_to_ecg_missing_flag\",\n",
    "    \"door_to_trop_missing\": \"door_to_trop_missing_flag\",\n",
    "    \"door_to_anti_missing\": \"door_to_anti_missing_flag\",\n",
    "    \"door_to_pci_missing\":  \"door_to_pci_missing_flag\",\n",
    "})\n",
    "\n",
    "# target_mortality 형 변환\n",
    "final[\"target_mortality\"] = final[\"target_mortality\"].astype(int)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6. 최종 컬럼 순서 정리 (1~38)\n",
    "# ----------------------------------------\n",
    "cols_order = [\n",
    "    \"subject_id\",                 # 1\n",
    "    \"hadm_id\",                    # 2\n",
    "    \"age\",                        # 3\n",
    "    \"gender\",                     # 4\n",
    "    \"race\",                       # 5\n",
    "    \"arrival_transport\",          # 6\n",
    "    \"cci_score\",                  # 7\n",
    "    \"hfrs_score\",                 # 8\n",
    "    \"door_to_ecg\",                # 9\n",
    "    \"door_to_trop\",               # 10\n",
    "    \"door_to_anti\",               # 11\n",
    "    \"door_to_pci\",                # 12\n",
    "    \"door_to_ecg_missing_flag\",   # 13\n",
    "    \"door_to_trop_missing_flag\",  # 14\n",
    "    \"door_to_anti_missing_flag\",  # 15\n",
    "    \"door_to_pci_missing_flag\",   # 16\n",
    "    \"prefix_len\",                 # 17\n",
    "    \"time_since_ed\",              # 18\n",
    "    \"time_since_last\",            # 19\n",
    "    \"is_night\",                   # 20\n",
    "    \"cum_ecg_cnt\",                # 21\n",
    "    \"cum_stemi_cnt\",              # 22\n",
    "    \"cum_trop_cnt\",               # 23\n",
    "    \"stemi_flag\",                 # 24\n",
    "    \"trop_pos_flag\",              # 25\n",
    "    \"last_trop\",                  # 26\n",
    "    \"run_max_trop\",               # 27\n",
    "    \"trop_trend\",                 # 28\n",
    "    \"pci_status\",                 # 29 (0/1)\n",
    "    \"time_since_start_min\",       # 30\n",
    "    \"current_event_id\",           # 31\n",
    "    \"current_heart_rate\",         # 32\n",
    "    \"current_mean_bp\",            # 33\n",
    "    \"timestamp\",                  # 34\n",
    "    \"target_mortality\",           # 35\n",
    "    \"target_next_evt\",            # 36\n",
    "    \"target_time_to_next\",        # 37\n",
    "    \"target_remain_los\",          # 38\n",
    "]\n",
    "\n",
    "final_out = final[cols_order].copy()\n",
    "\n",
    "print(f\"[DONE] 최종 event-level 테이블: {final_out.shape[0]} rows, {final_out.shape[1]} columns\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 7. 저장 (원하는 이름으로 수정해서 사용)\n",
    "# ----------------------------------------\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"cohort_ver150_event_level_full.csv\")\n",
    "final_out.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"[SAVE] {OUTPUT_PATH} 에 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a43a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
