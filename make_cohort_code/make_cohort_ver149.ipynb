{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697c4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13000\\1068982033.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hr.groupby([\"subject_id\", \"hadm_id\"])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13000\\1068982033.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  bp.groupby([\"subject_id\", \"hadm_id\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] saved: ./../cohort/cohort_ver148_with_ecg_hr_bp_arrays.csv\n",
      "shape: (1929, 6)\n",
      "columns: ['hadm_id', 'event_sequence_array', 'subject_id', 'hr_array', 'bp_array', 'ecg_array']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# -----------------------------------------\n",
    "# 0. 파일 경로\n",
    "# -----------------------------------------\n",
    "base = \"./../cohort/\"\n",
    "ts_path    = base + \"timestamp_array.csv\"\n",
    "ecg_path   = base + \"ecg_ver50_stemi_flag.csv\"\n",
    "chart_path = base + \"chartevents_ver50.csv\"\n",
    "out_path   = base + \"cohort_ver148_with_ecg_hr_bp_arrays.csv\"\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. Load\n",
    "# -----------------------------------------\n",
    "# timestamp_array: hadm_id, event_sequence_array (JSON string)\n",
    "ts    = pd.read_csv(ts_path, low_memory=False)\n",
    "ecg   = pd.read_csv(ecg_path, parse_dates=[\"ecg_time\"], low_memory=False)\n",
    "chart = pd.read_csv(chart_path, parse_dates=[\"charttime\"], low_memory=False)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. timestamp_array에 subject_id 붙이기\n",
    "#    - chartevents에서 hadm_id→subject_id 매핑\n",
    "# -----------------------------------------\n",
    "hadm_subject = (\n",
    "    chart[[\"hadm_id\", \"subject_id\"]]\n",
    "    .dropna(subset=[\"hadm_id\", \"subject_id\"])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "ts = ts.merge(hadm_subject, on=\"hadm_id\", how=\"left\")\n",
    "# 이제 ts: hadm_id, event_sequence_array, subject_id\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. HR / BP 시계열 배열 생성 (key: subject_id + hadm_id)\n",
    "# -----------------------------------------\n",
    "hr = chart[chart[\"variable_name\"] == \"heart_rate\"][\n",
    "    [\"subject_id\", \"hadm_id\", \"charttime\", \"valuenum\"]\n",
    "]\n",
    "bp = chart[chart[\"variable_name\"] == \"mean_bp\"][\n",
    "    [\"subject_id\", \"hadm_id\", \"charttime\", \"valuenum\"]\n",
    "]\n",
    "\n",
    "def make_array(df: pd.DataFrame) -> str:\n",
    "    \"\"\"charttime/valuenum을 JSON 배열로 직렬화\"\"\"\n",
    "    if df.empty:\n",
    "        return \"[]\"\n",
    "    df = df.sort_values(\"charttime\")\n",
    "    arr = [\n",
    "        {\n",
    "            \"time\": t.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"value\": float(v),\n",
    "        }\n",
    "        for t, v in zip(df[\"charttime\"], df[\"valuenum\"])\n",
    "    ]\n",
    "    return json.dumps(arr)\n",
    "\n",
    "# subject_id + hadm_id 기준으로 HR/BP 배열 생성\n",
    "hr_array = (\n",
    "    hr.groupby([\"subject_id\", \"hadm_id\"])\n",
    "      .apply(make_array)\n",
    "      .rename(\"hr_array\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "bp_array = (\n",
    "    bp.groupby([\"subject_id\", \"hadm_id\"])\n",
    "      .apply(make_array)\n",
    "      .rename(\"bp_array\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. ts에 HR/BP 병합 (key: subject_id + hadm_id)\n",
    "# -----------------------------------------\n",
    "merged = ts.merge(hr_array, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "merged = merged.merge(bp_array, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. ECG 배열 생성\n",
    "#    - ECG에는 hadm_id가 없으므로:\n",
    "#      (subject_id 일치) AND (해당 hadm의 event_sequence_array 시간 범위 ±1일)\n",
    "#      를 기준으로 붙임\n",
    "# -----------------------------------------\n",
    "def build_ecg_array(row) -> str:\n",
    "    sid = row[\"subject_id\"]\n",
    "\n",
    "    # event_sequence_array 파싱\n",
    "    try:\n",
    "        events = json.loads(row[\"event_sequence_array\"])\n",
    "    except Exception:\n",
    "        return \"[]\"\n",
    "\n",
    "    times = []\n",
    "    for e in events:\n",
    "        t = e.get(\"time\")\n",
    "        if t:\n",
    "            try:\n",
    "                times.append(pd.to_datetime(t))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    if not times:\n",
    "        return \"[]\"\n",
    "\n",
    "    start = min(times)\n",
    "    end   = max(times)\n",
    "    buffer = pd.Timedelta(\"1D\")\n",
    "\n",
    "    # subject_id만으로 ECG 매칭 + 해당 hadm 입원 구간 주변만 사용\n",
    "    sub_ecg = ecg[\n",
    "        (ecg[\"subject_id\"] == sid) &\n",
    "        (ecg[\"ecg_time\"] >= start - buffer) &\n",
    "        (ecg[\"ecg_time\"] <= end + buffer)\n",
    "    ].sort_values(\"ecg_time\")\n",
    "\n",
    "    if sub_ecg.empty:\n",
    "        return \"[]\"\n",
    "\n",
    "    arr = [\n",
    "        {\n",
    "            \"time\": t.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"stemi_flag\": int(sf),\n",
    "        }\n",
    "        for t, sf in zip(sub_ecg[\"ecg_time\"], sub_ecg[\"stemi_flag\"])\n",
    "    ]\n",
    "    return json.dumps(arr)\n",
    "\n",
    "merged[\"ecg_array\"] = merged.apply(build_ecg_array, axis=1)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6. 중복 컬럼 제거 (예방용)\n",
    "# -----------------------------------------\n",
    "merged = merged.loc[:, ~merged.columns.duplicated()]\n",
    "\n",
    "# -----------------------------------------\n",
    "# 7. 저장\n",
    "# -----------------------------------------\n",
    "merged.to_csv(out_path, index=False)\n",
    "print(\"[DONE] saved:\", out_path)\n",
    "print(\"shape:\", merged.shape)\n",
    "print(\"columns:\", merged.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a43a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
