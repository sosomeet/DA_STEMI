{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6326c7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] Event Log 로딩 완료: 38674 rows, 1878 hadm_id\n",
      "[LOAD] event_name 분포:\n",
      "event_name\n",
      "ECG_TAKEN         17801\n",
      "TROP_TAKEN         3778\n",
      "ANTI_PLT_ADMIN     2860\n",
      "ANTI_PLT_ORDER     2860\n",
      "ECG_STEMI_FLAG     2854\n",
      "ED_ARRIVAL         1869\n",
      "ED_DEPARTURE       1826\n",
      "DISCHARGE          1721\n",
      "ICU_INTIME          943\n",
      "TROP_POSITIVE       943\n",
      "ICU_OUTTIME         769\n",
      "PCI_START           293\n",
      "DEATH               157\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[CLEAN] === 요약 ===\n",
      "원본 hadm_id 수: 1878\n",
      "최종 남은 hadm_id 수: 1869\n",
      "최종 이벤트 row 수: 26860\n",
      "이벤트 수<2로 제거된 hadm_id 수: 9\n",
      "\n",
      "[CLEAN] 시작 기준 통계 (hadm 단위):\n",
      "  ED_ARRIVAL 기준 시작 hadm 수       : 1865\n",
      "  ED_ARRIVAL_SURR 기준 시작 hadm 수  : 0\n",
      "  첫 이벤트 기준 시작 hadm 수        : 13\n",
      "[MAP] 이벤트 종류 개수: 13\n",
      "        event_name  event_id\n",
      "0   ANTI_PLT_ADMIN         1\n",
      "1   ANTI_PLT_ORDER         2\n",
      "2            DEATH         3\n",
      "3        DISCHARGE         4\n",
      "4   ECG_STEMI_FLAG         5\n",
      "5        ECG_TAKEN         6\n",
      "6       ED_ARRIVAL         7\n",
      "7     ED_DEPARTURE         8\n",
      "8       ICU_INTIME         9\n",
      "9      ICU_OUTTIME        10\n",
      "10       PCI_START        11\n",
      "11   TROP_POSITIVE        12\n",
      "12      TROP_TAKEN        13\n",
      "[143] cohort row 수(hadm 기준): 1869\n",
      "[SAVE] cohort ver143 저장 완료: ./../cohort\\cohort_ver143_next_event_arr.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# 0. 경로 및 기본 설정\n",
    "# ==============================\n",
    "\n",
    "# 140 버전 event log (앞에서 만든 파일)\n",
    "INPUT_EVENT_LOG_PATH = \"./../cohort/cohort_ver140_event_log.csv\"\n",
    "\n",
    "OUTPUT_DIR = \"./../cohort\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 최종 출력: cohort ver143\n",
    "COHORT_143_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver143_next_event_arr.csv\")\n",
    "\n",
    "# 너무 짧은 trace 제거 기준\n",
    "MIN_EVENTS_PER_CASE = 2\n",
    "\n",
    "# EOS 토큰 ID (다음 이벤트가 없는 마지막 이벤트용)\n",
    "EOS_EVENT_ID = 0\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 1. 공통 유틸\n",
    "# ==============================\n",
    "\n",
    "def _to_datetime(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    \"\"\"주어진 컬럼을 datetime으로 캐스팅.\"\"\"\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. 이벤트 로그 로딩 (140 → raw)\n",
    "# ==============================\n",
    "\n",
    "def load_event_log(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    140 버전 Event Log CSV 로딩.\n",
    "    필수 컬럼:\n",
    "      - case_id\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - event_name\n",
    "      - timestamp\n",
    "\n",
    "    추가로 있다면:\n",
    "      - death_flag (0/1)\n",
    "      - dischtime (퇴원 시각)\n",
    "      - current_heart_rate, current_mean_bp 등도 그대로 사용.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"입력 이벤트 로그 파일을 찾을 수 없습니다: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    required_cols = [\"case_id\", \"subject_id\", \"hadm_id\", \"event_name\", \"timestamp\"]\n",
    "    for c in required_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(\n",
    "                f\"입력 이벤트 로그에 '{c}' 컬럼이 없습니다. 현재 컬럼: {list(df.columns)}\"\n",
    "            )\n",
    "\n",
    "    # 시간 컬럼 처리\n",
    "    df = _to_datetime(df, \"timestamp\")\n",
    "    if \"dischtime\" in df.columns:\n",
    "        df = _to_datetime(df, \"dischtime\")\n",
    "\n",
    "    # timestamp 결측 제거\n",
    "    df = df.dropna(subset=[\"timestamp\"])\n",
    "\n",
    "    df = df.sort_values(\n",
    "        by=[\"hadm_id\", \"timestamp\", \"event_name\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(f\"[LOAD] Event Log 로딩 완료: {len(df)} rows, {df['hadm_id'].nunique()} hadm_id\")\n",
    "    print(f\"[LOAD] event_name 분포:\\n{df['event_name'].value_counts()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. Event Log 클린업\n",
    "#    - (가능하면) ED_ARRIVAL / ED_ARRIVAL_SURR 이후만 사용\n",
    "#    - DISCHARGE/DEATH 이후 제거\n",
    "#    - 너무 짧은 trace 제거\n",
    "# ==============================\n",
    "\n",
    "def clean_event_log(raw_events: pd.DataFrame,\n",
    "                    min_events_per_case: int = MIN_EVENTS_PER_CASE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    hadm_id 단위로 다음 규칙 적용:\n",
    "\n",
    "      1) 시작 기준 이벤트:\n",
    "         - 우선순위 1: ED_ARRIVAL\n",
    "         - 우선순위 2: ED_ARRIVAL_SURR\n",
    "         - 둘 다 없으면: 해당 hadm의 첫 timestamp\n",
    "\n",
    "      2) DISCHARGE/DEATH 이후 이벤트 제거\n",
    "         - 둘 다 있으면 더 이른 시점을 기준으로 자름\n",
    "\n",
    "      3) 남은 이벤트 수가 min_events_per_case 미만이면 제거\n",
    "    \"\"\"\n",
    "    keep_groups = []\n",
    "    dropped_too_short = 0\n",
    "\n",
    "    # 통계용 카운트\n",
    "    cnt_start_ed       = 0  # ED_ARRIVAL 기준 시작\n",
    "    cnt_start_ed_surr  = 0  # ED_ARRIVAL_SURR 기준 시작\n",
    "    cnt_start_first    = 0  # 그냥 첫 이벤트 기준 시작\n",
    "\n",
    "    for hadm_id, g in raw_events.groupby(\"hadm_id\"):\n",
    "        g = g.sort_values([\"timestamp\", \"event_name\"]).copy()\n",
    "        subject_id = g[\"subject_id\"].iloc[0]\n",
    "        case_id = g[\"case_id\"].iloc[0]\n",
    "\n",
    "        # 1) 시작 시각 결정\n",
    "        is_ed      = (g[\"event_name\"] == \"ED_ARRIVAL\")\n",
    "        is_ed_surr = (g[\"event_name\"] == \"ED_ARRIVAL_SURR\")\n",
    "\n",
    "        if is_ed.any():\n",
    "            start_time = g.loc[is_ed, \"timestamp\"].min()\n",
    "            cnt_start_ed += 1\n",
    "        elif is_ed_surr.any():\n",
    "            start_time = g.loc[is_ed_surr, \"timestamp\"].min()\n",
    "            cnt_start_ed_surr += 1\n",
    "        else:\n",
    "            start_time = g[\"timestamp\"].min()\n",
    "            cnt_start_first += 1\n",
    "\n",
    "        g = g[g[\"timestamp\"] >= start_time].copy()\n",
    "\n",
    "        # 2) DISCHARGE/DEATH 이후 제거\n",
    "        is_end = g[\"event_name\"].isin([\"DISCHARGE\", \"DEATH\"])\n",
    "        if is_end.any():\n",
    "            end_time = g.loc[is_end, \"timestamp\"].min()\n",
    "            g = g[g[\"timestamp\"] <= end_time].copy()\n",
    "\n",
    "        # 3) 최소 이벤트 개수 체크\n",
    "        if len(g) < min_events_per_case:\n",
    "            dropped_too_short += 1\n",
    "            continue\n",
    "\n",
    "        g[\"subject_id\"] = subject_id\n",
    "        g[\"case_id\"] = case_id\n",
    "        keep_groups.append(g)\n",
    "\n",
    "    if not keep_groups:\n",
    "        print(\"[CLEAN] 남아 있는 trace가 없습니다.\")\n",
    "        print(f\"[CLEAN] 원본 hadm_id 수: {raw_events['hadm_id'].nunique()}\")\n",
    "        print(f\"[CLEAN] 이벤트 수<{min_events_per_case}로 제거된 hadm_id 수: {dropped_too_short}\")\n",
    "        return pd.DataFrame(columns=raw_events.columns)\n",
    "\n",
    "    clean_df = pd.concat(keep_groups, ignore_index=True)\n",
    "    clean_df = clean_df.sort_values(\n",
    "        by=[\"hadm_id\", \"timestamp\", \"event_name\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\n[CLEAN] === 요약 ===\")\n",
    "    print(f\"원본 hadm_id 수: {raw_events['hadm_id'].nunique()}\")\n",
    "    print(f\"최종 남은 hadm_id 수: {clean_df['hadm_id'].nunique()}\")\n",
    "    print(f\"최종 이벤트 row 수: {len(clean_df)}\")\n",
    "    print(f\"이벤트 수<{min_events_per_case}로 제거된 hadm_id 수: {dropped_too_short}\")\n",
    "    print(\"\\n[CLEAN] 시작 기준 통계 (hadm 단위):\")\n",
    "    print(f\"  ED_ARRIVAL 기준 시작 hadm 수       : {cnt_start_ed}\")\n",
    "    print(f\"  ED_ARRIVAL_SURR 기준 시작 hadm 수  : {cnt_start_ed_surr}\")\n",
    "    print(f\"  첫 이벤트 기준 시작 hadm 수        : {cnt_start_first}\")\n",
    "\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. event_name ↔ event_id 매핑\n",
    "# ==============================\n",
    "\n",
    "def build_event_id_map(events: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    event_name을 정수 ID로 매핑하는 테이블 생성.\n",
    "    \"\"\"\n",
    "    unique_events = sorted(events[\"event_name\"].unique())\n",
    "    event_id_map = pd.DataFrame({\n",
    "        \"event_name\": unique_events,\n",
    "        \"event_id\": range(1, len(unique_events) + 1)\n",
    "    })\n",
    "    print(f\"[MAP] 이벤트 종류 개수: {len(unique_events)}\")\n",
    "    print(event_id_map)\n",
    "    return event_id_map\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. cohort ver143 (hadm 단위 arr 요약) 생성\n",
    "# ==============================\n",
    "\n",
    "def build_cohort_ver143_arr(clean_events: pd.DataFrame,\n",
    "                            event_id_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    hadm_id 1건당 1행인 tabular cohort ver143 생성.\n",
    "\n",
    "    컬럼 개요:\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - case_id\n",
    "      - n_events\n",
    "      - death_flag (hadm 단위)\n",
    "      - dischtime (있으면)\n",
    "      - first_timestamp, last_timestamp\n",
    "\n",
    "      + 아래 7개 (요청)\n",
    "      - prefix_events_str        : 전체 이벤트 이름을 \">\"로 이어붙인 문자열\n",
    "      - current_heart_rate       : 각 이벤트 시점 HR 배열(JSON 문자열)\n",
    "      - current_mean_bp          : 각 이벤트 시점 BP 배열(JSON 문자열)\n",
    "      - target_mortality         : hadm 단위 병원 내 사망 여부(0/1)\n",
    "      - target_next_evt          : 각 이벤트 시점의 다음 이벤트 ID 배열(JSON)\n",
    "      - target_time_to_next      : 각 이벤트 시점의 다음 이벤트까지 시간(분) 배열(JSON)\n",
    "      - target_remain_los        : 각 이벤트 시점의 퇴원까지 남은 시간(일) 배열(JSON)\n",
    "    \"\"\"\n",
    "    name_to_id = dict(zip(event_id_map[\"event_name\"], event_id_map[\"event_id\"]))\n",
    "\n",
    "    clean_events = _to_datetime(clean_events, \"timestamp\")\n",
    "    if \"dischtime\" in clean_events.columns:\n",
    "        clean_events = _to_datetime(clean_events, \"dischtime\")\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for hadm_id, g in clean_events.groupby(\"hadm_id\"):\n",
    "        g = g.sort_values([\"timestamp\", \"event_name\"]).copy()\n",
    "\n",
    "        n_events = len(g)\n",
    "        if n_events < 2:\n",
    "            # 다음 이벤트가 거의 없기 때문에 스킵할 수도 있음\n",
    "            continue\n",
    "\n",
    "        subject_id = g[\"subject_id\"].iloc[0]\n",
    "        case_id = g[\"case_id\"].iloc[0] if \"case_id\" in g.columns else hadm_id\n",
    "\n",
    "        # hadm 단위 death_flag\n",
    "        if \"death_flag\" in g.columns:\n",
    "            df_val = g[\"death_flag\"].iloc[0]\n",
    "            death_flag = 0 if pd.isna(df_val) else int(df_val)\n",
    "        else:\n",
    "            death_flag = 0\n",
    "\n",
    "        # hadm 단위 dischtime\n",
    "        disch_time = g[\"dischtime\"].iloc[0] if \"dischtime\" in g.columns else None\n",
    "\n",
    "        events = list(g[\"event_name\"])\n",
    "        times = list(g[\"timestamp\"])\n",
    "        event_ids = [name_to_id.get(e, -1) for e in events]\n",
    "\n",
    "        first_timestamp = times[0]\n",
    "        last_timestamp = times[-1]\n",
    "\n",
    "        # 1) prefix_events_str: 전체 트레이스\n",
    "        prefix_events_str = \">\".join(events)\n",
    "\n",
    "        # 2) current_heart_rate 배열\n",
    "        if \"current_heart_rate\" in g.columns:\n",
    "            hr_arr = g[\"current_heart_rate\"].fillna(0).astype(float).tolist()\n",
    "        else:\n",
    "            hr_arr = [0.0] * n_events\n",
    "\n",
    "        # 3) current_mean_bp 배열\n",
    "        if \"current_mean_bp\" in g.columns:\n",
    "            bp_arr = g[\"current_mean_bp\"].fillna(0).astype(float).tolist()\n",
    "        else:\n",
    "            bp_arr = [0.0] * n_events\n",
    "\n",
    "        # 4) target_mortality: hadm 단위 스칼라\n",
    "        target_mortality = death_flag\n",
    "\n",
    "        # 5, 6, 7) 다음 이벤트 관련 배열들\n",
    "        next_evt_ids = []\n",
    "        time_to_next_arr = []\n",
    "        remain_los_arr = []\n",
    "\n",
    "        for i in range(n_events):\n",
    "            cur_time = times[i]\n",
    "\n",
    "            # 다음 이벤트 ID, 시간\n",
    "            if i < n_events - 1:\n",
    "                next_evt_ids.append(event_ids[i + 1])\n",
    "                dt_min = (times[i + 1] - cur_time).total_seconds() / 60.0\n",
    "                time_to_next_arr.append(float(dt_min))\n",
    "            else:\n",
    "                # 마지막 이벤트: EOS, 0\n",
    "                next_evt_ids.append(EOS_EVENT_ID)\n",
    "                time_to_next_arr.append(0.0)\n",
    "\n",
    "            # 퇴원까지 남은 시간(일)\n",
    "            if disch_time is not None and pd.notna(disch_time):\n",
    "                remain_minutes = (disch_time - cur_time).total_seconds() / 60.0\n",
    "                remain_days = remain_minutes / (60.0 * 24.0)\n",
    "                remain_los_arr.append(float(remain_days))\n",
    "            else:\n",
    "                remain_los_arr.append(np.nan)\n",
    "\n",
    "        rec = {\n",
    "            \"subject_id\": subject_id,\n",
    "            \"hadm_id\": hadm_id,\n",
    "            \"case_id\": case_id,\n",
    "            \"n_events\": n_events,\n",
    "            \"death_flag\": death_flag,\n",
    "            \"dischtime\": disch_time,\n",
    "            \"first_timestamp\": first_timestamp,\n",
    "            \"last_timestamp\": last_timestamp,\n",
    "\n",
    "            # 요청된 7개 컬럼\n",
    "            \"prefix_events_str\": prefix_events_str,\n",
    "            \"current_heart_rate\": json.dumps(hr_arr),\n",
    "            \"current_mean_bp\": json.dumps(bp_arr),\n",
    "            \"target_mortality\": target_mortality,\n",
    "            \"target_next_evt\": json.dumps(next_evt_ids),\n",
    "            \"target_time_to_next\": json.dumps(time_to_next_arr),\n",
    "            \"target_remain_los\": json.dumps(remain_los_arr),\n",
    "        }\n",
    "\n",
    "        records.append(rec)\n",
    "\n",
    "    cohort143 = pd.DataFrame(records)\n",
    "    print(f\"[143] cohort row 수(hadm 기준): {len(cohort143)}\")\n",
    "    return cohort143\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6. MAIN (cohort ver143 구축)\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    # 1) 140 event log 로딩\n",
    "    raw_events = load_event_log(INPUT_EVENT_LOG_PATH)\n",
    "\n",
    "    # 2) Clean: ED/ED_SURR 기준 시작, DISCHARGE/DEATH까지, 너무 짧은 trace 제거\n",
    "    clean_events = clean_event_log(raw_events, min_events_per_case=MIN_EVENTS_PER_CASE)\n",
    "    if clean_events.empty:\n",
    "        print(\"[MAIN] clean_events가 비어 있습니다. 140 이벤트 생성 로직을 다시 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 3) event_name ↔ event_id 매핑 (메모리에서만 사용)\n",
    "    event_id_map = build_event_id_map(clean_events)\n",
    "\n",
    "    # 4) cohort ver143 (hadm 단위 arr 요약) 생성\n",
    "    cohort143 = build_cohort_ver143_arr(clean_events, event_id_map)\n",
    "\n",
    "    # 5) 저장 (최종 출력은 ver143 한 개만)\n",
    "    cohort143.to_csv(COHORT_143_PATH, index=False)\n",
    "    print(f\"[SAVE] cohort ver143 저장 완료: {COHORT_143_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da720c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31a11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
