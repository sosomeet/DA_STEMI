{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697c4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] PPM 데이터 로딩 완료: 14312 rows, 1929 hadm_id\n",
      "[LOAD] current_event_id 고유 개수: 8\n",
      "[LOAD] next_event_id 고유 개수: 9\n",
      "[MAP] 이벤트 종류 개수: 14\n",
      "        event_name  event_id\n",
      "0       ED_ARRIVAL         1\n",
      "1   ECG_STEMI_FLAG         2\n",
      "2        ECG_TAKEN         3\n",
      "3    TROP_POSITIVE         4\n",
      "4       TROP_TAKEN         5\n",
      "5   ANTI_PLT_ADMIN         6\n",
      "6   ANTI_PLT_ORDER         7\n",
      "7        PCI_START         8\n",
      "8     ED_DEPARTURE         9\n",
      "9            DEATH        10\n",
      "10       DISCHARGE        11\n",
      "11      ICU_INTIME        12\n",
      "12     ICU_OUTTIME        13\n",
      "13             EOS        14\n",
      "[WARN] 매핑되지 않은 current_event_id 존재: [0]\n",
      "[WARN] 매핑되지 않은 next_event_id 존재: [0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1824\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1826\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[0;32m   1827\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1829\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03mApply function f in python space\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m    data after applying f\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1885\u001b[0m values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n",
      "Cell \u001b[1;32mIn[3], line 163\u001b[0m, in \u001b[0;36mattach_event_names_and_prefix.<locals>._build_prefix\u001b[1;34m(series)\u001b[0m\n\u001b[0;32m    162\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m--> 163\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(out, index\u001b[38;5;241m=\u001b[39mseries\u001b[38;5;241m.\u001b[39mindex)\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, float found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 211\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] 작업 완료.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 202\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    199\u001b[0m event_id_map \u001b[38;5;241m=\u001b[39m load_event_id_map(EVENT_ID_MAP_PATH)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# 3) event_name / prefix 문자열 부착\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m ppm_with_events \u001b[38;5;241m=\u001b[39m \u001b[43mattach_event_names_and_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mppm_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_id_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# 4) 저장\u001b[39;00m\n\u001b[0;32m    205\u001b[0m ppm_with_events\u001b[38;5;241m.\u001b[39mto_csv(OUTPUT_PPM_WITH_EVENTS_PATH, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 173\u001b[0m, in \u001b[0;36mattach_event_names_and_prefix\u001b[1;34m(ppm_df, event_id_map)\u001b[0m\n\u001b[0;32m    166\u001b[0m ppm_df \u001b[38;5;241m=\u001b[39m ppm_df\u001b[38;5;241m.\u001b[39msort_values(\n\u001b[0;32m    167\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhadm_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix_len\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# 이미 prefix_events_str가 102에서 있었지만,\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# event_id_map 기준으로 다시 만드는 게 더 일관적이라 덮어씀\u001b[39;00m\n\u001b[0;32m    172\u001b[0m ppm_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix_events_str\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 173\u001b[0m     \u001b[43mppm_df\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubject_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhadm_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcurrent_event\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_build_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[BUILD] prefix_events_str 예시:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    181\u001b[0m     ppm_df[\n\u001b[0;32m    182\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhadm_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix_len\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_event\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_event\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix_events_str\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    184\u001b[0m     ]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m    185\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:230\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[0;32m    225\u001b[0m     _apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, examples\u001b[38;5;241m=\u001b[39m_apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    227\u001b[0m     )\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1846\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1836\u001b[0m             )\n\u001b[0;32m   1837\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1838\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[0;32m   1839\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m-> 1846\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj_with_exclusions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 163\u001b[0m, in \u001b[0;36mattach_event_names_and_prefix.<locals>._build_prefix\u001b[1;34m(series)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m series:\n\u001b[0;32m    162\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m--> 163\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(out, index\u001b[38;5;241m=\u001b[39mseries\u001b[38;5;241m.\u001b[39mindex)\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# 0. 경로 및 기본 설정\n",
    "# ==============================\n",
    "\n",
    "# 방금 만든 prefix+feature CSV (경로만 본인 환경에 맞게 수정)\n",
    "INPUT_PPM_PATH = \"./../cohort/cohort_102_recalc_cum.csv\"\n",
    "\n",
    "# ver142에서 이미 만들어 둔 event_id_map\n",
    "EVENT_ID_MAP_PATH = \"./../cohort/cohort_ver142_event_id_map.csv\"\n",
    "\n",
    "OUTPUT_DIR = \"./../cohort\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# event 이름/시퀀스까지 붙인 최종 출력 경로\n",
    "OUTPUT_PPM_WITH_EVENTS_PATH = os.path.join(\n",
    "    OUTPUT_DIR,\n",
    "    \"cohort_ver144_ppm_with_event_names.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 1. 공통 유틸\n",
    "# ==============================\n",
    "\n",
    "def _check_columns(df: pd.DataFrame, required_cols):\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"필수 컬럼 {missing} 이(가) 누락되어 있습니다. 현재 컬럼: {list(df.columns)}\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. PPM prefix 데이터 로딩\n",
    "# ==============================\n",
    "\n",
    "def load_ppm_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    방금 만든 prefix 기반 cohort CSV 로딩.\n",
    "    필수 컬럼(현재 102 버전 기준):\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - prefix_len\n",
    "      - current_event_id\n",
    "      - next_event_id 또는 target_next_evt\n",
    "      - time_since_start_min (있으면 사용)\n",
    "      - target_time_to_next (있으면 time_to_next_min으로 복사)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"입력 PPM 데이터 파일을 찾을 수 없습니다: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # next_event_id 이름이 다를 수 있으므로 보정\n",
    "    if \"next_event_id\" not in df.columns and \"target_next_evt\" in df.columns:\n",
    "        df = df.rename(columns={\"target_next_evt\": \"next_event_id\"})\n",
    "\n",
    "    # 이 스크립트에서 진짜로 필요한 최소 컬럼만 체크\n",
    "    required_cols = [\n",
    "        \"subject_id\",\n",
    "        \"hadm_id\",\n",
    "        \"prefix_len\",\n",
    "        \"current_event_id\",\n",
    "        \"next_event_id\",\n",
    "    ]\n",
    "    _check_columns(df, required_cols)\n",
    "\n",
    "    # time_since_start_min / time_to_next_min 은 있으면 쓰고, 없으면 만들어만 둠\n",
    "    if \"time_since_start_min\" not in df.columns:\n",
    "        df[\"time_since_start_min\"] = np.nan\n",
    "\n",
    "    # 기존 코드 호환을 위해 time_to_next_min 컬럼 생성\n",
    "    if \"time_to_next_min\" not in df.columns:\n",
    "        if \"target_time_to_next\" in df.columns:\n",
    "            df[\"time_to_next_min\"] = df[\"target_time_to_next\"]\n",
    "        else:\n",
    "            df[\"time_to_next_min\"] = np.nan\n",
    "\n",
    "    # prefix 데이터 특성상 prefix_len 순서대로 정렬\n",
    "    df = df.sort_values(\n",
    "        by=[\"subject_id\", \"hadm_id\", \"prefix_len\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(f\"[LOAD] PPM 데이터 로딩 완료: {len(df)} rows, {df['hadm_id'].nunique()} hadm_id\")\n",
    "    print(f\"[LOAD] current_event_id 고유 개수: {df['current_event_id'].nunique()}\")\n",
    "    print(f\"[LOAD] next_event_id 고유 개수: {df['next_event_id'].nunique()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. event_id_map 로딩\n",
    "# ==============================\n",
    "\n",
    "def load_event_id_map(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ver142에서 만든 event_id_map CSV 로딩.\n",
    "    필수 컬럼:\n",
    "      - event_name\n",
    "      - event_id\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"event_id_map 파일을 찾을 수 없습니다: {path}\")\n",
    "\n",
    "    m = pd.read_csv(path)\n",
    "    required_cols = [\"event_name\", \"event_id\"]\n",
    "    _check_columns(m, required_cols)\n",
    "\n",
    "    # event_id를 int로 보정\n",
    "    m[\"event_id\"] = m[\"event_id\"].astype(int)\n",
    "\n",
    "    print(f\"[MAP] 이벤트 종류 개수: {len(m)}\")\n",
    "    print(m.sort_values(\"event_id\"))\n",
    "    return m\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. event_id → event_name 매핑 및 prefix 문자열 생성\n",
    "# ==============================\n",
    "\n",
    "def attach_event_names_and_prefix(ppm_df: pd.DataFrame,\n",
    "                                  event_id_map: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - current_event_id / next_event_id → event_name 매핑\n",
    "    - prefix_len 기준으로 prefix_events_str(이름 기반 시퀀스) 생성\n",
    "    - full_trace_len 계산\n",
    "    \"\"\"\n",
    "    id_to_name = dict(zip(event_id_map[\"event_id\"], event_id_map[\"event_name\"]))\n",
    "\n",
    "    # 1) 현재/다음 이벤트 이름 매핑\n",
    "    ppm_df[\"current_event\"] = ppm_df[\"current_event_id\"].map(id_to_name)\n",
    "    ppm_df[\"next_event\"] = ppm_df[\"next_event_id\"].map(id_to_name)\n",
    "\n",
    "    # 매핑 안 된 event_id가 있는지 체크\n",
    "    unknown_current = ppm_df[ppm_df[\"current_event\"].isna()][\"current_event_id\"].unique()\n",
    "    unknown_next = ppm_df[ppm_df[\"next_event\"].isna()][\"next_event_id\"].unique()\n",
    "\n",
    "    if len(unknown_current) > 0:\n",
    "        print(f\"[WARN] 매핑되지 않은 current_event_id 존재: {unknown_current}\")\n",
    "    if len(unknown_next) > 0:\n",
    "        print(f\"[WARN] 매핑되지 않은 next_event_id 존재: {unknown_next}\")\n",
    "\n",
    "    # 2) full_trace_len 계산 (각 hadm_id 내에서 최대 prefix_len)\n",
    "    ppm_df[\"full_trace_len\"] = ppm_df.groupby(\n",
    "        [\"subject_id\", \"hadm_id\"]\n",
    "    )[\"prefix_len\"].transform(\"max\")\n",
    "\n",
    "    # 3) prefix_events_str (이름 기반 시퀀스) 생성\n",
    "    #    각 케이스(subject_id + hadm_id) 별로 prefix_len 순으로 정렬 후\n",
    "    #    current_event를 누적하여 \"ED_ARRIVAL>ECG_TAKEN>...\" 형태로 만듦\n",
    "\n",
    "    def _build_prefix(series: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        series: 한 케이스 내 current_event(이름) 시퀀스.\n",
    "        각 row마다 '여기까지의 이벤트 시퀀스'를 문자열로 반환.\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        acc = []\n",
    "        for v in series:\n",
    "            acc.append(v)\n",
    "            out.append(\">\".join(acc))\n",
    "        return pd.Series(out, index=series.index)\n",
    "\n",
    "    ppm_df = ppm_df.sort_values(\n",
    "        [\"subject_id\", \"hadm_id\", \"prefix_len\"]\n",
    "    )\n",
    "\n",
    "    # 이미 prefix_events_str가 102에서 있었지만,\n",
    "    # event_id_map 기준으로 다시 만드는 게 더 일관적이라 덮어씀\n",
    "    ppm_df[\"prefix_events_str\"] = (\n",
    "        ppm_df\n",
    "        .groupby([\"subject_id\", \"hadm_id\"])[\"current_event\"]\n",
    "        .apply(_build_prefix)\n",
    "        .reset_index(level=[0, 1], drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\n[BUILD] prefix_events_str 예시:\")\n",
    "    print(\n",
    "        ppm_df[\n",
    "            [\"subject_id\", \"hadm_id\", \"prefix_len\",\n",
    "             \"current_event\", \"next_event\", \"prefix_events_str\"]\n",
    "        ].head(20)\n",
    "    )\n",
    "\n",
    "    return ppm_df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. MAIN\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    # 1) prefix 기반 PPM 데이터 로딩\n",
    "    ppm_df = load_ppm_dataset(INPUT_PPM_PATH)\n",
    "\n",
    "    # 2) event_id_map 로딩\n",
    "    event_id_map = load_event_id_map(EVENT_ID_MAP_PATH)\n",
    "\n",
    "    # 3) event_name / prefix 문자열 부착\n",
    "    ppm_with_events = attach_event_names_and_prefix(ppm_df, event_id_map)\n",
    "\n",
    "    # 4) 저장\n",
    "    ppm_with_events.to_csv(OUTPUT_PPM_WITH_EVENTS_PATH, index=False)\n",
    "    print(f\"\\n[SAVE] 이벤트 이름/시퀀스 포함 PPM 데이터 저장: {OUTPUT_PPM_WITH_EVENTS_PATH}\")\n",
    "    print(\"[INFO] 작업 완료.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2444b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
