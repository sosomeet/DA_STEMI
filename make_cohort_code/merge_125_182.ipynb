{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcfe8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14312, 40)\n",
      "   subject_id  hadm_id_x  age_x  gender_x                    race_x  \\\n",
      "0    13647833   20006266     40         1  ASIAN - SOUTH EAST ASIAN   \n",
      "1    13647833   20006266     40         1  ASIAN - SOUTH EAST ASIAN   \n",
      "2    13647833   20006266     40         1  ASIAN - SOUTH EAST ASIAN   \n",
      "3    13647833   20006266     40         1  ASIAN - SOUTH EAST ASIAN   \n",
      "4    13647833   20006266     40         1  ASIAN - SOUTH EAST ASIAN   \n",
      "\n",
      "   prefix_len  time_since_ed  time_since_last  is_night  cum_ecg_cnt  ...  \\\n",
      "0           1            0.0                0         0            0  ...   \n",
      "1           2            0.0         27504819         1            1  ...   \n",
      "2           3            0.0              654         0            1  ...   \n",
      "3           4          626.0              626         0            1  ...   \n",
      "4           5         1240.0              614         0            1  ...   \n",
      "\n",
      "   age_y  gender_y                    race_y  arrival_transport_y  cci_score  \\\n",
      "0     40         1  ASIAN - SOUTH EAST ASIAN                    1          0   \n",
      "1     40         1  ASIAN - SOUTH EAST ASIAN                    1          0   \n",
      "2     40         1  ASIAN - SOUTH EAST ASIAN                    1          0   \n",
      "3     40         1  ASIAN - SOUTH EAST ASIAN                    1          0   \n",
      "4     40         1  ASIAN - SOUTH EAST ASIAN                    1          0   \n",
      "\n",
      "   hfrs_score  door_to_ecg  door_to_trop  door_to_anti  door_to_pci  \n",
      "0         0.0         -1.0         626.0          -1.0         -1.0  \n",
      "1         0.0         -1.0         626.0          -1.0         -1.0  \n",
      "2         0.0         -1.0         626.0          -1.0         -1.0  \n",
      "3         0.0         -1.0         626.0          -1.0         -1.0  \n",
      "4         0.0         -1.0         626.0          -1.0         -1.0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "path_125 = \"./../cohort/cohort_ver125_feature_matrix_repaired.csv\"\n",
    "path_182 = \"./../cohort/cohort_ver182_winsor_99p.csv\"\n",
    "\n",
    "# CSV 로드\n",
    "df125 = pd.read_csv(path_125)\n",
    "df182 = pd.read_csv(path_182)\n",
    "\n",
    "df182_unique = df182.drop_duplicates(subset=['subject_id'], keep='first')\n",
    "\n",
    "# subject_id 기준 병합 (125 기준으로 유지)\n",
    "df_merged = df125.merge(df182_unique, on='subject_id', how='left')\n",
    "\n",
    "# 저장\n",
    "df_merged.to_csv(\"cohort_101_merged_125_182.csv\", index=False)\n",
    "\n",
    "print(df_merged.shape)\n",
    "print(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3adc11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id   hadm_id  prefix_len  cum_ecg_cnt  cum_stemi_cnt  cum_trop_cnt\n",
      "0     10000764  27897940           1            0              0             0\n",
      "1     10000764  27897940           2            0              0             0\n",
      "2     10000764  27897940           3            1              1             0\n",
      "3     10000764  27897940           4            2              1             0\n",
      "4     10000764  27897940           5            2              1             1\n",
      "5     10000764  27897940           6            3              1             1\n",
      "6     10000764  27897940           7            4              1             1\n",
      "7     10000764  27897940           8            5              1             1\n",
      "8     10000764  27897940           9            6              1             1\n",
      "9     10000764  27897940          10            7              1             1\n",
      "10    10000764  27897940          11            8              1             1\n",
      "11    10000764  27897940          12            8              1             1\n",
      "12    10010058  26359957           1            0              0             0\n",
      "13    10010058  26359957           2            1              1             0\n",
      "14    10010058  26359957           3            1              1             0\n",
      "15    10010058  26359957           4            1              1             1\n",
      "16    10010058  26359957           5            1              1             2\n",
      "17    10010058  26359957           6            2              1             2\n",
      "18    10010058  26359957           7            3              1             2\n",
      "19    10010058  26359957           8            4              1             2\n",
      "20    10010058  26359957           9            4              1             2\n",
      "21    10010058  26359957          10            4              1             2\n",
      "22    10012438  22764825           1            0              0             0\n",
      "23    10012438  22764825           2            0              0             0\n",
      "24    10012438  22764825           3            0              0             1\n",
      "25    10012438  22764825           4            0              0             2\n",
      "26    10012438  22764825           5            0              0             2\n",
      "27    10012438  22764825           6            0              0             2\n",
      "28    10013310  21243435           1            0              0             0\n",
      "29    10013310  21243435           2            1              1             0\n",
      "저장 완료: ./../cohort/cohort_102_recalc_cum.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 병합된 파일 로드\n",
    "path_merged = \"./../cohort/cohort_101_merged_125_182.csv\"\n",
    "df = pd.read_csv(path_merged)\n",
    "\n",
    "# 2. prefix 순서대로 정렬 (필요에 따라 정렬 기준 조정 가능)\n",
    "df = df.sort_values([\"subject_id\", \"hadm_id\", \"prefix_len\"]).reset_index(drop=True)\n",
    "\n",
    "# 3. 기존 cum_ 컬럼은 버리고 새로 계산할 준비\n",
    "for col in [\"cum_ecg_cnt\", \"cum_stemi_cnt\", \"cum_trop_cnt\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# 4. 이벤트 플래그 정의\n",
    "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
    "# 이 부분은 네 데이터에 맞게 조건만 조정하면 됨.\n",
    "\n",
    "# (예시 1) current_event_id가 문자열인 경우\n",
    "#   - ECG_TAKEN, ECG_STEMI_FLAG, TROP_TAKEN, TROP_POSITIVE 같은 이름일 때\n",
    "# df[\"is_ecg\"]       = df[\"current_event_id\"].isin([\"ECG_TAKEN\", \"ECG_STEMI_FLAG\"]).astype(int)\n",
    "# df[\"is_stemi_ecg\"] = (df[\"current_event_id\"] == \"ECG_STEMI_FLAG\").astype(int)\n",
    "# df[\"is_trop\"]      = df[\"current_event_id\"].isin([\"TROP_TAKEN\", \"TROP_POSITIVE\"]).astype(int)\n",
    "\n",
    "# (예시 2) current_event_id가 숫자 코드이고, 예를 들어\n",
    "#   1: ED_ARRIVAL, 2: ECG_TAKEN, 3: ECG_STEMI_FLAG, 4: TROP_TAKEN, 5: TROP_POSITIVE, ...\n",
    "# 라고 가정한다면 (실제 코드에 맞게 숫자만 바꿔주면 됨)\n",
    "df[\"is_ecg\"]       = df[\"current_event_id\"].isin([2, 3]).astype(int)   # ECG_TAKEN + ECG_STEMI_FLAG\n",
    "df[\"is_stemi_ecg\"] = df[\"current_event_id\"].eq(3).astype(int)         # ECG_STEMI_FLAG\n",
    "df[\"is_trop\"]      = df[\"current_event_id\"].isin([4, 5]).astype(int)  # TROP_TAKEN + TROP_POSITIVE\n",
    "\n",
    "# 만약 따로 이벤트 코드가 없고, stemi_flag / trop_pos_flag만 있다면 예를 들어:\n",
    "# df[\"is_ecg\"]       = (df[\"stemi_flag\"].notna()).astype(int)  # ECG row에서만 stemi_flag가 세팅되어 있다면\n",
    "# df[\"is_stemi_ecg\"] = (df[\"stemi_flag\"] == 1).astype(int)\n",
    "# df[\"is_trop\"]      = (df[\"trop_pos_flag\"].notna()).astype(int)\n",
    "\n",
    "# ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
    "# 여기까지 조건은 네 데이터 구조에 맞게 골라서/수정해서 사용\n",
    "\n",
    "# 5. 그룹별 누적 합 (prefix 기반 누적)\n",
    "group_keys = [\"subject_id\", \"hadm_id\"]\n",
    "\n",
    "df[\"cum_ecg_cnt\"]   = df.groupby(group_keys)[\"is_ecg\"].cumsum()\n",
    "df[\"cum_stemi_cnt\"] = df.groupby(group_keys)[\"is_stemi_ecg\"].cumsum()\n",
    "df[\"cum_trop_cnt\"]  = df.groupby(group_keys)[\"is_trop\"].cumsum()\n",
    "\n",
    "# 6. 임시 플래그 컬럼 제거\n",
    "df = df.drop(columns=[\"is_ecg\", \"is_stemi_ecg\", \"is_trop\"])\n",
    "\n",
    "# 7. 저장\n",
    "out_path = \"./../cohort/cohort_102_recalc_cum.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(df[[\"subject_id\", \"hadm_id\", \"prefix_len\",\n",
    "          \"cum_ecg_cnt\", \"cum_stemi_cnt\", \"cum_trop_cnt\"]].head(30))\n",
    "print(\"저장 완료:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9e60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
