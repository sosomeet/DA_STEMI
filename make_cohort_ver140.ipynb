{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596e996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "697c4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COHORT] 원래 STEMI 입원 후보 row 수: 1929\n",
      "[COHORT] subject_id 기준 '첫 STEMI 입원'만 남긴 row 수: 1878\n",
      "[LOAD] admissions, patients, icustays...\n",
      "[LOAD] edstays (있으면 로딩)...\n",
      "[LOAD] labevents_troponin ...\n",
      "[LOAD] labevents_troponin.csv 로딩: ../../data/MIMIC4-hosp-icu\\labevents_troponin.csv\n",
      "[LOAD] procedures_icd, prescriptions, ECG machine_measurements...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26072\\3807578963.py:140: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prescriptions = pd.read_csv(os.path.join(HOSP_DIR, \"prescriptions.csv\"))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26072\\3807578963.py:141: DtypeWarning: Columns (16,17,18,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ecg = pd.read_csv(os.path.join(ECG_DIR, \"machine_measurements.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 최종 STEMI cohort size (첫 입원 기준): 1878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26072\\3807578963.py:582: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  all_events.groupby(\"hadm_id\", group_keys=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SUMMARY] 140 event log 요약\n",
      "  전체 이벤트 row 수: 38674\n",
      "  hadm_id 수: 1878 / 코호트 hadm_id 수: 1878\n",
      "  hadm당 이벤트 개수 통계:\n",
      "count    1878.000000\n",
      "mean       20.593184\n",
      "std        15.284606\n",
      "min         1.000000\n",
      "25%        11.000000\n",
      "50%        18.000000\n",
      "75%        25.000000\n",
      "max       219.000000\n",
      "Name: event_name, dtype: float64\n",
      "[SAVE] 140 버전 event log 저장 완료: ./cohort\\cohort_ver140_event_log.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================\n",
    "# 0. 경로 및 기본 설정\n",
    "# ==============================\n",
    "\n",
    "COHORT_PATH = \"./cohort/cohort_ver50_only_subject_id.csv\"\n",
    "\n",
    "HOSP_DIR = \"../../data/MIMIC4-hosp-icu\"\n",
    "ICU_DIR = \"../../data/MIMIC4-hosp-icu\"\n",
    "ED_DIR = \"../../data/mimic-iv-ed/ed\"\n",
    "ECG_DIR = \"../../data/mimic-iv-ecg\"\n",
    "\n",
    "OUTPUT_DIR = \"./cohort\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 140 버전 event log 출력 경로\n",
    "EVENT_LOG_140_PATH = os.path.join(OUTPUT_DIR, \"cohort_ver140_event_log.csv\")\n",
    "\n",
    "# Troponin 양성 기준\n",
    "TROP_POS_THRESHOLD = 0.04\n",
    "\n",
    "# PCI ICD 코드 prefix\n",
    "PCI_ICD9_PREFIXES = [\"00.66\", \"36.0\"]\n",
    "PCI_ICD10_PREFIXES = [\"027\", \"929\"]\n",
    "\n",
    "# 항혈소판제 이름 리스트\n",
    "ANTI_PLT_DRUGS = [\"aspirin\", \"clopidogrel\", \"ticagrelor\", \"prasugrel\"]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 1. 공통 유틸\n",
    "# ==============================\n",
    "\n",
    "def _to_datetime(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    지정된 컬럼들을 datetime으로 변환.\n",
    "    연도 이상치는 그대로 허용하고, 파싱 실패는 NaT로 둔다.\n",
    "    \"\"\"\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _attrs_to_json(attrs: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    attributes dict를 JSON 문자열로 변환.\n",
    "    NaN은 None으로 치환.\n",
    "    \"\"\"\n",
    "    clean = {}\n",
    "    for k, v in attrs.items():\n",
    "        if isinstance(v, float) and pd.isna(v):\n",
    "            clean[k] = None\n",
    "        else:\n",
    "            clean[k] = v\n",
    "    return json.dumps(clean, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. Cohort 및 원본 테이블 로딩\n",
    "# ==============================\n",
    "\n",
    "def load_labevents_troponin() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Troponin 전용 labevents_troponin.csv 로딩.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        os.path.join(HOSP_DIR, \"labevents_troponin.csv\"),\n",
    "        \"./labevents_troponin.csv\",\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            print(f\"[LOAD] labevents_troponin.csv 로딩: {p}\")\n",
    "            return pd.read_csv(p)\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"labevents_troponin.csv 파일을 찾을 수 없습니다.\\n\"\n",
    "        f\"다음 경로 중 하나에 존재해야 합니다.\\n{candidates}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def load_cohort_first_stemi_admission(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    STEMI 대상 환자 코호트 로딩.\n",
    "    - 입력: subject_id, hadm_id (중복 가능)\n",
    "    - 처리: admissions.admittime 기준으로 각 subject_id당 가장 이른 hadm_id 하나만 남긴다.\n",
    "    \"\"\"\n",
    "    cohort_raw = pd.read_csv(path)\n",
    "\n",
    "    if \"subject_id\" not in cohort_raw.columns:\n",
    "        raise ValueError(f\"cohort 파일에 subject_id 컬럼이 없습니다. 현재 컬럼: {list(cohort_raw.columns)}\")\n",
    "    if \"hadm_id\" not in cohort_raw.columns:\n",
    "        raise ValueError(\n",
    "            \"cohort 파일에 hadm_id 컬럼이 없습니다.\\n\"\n",
    "            \"STEMI 분석은 hadm_id(입원 단위) 기준으로 해야 합니다.\\n\"\n",
    "            \"cohort_ver50_only_subject_id.csv를 subject_id, hadm_id 두 컬럼을 포함하도록 다시 만들어 주세요.\"\n",
    "        )\n",
    "\n",
    "    cohort_all = cohort_raw[[\"subject_id\", \"hadm_id\"]].drop_duplicates()\n",
    "\n",
    "    admissions_path = os.path.join(HOSP_DIR, \"admissions.csv\")\n",
    "    admissions = pd.read_csv(admissions_path)[[\"subject_id\", \"hadm_id\", \"admittime\"]]\n",
    "    admissions = _to_datetime(admissions, [\"admittime\"])\n",
    "\n",
    "    merged = cohort_all.merge(admissions, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "    merged = merged.sort_values([\"subject_id\", \"admittime\"])\n",
    "\n",
    "    first_stemi_adm = merged.groupby(\"subject_id\", as_index=False).head(1)\n",
    "    cohort_final = first_stemi_adm[[\"subject_id\", \"hadm_id\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    print(f\"[COHORT] 원래 STEMI 입원 후보 row 수: {len(cohort_all)}\")\n",
    "    print(f\"[COHORT] subject_id 기준 '첫 STEMI 입원'만 남긴 row 수: {len(cohort_final)}\")\n",
    "\n",
    "    return cohort_final\n",
    "\n",
    "\n",
    "def load_source_tables() -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    MIMIC-IV 원본 테이블 로딩.\n",
    "    \"\"\"\n",
    "    print(\"[LOAD] admissions, patients, icustays...\")\n",
    "    admissions = pd.read_csv(os.path.join(HOSP_DIR, \"admissions.csv\"))\n",
    "    patients = pd.read_csv(os.path.join(HOSP_DIR, \"patients.csv\"))\n",
    "    icustays = pd.read_csv(os.path.join(ICU_DIR, \"icustays.csv\"))\n",
    "\n",
    "    print(\"[LOAD] edstays (있으면 로딩)...\")\n",
    "    edstays_path = os.path.join(ED_DIR, \"edstays.csv\")\n",
    "    edstays = pd.read_csv(edstays_path) if os.path.exists(edstays_path) else None\n",
    "\n",
    "    print(\"[LOAD] labevents_troponin ...\")\n",
    "    labevents_trop = load_labevents_troponin()\n",
    "\n",
    "    print(\"[LOAD] procedures_icd, prescriptions, ECG machine_measurements...\")\n",
    "    procedures_icd = pd.read_csv(os.path.join(HOSP_DIR, \"procedures_icd.csv\"))\n",
    "    prescriptions = pd.read_csv(os.path.join(HOSP_DIR, \"prescriptions.csv\"))\n",
    "    ecg = pd.read_csv(os.path.join(ECG_DIR, \"machine_measurements.csv\"))\n",
    "\n",
    "    return {\n",
    "        \"admissions\": admissions,\n",
    "        \"patients\": patients,\n",
    "        \"icustays\": icustays,\n",
    "        \"edstays\": edstays,\n",
    "        \"labevents_trop\": labevents_trop,\n",
    "        \"procedures_icd\": procedures_icd,\n",
    "        \"prescriptions\": prescriptions,\n",
    "        \"ecg\": ecg,\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3. 개별 Event 생성 함수들\n",
    "# ==============================\n",
    "\n",
    "def build_ed_events(cohort: pd.DataFrame,\n",
    "                    edstays: pd.DataFrame,\n",
    "                    admissions: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ED_ARRIVAL, ED_DEPARTURE, ED_ARRIVAL_SURR 이벤트 생성.\n",
    "\n",
    "    - edstays 기준으로 ED_ARRIVAL / ED_DEPARTURE 생성 (있으면 그대로 사용)\n",
    "    - 해당 hadm에 ED 이벤트가 전혀 없으면 admissions.admittime으로\n",
    "      ED_ARRIVAL_SURR 생성\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    hadm_with_ed = set()\n",
    "\n",
    "    # 1) 실제 ED_ARRIVAL / ED_DEPARTURE\n",
    "    if edstays is not None:\n",
    "        ed = edstays.merge(cohort, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "        ed = _to_datetime(ed, [\"intime\", \"outtime\"])\n",
    "\n",
    "        for _, row in ed.iterrows():\n",
    "            hid = row[\"hadm_id\"]\n",
    "            sid = row[\"subject_id\"]\n",
    "\n",
    "            if pd.notnull(row.get(\"intime\")):\n",
    "                events.append({\n",
    "                    \"subject_id\": sid,\n",
    "                    \"hadm_id\": hid,\n",
    "                    \"event_name\": \"ED_ARRIVAL\",\n",
    "                    \"timestamp\": row[\"intime\"],\n",
    "                    \"attributes\": _attrs_to_json({}),\n",
    "                })\n",
    "                hadm_with_ed.add(hid)\n",
    "\n",
    "            if pd.notnull(row.get(\"outtime\")):\n",
    "                events.append({\n",
    "                    \"subject_id\": sid,\n",
    "                    \"hadm_id\": hid,\n",
    "                    \"event_name\": \"ED_DEPARTURE\",\n",
    "                    \"timestamp\": row[\"outtime\"],\n",
    "                    \"attributes\": _attrs_to_json({}),\n",
    "                })\n",
    "                hadm_with_ed.add(hid)\n",
    "\n",
    "    # 2) surrogate ED_ARRIVAL (ED가 전혀 없는 hadm에 대해)\n",
    "    adm = admissions.merge(cohort, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "    adm = _to_datetime(adm, [\"admittime\"])\n",
    "\n",
    "    for _, row in adm.iterrows():\n",
    "        hid = row[\"hadm_id\"]\n",
    "        sid = row[\"subject_id\"]\n",
    "        if hid in hadm_with_ed:\n",
    "            continue  # 이미 ED 이벤트 있음\n",
    "\n",
    "        admt = row.get(\"admittime\")\n",
    "        if pd.isna(admt):\n",
    "            continue\n",
    "\n",
    "        events.append({\n",
    "            \"subject_id\": sid,\n",
    "            \"hadm_id\": hid,\n",
    "            \"event_name\": \"ED_ARRIVAL_SURR\",\n",
    "            \"timestamp\": admt,\n",
    "            \"attributes\": _attrs_to_json({\"source\": \"admittime\"}),\n",
    "        })\n",
    "        hadm_with_ed.add(hid)\n",
    "\n",
    "    if not events:\n",
    "        return pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"event_name\", \"timestamp\", \"attributes\"])\n",
    "\n",
    "    ed_events = pd.DataFrame(events)\n",
    "    ed_events = _to_datetime(ed_events, [\"timestamp\"])\n",
    "    return ed_events\n",
    "\n",
    "\n",
    "def build_admission_events(cohort: pd.DataFrame,\n",
    "                           admissions: pd.DataFrame,\n",
    "                           patients: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    DISCHARGE, DEATH 이벤트 생성.\n",
    "    \"\"\"\n",
    "    adm = admissions.merge(cohort, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "    adm = _to_datetime(adm, [\"admittime\", \"dischtime\"])\n",
    "    pat = _to_datetime(patients.copy(), [\"dod\"])\n",
    "\n",
    "    adm = adm.merge(pat[[\"subject_id\", \"dod\"]], on=\"subject_id\", how=\"left\")\n",
    "\n",
    "    events = []\n",
    "    for _, row in adm.iterrows():\n",
    "        sid = row[\"subject_id\"]\n",
    "        hid = row[\"hadm_id\"]\n",
    "        if pd.notnull(row.get(\"dischtime\")):\n",
    "            events.append({\n",
    "                \"subject_id\": sid,\n",
    "                \"hadm_id\": hid,\n",
    "                \"event_name\": \"DISCHARGE\",\n",
    "                \"timestamp\": row[\"dischtime\"],\n",
    "                \"attributes\": _attrs_to_json({}),\n",
    "            })\n",
    "        if pd.notnull(row.get(\"dod\")):\n",
    "            events.append({\n",
    "                \"subject_id\": sid,\n",
    "                \"hadm_id\": hid,\n",
    "                \"event_name\": \"DEATH\",\n",
    "                \"timestamp\": row[\"dod\"],\n",
    "                \"attributes\": _attrs_to_json({}),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "\n",
    "def build_icu_events(cohort: pd.DataFrame, icustays: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ICU_INTIME, ICU_OUTTIME 이벤트 생성.\n",
    "    \"\"\"\n",
    "    icu = icustays.merge(cohort, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "    icu = _to_datetime(icu, [\"intime\", \"outtime\"])\n",
    "\n",
    "    events = []\n",
    "    for _, row in icu.iterrows():\n",
    "        sid = row[\"subject_id\"]\n",
    "        hid = row[\"hadm_id\"]\n",
    "        attrs = {\n",
    "            \"first_careunit\": row.get(\"first_careunit\", None),\n",
    "            \"last_careunit\": row.get(\"last_careunit\", None),\n",
    "            \"stay_id\": row.get(\"stay_id\", None),\n",
    "        }\n",
    "        if pd.notnull(row.get(\"intime\")):\n",
    "            events.append({\n",
    "                \"subject_id\": sid,\n",
    "                \"hadm_id\": hid,\n",
    "                \"event_name\": \"ICU_INTIME\",\n",
    "                \"timestamp\": row[\"intime\"],\n",
    "                \"attributes\": _attrs_to_json(attrs),\n",
    "            })\n",
    "        if pd.notnull(row.get(\"outtime\")):\n",
    "            events.append({\n",
    "                \"subject_id\": sid,\n",
    "                \"hadm_id\": hid,\n",
    "                \"event_name\": \"ICU_OUTTIME\",\n",
    "                \"timestamp\": row[\"outtime\"],\n",
    "                \"attributes\": _attrs_to_json(attrs),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "\n",
    "def build_troponin_events(cohort: pd.DataFrame,\n",
    "                          labevents_trop: pd.DataFrame,\n",
    "                          positive_threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    TROP_TAKEN, TROP_POSITIVE 이벤트 생성.\n",
    "    \"\"\"\n",
    "    lab = labevents_trop.merge(cohort, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "    lab = _to_datetime(lab, [\"charttime\"])\n",
    "\n",
    "    events = []\n",
    "\n",
    "    # TROP_TAKEN\n",
    "    for _, row in lab.iterrows():\n",
    "        if pd.notnull(row.get(\"charttime\")):\n",
    "            attrs = {\n",
    "                \"itemid\": row.get(\"itemid\", None),\n",
    "                \"valuenum\": row.get(\"valuenum\", None),\n",
    "                \"value\": row.get(\"value\", None),\n",
    "                \"flag\": row.get(\"flag\", None),\n",
    "            }\n",
    "            events.append({\n",
    "                \"subject_id\": row[\"subject_id\"],\n",
    "                \"hadm_id\": row[\"hadm_id\"],\n",
    "                \"event_name\": \"TROP_TAKEN\",\n",
    "                \"timestamp\": row[\"charttime\"],\n",
    "                \"attributes\": _attrs_to_json(attrs),\n",
    "            })\n",
    "\n",
    "    # TROP_POSITIVE: hadm_id 기준 첫 양성\n",
    "    if \"valuenum\" in lab.columns:\n",
    "        lab_pos = lab[lab[\"valuenum\"] >= positive_threshold].copy()\n",
    "        lab_pos = lab_pos.dropna(subset=[\"charttime\"])\n",
    "        lab_pos_sorted = lab_pos.sort_values([\"subject_id\", \"hadm_id\", \"charttime\"])\n",
    "        first_pos = lab_pos_sorted.groupby([\"subject_id\", \"hadm_id\"], as_index=False).head(1)\n",
    "\n",
    "        for _, row in first_pos.iterrows():\n",
    "            attrs = {\n",
    "                \"itemid\": row.get(\"itemid\", None),\n",
    "                \"valuenum\": row.get(\"valuenum\", None),\n",
    "                \"value\": row.get(\"value\", None),\n",
    "                \"flag\": row.get(\"flag\", None),\n",
    "            }\n",
    "            events.append({\n",
    "                \"subject_id\": row[\"subject_id\"],\n",
    "                \"hadm_id\": row[\"hadm_id\"],\n",
    "                \"event_name\": \"TROP_POSITIVE\",\n",
    "                \"timestamp\": row[\"charttime\"],\n",
    "                \"attributes\": _attrs_to_json(attrs),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "\n",
    "def build_ecg_events(cohort: pd.DataFrame, ecg: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ECG_TAKEN, ECG_STEMI_FLAG 이벤트 생성.\n",
    "    machine_measurements.csv: 보통 subject_id만 있으므로\n",
    "    cohort에서 subject_id→hadm_id 매핑을 붙여 사용.\n",
    "    \"\"\"\n",
    "    ecg_c = ecg.copy()\n",
    "\n",
    "    # 시간 컬럼 통일\n",
    "    if \"charttime\" not in ecg_c.columns:\n",
    "        if \"ecg_time\" in ecg_c.columns:\n",
    "            ecg_c = ecg_c.rename(columns={\"ecg_time\": \"charttime\"})\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"ECG 데이터에 charttime/ecg_time 둘 다 없습니다. 시간 컬럼을 확인해 주세요.\"\n",
    "            )\n",
    "\n",
    "    subj_hadm_map = cohort[[\"subject_id\", \"hadm_id\"]].drop_duplicates()\n",
    "    ecg_c = ecg_c.merge(subj_hadm_map, on=\"subject_id\", how=\"inner\")\n",
    "    ecg_c = _to_datetime(ecg_c, [\"charttime\"])\n",
    "\n",
    "    def has_stemi_flag(row) -> bool:\n",
    "        mm = str(row.get(\"machine_measurements\", \"\")).upper()\n",
    "        reports = []\n",
    "        for i in range(30):\n",
    "            col = f\"report_{i}\"\n",
    "            if col in row.index:\n",
    "                reports.append(str(row.get(col, \"\")))\n",
    "        rep_text = \" \".join(reports).upper()\n",
    "        text = mm + \" \" + rep_text\n",
    "\n",
    "        if \"STEMI\" in text:\n",
    "            return True\n",
    "        if \"ST ELEVATION\" in text:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    ecg_c[\"is_stemi\"] = ecg_c.apply(has_stemi_flag, axis=1)\n",
    "\n",
    "    events = []\n",
    "    for _, row in ecg_c.iterrows():\n",
    "        ts = row.get(\"charttime\")\n",
    "        if pd.isna(ts):\n",
    "            continue\n",
    "\n",
    "        events.append({\n",
    "            \"subject_id\": row[\"subject_id\"],\n",
    "            \"hadm_id\": row[\"hadm_id\"],\n",
    "            \"event_name\": \"ECG_TAKEN\",\n",
    "            \"timestamp\": ts,\n",
    "            \"attributes\": _attrs_to_json({}),\n",
    "        })\n",
    "\n",
    "        if row[\"is_stemi\"]:\n",
    "            events.append({\n",
    "                \"subject_id\": row[\"subject_id\"],\n",
    "                \"hadm_id\": row[\"hadm_id\"],\n",
    "                \"event_name\": \"ECG_STEMI_FLAG\",\n",
    "                \"timestamp\": ts,\n",
    "                \"attributes\": _attrs_to_json({}),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "\n",
    "def build_pci_events(cohort: pd.DataFrame,\n",
    "                     procedures_icd: pd.DataFrame,\n",
    "                     pci_icd9_prefixes: List[str],\n",
    "                     pci_icd10_prefixes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PCI_START 이벤트 생성.\n",
    "    \"\"\"\n",
    "    proc = procedures_icd.merge(cohort, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "    proc = _to_datetime(proc, [\"chartdate\"])\n",
    "\n",
    "    def is_pci(code: Any, version: Any) -> bool:\n",
    "        if pd.isna(code):\n",
    "            return False\n",
    "        code_str = str(code)\n",
    "        if version == 9:\n",
    "            return any(code_str.startswith(p) for p in pci_icd9_prefixes)\n",
    "        elif version == 10:\n",
    "            return any(code_str.startswith(p) for p in pci_icd10_prefixes)\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    proc[\"is_pci\"] = proc.apply(\n",
    "        lambda r: is_pci(r.get(\"icd_code\", None), r.get(\"icd_version\", None)), axis=1\n",
    "    )\n",
    "    pci_rows = proc[proc[\"is_pci\"]].copy()\n",
    "\n",
    "    events = []\n",
    "    for _, row in pci_rows.iterrows():\n",
    "        ts = row.get(\"chartdate\")\n",
    "        if pd.isna(ts):\n",
    "            continue\n",
    "        attrs = {\n",
    "            \"icd_code\": row.get(\"icd_code\", None),\n",
    "            \"icd_version\": row.get(\"icd_version\", None),\n",
    "        }\n",
    "        events.append({\n",
    "            \"subject_id\": row[\"subject_id\"],\n",
    "            \"hadm_id\": row[\"hadm_id\"],\n",
    "            \"event_name\": \"PCI_START\",\n",
    "            \"timestamp\": ts,\n",
    "            \"attributes\": _attrs_to_json(attrs),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "\n",
    "def build_antiplatelet_events(cohort: pd.DataFrame,\n",
    "                              prescriptions: pd.DataFrame,\n",
    "                              drug_name_list: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ANTI_PLT_ORDER, ANTI_PLT_ADMIN 이벤트 생성.\n",
    "    \"\"\"\n",
    "    rx = prescriptions.merge(cohort, on=[\"subject_id\", \"hadm_id\"], how=\"inner\")\n",
    "    rx = _to_datetime(rx, [\"starttime\", \"stoptime\"])\n",
    "\n",
    "    drug_lower_list = [d.lower() for d in drug_name_list]\n",
    "    rx[\"drug_lower\"] = rx[\"drug\"].astype(str).str.lower()\n",
    "    rx = rx[rx[\"drug_lower\"].isin(drug_lower_list)]\n",
    "\n",
    "    events = []\n",
    "    for _, row in rx.iterrows():\n",
    "        if pd.notnull(row.get(\"starttime\")):\n",
    "            attrs = {\n",
    "                \"drug\": row.get(\"drug\", None),\n",
    "                \"route\": row.get(\"route\", None),\n",
    "                \"dose_val_rx\": row.get(\"dose_val_rx\", None),\n",
    "                \"dose_unit_rx\": row.get(\"dose_unit_rx\", None),\n",
    "            }\n",
    "            events.append({\n",
    "                \"subject_id\": row[\"subject_id\"],\n",
    "                \"hadm_id\": row[\"hadm_id\"],\n",
    "                \"event_name\": \"ANTI_PLT_ORDER\",\n",
    "                \"timestamp\": row[\"starttime\"],\n",
    "                \"attributes\": _attrs_to_json(attrs),\n",
    "            })\n",
    "            events.append({\n",
    "                \"subject_id\": row[\"subject_id\"],\n",
    "                \"hadm_id\": row[\"hadm_id\"],\n",
    "                \"event_name\": \"ANTI_PLT_ADMIN\",\n",
    "                \"timestamp\": row[\"starttime\"],\n",
    "                \"attributes\": _attrs_to_json(attrs),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. Event Log 통합 + 140 버전 생성\n",
    "# ==============================\n",
    "\n",
    "def build_event_log_140(cohort: pd.DataFrame,\n",
    "                        tables: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    140 버전 event log 생성.\n",
    "\n",
    "    출력 컬럼:\n",
    "      - case_id (hadm_id)\n",
    "      - subject_id\n",
    "      - hadm_id\n",
    "      - event_name\n",
    "      - timestamp\n",
    "      - attributes\n",
    "    \"\"\"\n",
    "    admissions = tables[\"admissions\"]\n",
    "    patients = tables[\"patients\"]\n",
    "    icustays = tables[\"icustays\"]\n",
    "    edstays = tables[\"edstays\"]\n",
    "    labevents_trop = tables[\"labevents_trop\"]\n",
    "    procedures_icd = tables[\"procedures_icd\"]\n",
    "    prescriptions = tables[\"prescriptions\"]\n",
    "    ecg = tables[\"ecg\"]\n",
    "\n",
    "    ed_events = build_ed_events(cohort, edstays, admissions)\n",
    "    adm_events = build_admission_events(cohort, admissions, patients)\n",
    "    icu_events = build_icu_events(cohort, icustays)\n",
    "    trop_events = build_troponin_events(cohort, labevents_trop, TROP_POS_THRESHOLD)\n",
    "    ecg_events = build_ecg_events(cohort, ecg)\n",
    "    pci_events = build_pci_events(\n",
    "        cohort,\n",
    "        procedures_icd,\n",
    "        pci_icd9_prefixes=PCI_ICD9_PREFIXES,\n",
    "        pci_icd10_prefixes=PCI_ICD10_PREFIXES,\n",
    "    )\n",
    "    antiplatelet_events = build_antiplatelet_events(cohort, prescriptions, ANTI_PLT_DRUGS)\n",
    "\n",
    "    all_events = pd.concat(\n",
    "        [\n",
    "            ed_events,\n",
    "            adm_events,\n",
    "            icu_events,\n",
    "            trop_events,\n",
    "            ecg_events,\n",
    "            pci_events,\n",
    "            antiplatelet_events,\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    if all_events.empty:\n",
    "        print(\"[WARN] 생성된 이벤트가 없습니다.\")\n",
    "        return pd.DataFrame(columns=[\"case_id\", \"subject_id\", \"hadm_id\", \"event_name\", \"timestamp\", \"attributes\"])\n",
    "\n",
    "    # timestamp 정리 및 정렬\n",
    "    all_events = all_events.dropna(subset=[\"timestamp\"])\n",
    "    all_events[\"timestamp\"] = pd.to_datetime(all_events[\"timestamp\"], errors=\"coerce\")\n",
    "    all_events = all_events.dropna(subset=[\"timestamp\"])\n",
    "\n",
    "    all_events = all_events.sort_values(\n",
    "        by=[\"subject_id\", \"hadm_id\", \"timestamp\", \"event_name\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # DISCHARGE 또는 DEATH 이후 이벤트 잘라내기\n",
    "    def trim_after_end(df_one_adm: pd.DataFrame) -> pd.DataFrame:\n",
    "        end_idx = df_one_adm[df_one_adm[\"event_name\"].isin([\"DISCHARGE\", \"DEATH\"])].index\n",
    "        if len(end_idx) == 0:\n",
    "            return df_one_adm\n",
    "        cutoff = end_idx.min()\n",
    "        return df_one_adm.loc[:cutoff]\n",
    "\n",
    "    all_events = (\n",
    "        all_events.groupby(\"hadm_id\", group_keys=False)\n",
    "                  .apply(trim_after_end)\n",
    "                  .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # case_id = hadm_id\n",
    "    all_events[\"case_id\"] = all_events[\"hadm_id\"]\n",
    "\n",
    "    # 최종 컬럼 순서\n",
    "    all_events = all_events[\n",
    "        [\"case_id\", \"subject_id\", \"hadm_id\", \"event_name\", \"timestamp\", \"attributes\"]\n",
    "    ]\n",
    "\n",
    "    # 디버깅용 요약\n",
    "    print(\"\\n[SUMMARY] 140 event log 요약\")\n",
    "    print(f\"  전체 이벤트 row 수: {len(all_events)}\")\n",
    "    print(f\"  hadm_id 수: {all_events['hadm_id'].nunique()} / 코호트 hadm_id 수: {len(cohort)}\")\n",
    "    ev_per_hadm = all_events.groupby(\"hadm_id\")[\"event_name\"].count()\n",
    "    print(\"  hadm당 이벤트 개수 통계:\")\n",
    "    print(ev_per_hadm.describe())\n",
    "\n",
    "    return all_events\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 5. MAIN\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    # 1) 코호트 로딩 (각 subject당 첫 STEMI 입원)\n",
    "    cohort = load_cohort_first_stemi_admission(COHORT_PATH)\n",
    "\n",
    "    # 2) 원본 테이블 로딩\n",
    "    tables = load_source_tables()\n",
    "\n",
    "    print(f\"[INFO] 최종 STEMI cohort size (첫 입원 기준): {len(cohort)}\")\n",
    "\n",
    "    # 3) 140 event log 생성\n",
    "    event_log_140 = build_event_log_140(cohort, tables)\n",
    "\n",
    "    # 4) 저장\n",
    "    event_log_140.to_csv(EVENT_LOG_140_PATH, index=False)\n",
    "    print(f\"[SAVE] 140 버전 event log 저장 완료: {EVENT_LOG_140_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2444b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
