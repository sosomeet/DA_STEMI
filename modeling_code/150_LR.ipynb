{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec6adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] 데이터 로딩 완료\n",
      " - shape : (40817, 27)\n",
      "[PREP] race -> race_enc 인코딩 완료\n",
      "[PREP] delay_label 생성 완료 (75% 기준: 168.10)\n",
      "[INFO] 사용 feature 수: 26\n",
      "[INFO] Feature 예시: ['age', 'gender', 'race_enc', 'arrival_transport', 'prefix_len', 'current_event_id', 'time_since_start_min', 'time_since_ed', 'time_since_last', 'is_night']\n",
      "[PREP] 결측 제거 후: (40817, 37)\n",
      "[SPLIT] hadm_id 기준 분할 완료\n",
      " - 전체 hadm_id: 1929\n",
      " - train hadm_id: 1350 , rows: 28412\n",
      " - val   hadm_id: 289 , rows: 5723\n",
      " - test  hadm_id: 290 , rows: 6682\n",
      "[PREP] StandardScaler 적용 완료\n",
      "[TRAIN] Mortality LR 학습\n",
      "[TRAIN] Delay LR 학습\n",
      "[TRAIN] Next-event LR(multinomial) 학습\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Time-to-next LinearRegression 학습 (log1p scale)\n",
      "[TRAIN] Remain LOS LinearRegression 학습 (days)\n",
      "\n",
      "[EVAL] Train\n",
      "  mortality: {'AUC': np.float64(0.7018918255141731), 'AP': np.float64(0.1815052336599004), 'ACC': 0.6424398141630298, 'PREC': 0.13388614553246994, 'REC': 0.6247826086956522, 'F1': 0.22051714877618353}\n",
      "  delay    : {'AUC': np.float64(0.7867874900077182), 'AP': np.float64(0.49911552915024454), 'ACC': 0.702132901590877, 'PREC': 0.444867221561633, 'REC': 0.793552036199095, 'F1': 0.5701224158073855}\n",
      "  next_evt : {'ACC': 0.5457553146557792, 'PREC': 0.26699927086561914, 'REC': 0.23411485462769788, 'F1': 0.20646943772105933}\n",
      "  time_to_next: {'RMSE': np.float64(1196.5561539806702), 'MAE': 354.6302704665939}\n",
      "  remain_los  : {'RMSE': np.float64(1.7727524384644449), 'MAE': 1.2323418173469307}\n",
      "\n",
      "[EVAL] Val\n",
      "  mortality: {'AUC': np.float64(0.5945130709566216), 'AP': np.float64(0.17221669423168534), 'ACC': 0.6192556351563865, 'PREC': 0.12112541726275632, 'REC': 0.43050847457627117, 'F1': 0.1890584294752512}\n",
      "  delay    : {'AUC': np.float64(0.7570849907651085), 'AP': np.float64(0.46673012447635065), 'ACC': 0.6664336886248471, 'PREC': 0.42005813953488375, 'REC': 0.786929884275017, 'F1': 0.5477375029613836}\n",
      "  next_evt : {'ACC': 0.5196575222785252, 'PREC': 0.23003922258100393, 'REC': 0.23105141540580867, 'F1': 0.203206098018949}\n",
      "  time_to_next: {'RMSE': np.float64(1142.2068894001518), 'MAE': 341.0760392444008}\n",
      "  remain_los  : {'RMSE': np.float64(1.8438818942601511), 'MAE': 1.2593818096430425}\n",
      "\n",
      "[EVAL] Test\n",
      "  mortality: {'AUC': np.float64(0.5945712668650436), 'AP': np.float64(0.19047767304018157), 'ACC': 0.6090990721340915, 'PREC': 0.1362088535754824, 'REC': 0.5224963715529753, 'F1': 0.21608643457382953}\n",
      "  delay    : {'AUC': np.float64(0.7896658362683618), 'AP': np.float64(0.5116625663043077), 'ACC': 0.7026339419335528, 'PREC': 0.44581939799331105, 'REC': 0.8015634395670475, 'F1': 0.572963679346658}\n",
      "  next_evt : {'ACC': 0.5474408859622868, 'PREC': 0.28388409346453675, 'REC': 0.2586867157349146, 'F1': 0.22662079187664533}\n",
      "  time_to_next: {'RMSE': np.float64(7.82180512977021e+25), 'MAE': 1.3440810527467307e+24}\n",
      "  remain_los  : {'RMSE': np.float64(2.116117747455073), 'MAE': 1.179398045006862}\n",
      "\n",
      "[FINAL RESULT]\n",
      "{'Train': {'mortality': {'AUC': np.float64(0.7018918255141731), 'AP': np.float64(0.1815052336599004), 'ACC': 0.6424398141630298, 'PREC': 0.13388614553246994, 'REC': 0.6247826086956522, 'F1': 0.22051714877618353}, 'delay': {'AUC': np.float64(0.7867874900077182), 'AP': np.float64(0.49911552915024454), 'ACC': 0.702132901590877, 'PREC': 0.444867221561633, 'REC': 0.793552036199095, 'F1': 0.5701224158073855}, 'next_event': {'ACC': 0.5457553146557792, 'PREC': 0.26699927086561914, 'REC': 0.23411485462769788, 'F1': 0.20646943772105933}, 'time_to_next': {'RMSE': np.float64(1196.5561539806702), 'MAE': 354.6302704665939}, 'remain_los': {'RMSE': np.float64(1.7727524384644449), 'MAE': 1.2323418173469307}}, 'Val': {'mortality': {'AUC': np.float64(0.5945130709566216), 'AP': np.float64(0.17221669423168534), 'ACC': 0.6192556351563865, 'PREC': 0.12112541726275632, 'REC': 0.43050847457627117, 'F1': 0.1890584294752512}, 'delay': {'AUC': np.float64(0.7570849907651085), 'AP': np.float64(0.46673012447635065), 'ACC': 0.6664336886248471, 'PREC': 0.42005813953488375, 'REC': 0.786929884275017, 'F1': 0.5477375029613836}, 'next_event': {'ACC': 0.5196575222785252, 'PREC': 0.23003922258100393, 'REC': 0.23105141540580867, 'F1': 0.203206098018949}, 'time_to_next': {'RMSE': np.float64(1142.2068894001518), 'MAE': 341.0760392444008}, 'remain_los': {'RMSE': np.float64(1.8438818942601511), 'MAE': 1.2593818096430425}}, 'Test': {'mortality': {'AUC': np.float64(0.5945712668650436), 'AP': np.float64(0.19047767304018157), 'ACC': 0.6090990721340915, 'PREC': 0.1362088535754824, 'REC': 0.5224963715529753, 'F1': 0.21608643457382953}, 'delay': {'AUC': np.float64(0.7896658362683618), 'AP': np.float64(0.5116625663043077), 'ACC': 0.7026339419335528, 'PREC': 0.44581939799331105, 'REC': 0.8015634395670475, 'F1': 0.572963679346658}, 'next_event': {'ACC': 0.5474408859622868, 'PREC': 0.28388409346453675, 'REC': 0.2586867157349146, 'F1': 0.22662079187664533}, 'time_to_next': {'RMSE': np.float64(7.82180512977021e+25), 'MAE': 1.3440810527467307e+24}, 'remain_los': {'RMSE': np.float64(2.116117747455073), 'MAE': 1.179398045006862}}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    mean_squared_error, mean_absolute_error\n",
    ")\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA_PATH = \"./../cohort/cohort_ver151_reorder_col.csv\"\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 1. 데이터 로딩\n",
    "# ======================================================\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(\"[LOAD] 데이터 로딩 완료\")\n",
    "print(\" - shape :\", df.shape)\n",
    "\n",
    "required_cols = [\n",
    "    \"hadm_id\",\n",
    "    \"target_mortality\",\n",
    "    \"target_next_evt\",\n",
    "    \"target_time_to_next\",\n",
    "    \"target_remain_los\",\n",
    "]\n",
    "\n",
    "for c in required_cols:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"필수 컬럼 {c} 이(가) 없습니다.\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. 기본 전처리: race 인코딩, delay_label, time_to_next_clip/log1p\n",
    "# ======================================================\n",
    "if \"race\" in df.columns:\n",
    "    le_race = LabelEncoder()\n",
    "    df[\"race_enc\"] = le_race.fit_transform(df[\"race\"].astype(str))\n",
    "    print(\"[PREP] race -> race_enc 인코딩 완료\")\n",
    "else:\n",
    "    print(\"[WARN] race 컬럼 없음, race_enc 사용 불가. 대신 0으로 채웁니다.\")\n",
    "    df[\"race_enc\"] = 0\n",
    "\n",
    "# time_to_next 클리핑 + log1p (LGBM/Transformer와 비슷한 방식)\n",
    "clip_value = df[\"target_time_to_next\"].quantile(0.995)\n",
    "df[\"time_to_next_clip\"] = df[\"target_time_to_next\"].clip(upper=clip_value)\n",
    "df[\"time_to_next_log1p\"] = np.log1p(df[\"time_to_next_clip\"])\n",
    "\n",
    "# delay_label (75% 기준)\n",
    "if \"delay_label\" not in df.columns:\n",
    "    delay_thr = df[\"time_to_next_clip\"].quantile(0.75)\n",
    "    df[\"delay_label\"] = (df[\"time_to_next_clip\"] > delay_thr).astype(int)\n",
    "    print(f\"[PREP] delay_label 생성 완료 (75% 기준: {delay_thr:.2f})\")\n",
    "else:\n",
    "    print(\"[PREP] 기존 delay_label 사용\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3. Feature Engineering (Transformer에서 쓰던 것 재사용)\n",
    "# ======================================================\n",
    "def add_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_fe = df_in.copy()\n",
    "\n",
    "    # HR/BP 비율\n",
    "    if \"current_heart_rate\" in df_fe.columns and \"current_mean_bp\" in df_fe.columns:\n",
    "        df_fe[\"hr_bp_ratio\"] = df_fe[\"current_heart_rate\"] / (df_fe[\"current_mean_bp\"].abs() + 1.0)\n",
    "    else:\n",
    "        df_fe[\"hr_bp_ratio\"] = 0.0\n",
    "\n",
    "    # 마지막 이벤트 시간 / 전체 시간 비율\n",
    "    if \"time_since_last\" in df_fe.columns and \"time_since_start_min\" in df_fe.columns:\n",
    "        df_fe[\"time_last_ratio\"] = df_fe[\"time_since_last\"] / (df_fe[\"time_since_start_min\"].abs() + 1.0)\n",
    "    else:\n",
    "        df_fe[\"time_last_ratio\"] = 0.0\n",
    "\n",
    "    # pathway 진행도\n",
    "    if \"pathway_stage\" in df_fe.columns and \"prefix_len\" in df_fe.columns:\n",
    "        df_fe[\"event_progress\"] = df_fe[\"pathway_stage\"] / (df_fe[\"prefix_len\"] + 1.0)\n",
    "    else:\n",
    "        df_fe[\"event_progress\"] = 0.0\n",
    "\n",
    "    # 글로벌 median 기준 delay 위험\n",
    "    if \"time_since_last\" in df.columns:\n",
    "        global_median = df[\"time_since_last\"].median()\n",
    "        df_fe[\"risk_delay\"] = (df_fe[\"time_since_last\"] > global_median).astype(int)\n",
    "    else:\n",
    "        df_fe[\"risk_delay\"] = 0\n",
    "\n",
    "    # STEMI 누적 위험도\n",
    "    has_stemi = \"stemi_flag\" in df_fe.columns\n",
    "    has_cum_stemi = \"cum_stemi_cnt\" in df_fe.columns\n",
    "    if has_stemi and has_cum_stemi:\n",
    "        df_fe[\"risk_stemi\"] = df_fe[\"stemi_flag\"] * df_fe[\"cum_stemi_cnt\"]\n",
    "    elif has_stemi:\n",
    "        df_fe[\"risk_stemi\"] = df_fe[\"stemi_flag\"]\n",
    "    else:\n",
    "        df_fe[\"risk_stemi\"] = 0\n",
    "\n",
    "    # Troponin 이상 여부\n",
    "    if \"last_trop\" in df_fe.columns:\n",
    "        df_fe[\"trop_abnormal\"] = (df_fe[\"last_trop\"] > 0.04).astype(int)\n",
    "    else:\n",
    "        df_fe[\"trop_abnormal\"] = 0\n",
    "\n",
    "    return df_fe\n",
    "\n",
    "\n",
    "df = add_features(df)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. 사용 Feature 정의\n",
    "# ======================================================\n",
    "candidate_cols = [\n",
    "    \"age\", \"gender\", \"race_enc\",\n",
    "    \"arrival_transport\",\n",
    "    \"prefix_len\", \"current_event_id\",\n",
    "    \"time_since_start_min\", \"time_since_ed\", \"time_since_last\",\n",
    "    \"is_night\",\n",
    "    \"cum_ecg_cnt\", \"cum_trop_cnt\",\n",
    "    \"stemi_flag\", \"trop_pos_flag\",\n",
    "    \"last_trop\", \"run_max_trop\", \"trop_trend\",\n",
    "    \"pci_status\",\n",
    "    \"current_heart_rate\", \"current_mean_bp\",\n",
    "    \"hr_bp_ratio\", \"time_last_ratio\", \"event_progress\",\n",
    "    \"risk_delay\", \"risk_stemi\", \"trop_abnormal\",\n",
    "]\n",
    "\n",
    "feature_cols = [c for c in candidate_cols if c in df.columns]\n",
    "print(\"[INFO] 사용 feature 수:\", len(feature_cols))\n",
    "print(\"[INFO] Feature 예시:\", feature_cols[:10])\n",
    "\n",
    "target_cols = {\n",
    "    \"mortality\": \"target_mortality\",\n",
    "    \"next_event\": \"target_next_evt\",\n",
    "    \"time_to_next\": \"time_to_next_log1p\",   # 회귀는 log1p된 값\n",
    "    \"delay\": \"delay_label\",\n",
    "    \"remain_los\": \"target_remain_los\",\n",
    "}\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 5. 결측행 제거\n",
    "# ======================================================\n",
    "df = df.dropna(subset=feature_cols + list(target_cols.values()))\n",
    "print(\"[PREP] 결측 제거 후:\", df.shape)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 6. hadm_id 기준 Train / Val / Test 분할\n",
    "# ======================================================\n",
    "def split_by_hadm(df_in, random_state=42, train_ratio=0.7, val_ratio=0.15):\n",
    "    if \"hadm_id\" not in df_in.columns:\n",
    "        raise ValueError(\"hadm_id 컬럼이 없습니다.\")\n",
    "\n",
    "    hadm_ids = df_in[\"hadm_id\"].unique()\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    rng.shuffle(hadm_ids)\n",
    "\n",
    "    n = len(hadm_ids)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    hadm_train = hadm_ids[:n_train]\n",
    "    hadm_val   = hadm_ids[n_train:n_train + n_val]\n",
    "    hadm_test  = hadm_ids[n_train + n_val:]\n",
    "\n",
    "    df_train = df_in[df_in[\"hadm_id\"].isin(hadm_train)].copy()\n",
    "    df_val   = df_in[df_in[\"hadm_id\"].isin(hadm_val)].copy()\n",
    "    df_test  = df_in[df_in[\"hadm_id\"].isin(hadm_test)].copy()\n",
    "\n",
    "    print(\"[SPLIT] hadm_id 기준 분할 완료\")\n",
    "    print(\" - 전체 hadm_id:\", n)\n",
    "    print(\" - train hadm_id:\", len(hadm_train), \", rows:\", len(df_train))\n",
    "    print(\" - val   hadm_id:\", len(hadm_val),   \", rows:\", len(df_val))\n",
    "    print(\" - test  hadm_id:\", len(hadm_test),  \", rows:\", len(df_test))\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "df_train, df_val, df_test = split_by_hadm(df, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 7. 스케일링 (StandardScaler)\n",
    "# ======================================================\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[feature_cols])\n",
    "\n",
    "X_train = scaler.transform(df_train[feature_cols])\n",
    "X_val   = scaler.transform(df_val[feature_cols])\n",
    "X_test  = scaler.transform(df_test[feature_cols])\n",
    "\n",
    "y_train = {name: df_train[col].values for name, col in target_cols.items()}\n",
    "y_val   = {name: df_val[col].values   for name, col in target_cols.items()}\n",
    "y_test  = {name: df_test[col].values  for name, col in target_cols.items()}\n",
    "\n",
    "print(\"[PREP] StandardScaler 적용 완료\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 8. 모델 정의 (LR / LinearRegression)\n",
    "# ======================================================\n",
    "mort_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "delay_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# next_event: 멀티클래스 (target_next_evt는 1~K라고 가정)\n",
    "next_event_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "time_to_next_model = LinearRegression()\n",
    "remain_los_model   = LinearRegression()\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 9. 학습\n",
    "# ======================================================\n",
    "print(\"[TRAIN] Mortality LR 학습\")\n",
    "mort_model.fit(X_train, y_train[\"mortality\"])\n",
    "\n",
    "print(\"[TRAIN] Delay LR 학습\")\n",
    "delay_model.fit(X_train, y_train[\"delay\"])\n",
    "\n",
    "print(\"[TRAIN] Next-event LR(multinomial) 학습\")\n",
    "next_event_model.fit(X_train, y_train[\"next_event\"])\n",
    "\n",
    "print(\"[TRAIN] Time-to-next LinearRegression 학습 (log1p scale)\")\n",
    "time_to_next_model.fit(X_train, y_train[\"time_to_next\"])\n",
    "\n",
    "print(\"[TRAIN] Remain LOS LinearRegression 학습 (days)\")\n",
    "remain_los_model.fit(X_train, y_train[\"remain_los\"])\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 10. 평가 함수\n",
    "# ======================================================\n",
    "def eval_binary(model, X, y_true, name=\"\"):\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # AUC는 y에 0/1 두 클래스가 모두 있을 때만 계산\n",
    "    if len(np.unique(y_true)) > 1:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "\n",
    "    ap   = average_precision_score(y_true, y_prob)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    return dict(AUC=auc, AP=ap, ACC=acc, PREC=prec, REC=rec, F1=f1)\n",
    "\n",
    "\n",
    "def eval_multiclass(model, X, y_true, name=\"\"):\n",
    "    y_pred = model.predict(X)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    return dict(ACC=acc, PREC=prec, REC=rec, F1=f1)\n",
    "\n",
    "\n",
    "def eval_reg_time_to_next(model, X, y_log1p_true, name=\"\"):\n",
    "    # y_log1p_true: log1p(time_to_next_clip)\n",
    "    y_log1p_pred = model.predict(X)\n",
    "    # 분 단위로 복원\n",
    "    y_true = np.expm1(y_log1p_true)\n",
    "    y_pred = np.expm1(y_log1p_pred)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    return dict(RMSE=rmse, MAE=mae)\n",
    "\n",
    "\n",
    "def eval_reg_simple(model, X, y_true, name=\"\"):\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    return dict(RMSE=rmse, MAE=mae)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 11. Train / Val / Test 평가\n",
    "# ======================================================\n",
    "results = {\n",
    "    \"Train\": {},\n",
    "    \"Val\": {},\n",
    "    \"Test\": {},\n",
    "}\n",
    "\n",
    "for split_name, X, y in [\n",
    "    (\"Train\", X_train, y_train),\n",
    "    (\"Val\",   X_val,   y_val),\n",
    "    (\"Test\",  X_test,  y_test),\n",
    "]:\n",
    "    res_split = {}\n",
    "    print(f\"\\n[EVAL] {split_name}\")\n",
    "\n",
    "    # (1) 사망\n",
    "    res_split[\"mortality\"] = eval_binary(mort_model, X, y[\"mortality\"], name=\"mortality\")\n",
    "    print(\"  mortality:\", res_split[\"mortality\"])\n",
    "\n",
    "    # (2) 지연\n",
    "    res_split[\"delay\"] = eval_binary(delay_model, X, y[\"delay\"], name=\"delay\")\n",
    "    print(\"  delay    :\", res_split[\"delay\"])\n",
    "\n",
    "    # (3) 다음 이벤트 종류\n",
    "    res_split[\"next_event\"] = eval_multiclass(next_event_model, X, y[\"next_event\"], name=\"next_event\")\n",
    "    print(\"  next_evt :\", res_split[\"next_event\"])\n",
    "\n",
    "    # (4) 다음 이벤트까지 시간 (time_to_next_log1p → 분 단위 복원 후 RMSE/MAE)\n",
    "    res_split[\"time_to_next\"] = eval_reg_time_to_next(\n",
    "        time_to_next_model, X, y[\"time_to_next\"], name=\"time_to_next\"\n",
    "    )\n",
    "    print(\"  time_to_next:\", res_split[\"time_to_next\"])\n",
    "\n",
    "    # (5) 남은 입원 기간 (remain_los, days)\n",
    "    res_split[\"remain_los\"] = eval_reg_simple(\n",
    "        remain_los_model, X, y[\"remain_los\"], name=\"remain_los\"\n",
    "    )\n",
    "    print(\"  remain_los  :\", res_split[\"remain_los\"])\n",
    "\n",
    "    results[split_name] = res_split\n",
    "\n",
    "print(\"\\n[FINAL RESULT]\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83ffef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
