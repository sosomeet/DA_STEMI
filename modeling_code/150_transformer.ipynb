{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15670f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] 데이터 로딩 완료\n",
      " - shape : (40817, 27)\n",
      "[PREP] race -> race_enc 인코딩 완료\n",
      "[PREP] time_to_next_clip 상한(99.5%): 9920.20\n",
      "[PREP] delay_threshold(75%): 168.10\n",
      "[PREP] delay_label 분포:\n",
      "delay_label\n",
      "0    0.750006\n",
      "1    0.249994\n",
      "Name: ratio, dtype: float64\n",
      "[INFO] 사용 feature 수: 20\n",
      "[INFO] Feature columns 예시: ['age', 'gender', 'arrival_transport', 'prefix_len', 'current_event_id', 'time_since_start_min', 'time_since_ed', 'time_since_last', 'is_night', 'cum_ecg_cnt', 'cum_trop_cnt', 'stemi_flag', 'trop_pos_flag', 'last_trop', 'run_max_trop', 'trop_trend', 'pci_status', 'current_heart_rate', 'current_mean_bp', 'race_enc']\n",
      "[SPLIT] hadm_id 기준 분할 완료\n",
      " - 전체 hadm_id: 1929\n",
      " - train hadm_id: 1350 , rows: 28412\n",
      " - val   hadm_id: 289 , rows: 5723\n",
      " - test  hadm_id: 290 , rows: 6682\n",
      "\n",
      "[TRAIN] Binary 모델 학습 시작: Mortality\n",
      "[EVAL-Mortality] AUC=0.5381, AP=0.1291, ACC=0.8835, F1=0.0800\n",
      "\n",
      "[TRAIN] Multiclass 모델 학습 시작: NextEvent (num_class=14)\n",
      "[EVAL-NextEvent] ACC=0.5843, Macro-F1=0.3849\n",
      "\n",
      "[TRAIN] Regression 모델 학습 시작: TimeToNext_log1p\n",
      "[EVAL-TimeToNext_log1p] RMSE=1.6341, MAE=1.1166\n",
      "\n",
      "[TRAIN] Regression 모델 학습 시작: RemainLOS\n",
      "[EVAL-RemainLOS] RMSE=1.1436, MAE=0.8222\n",
      "\n",
      "[TRAIN] Binary 모델 학습 시작: DelayRisk\n",
      "[EVAL-DelayRisk] AUC=0.9036, AP=0.7238, ACC=0.8394, F1=0.6934\n",
      "\n",
      "[INFO] 모든 모델 학습 완료\n",
      "\n",
      "[INFO] Test 예측 및 CSV 저장 시작\n",
      "[SAVE] Test 예측 결과 CSV 저장 완료: ./ppm_pred_results_test.csv\n",
      "   subject_id   hadm_id        timestamp  mortality_true  \\\n",
      "0    19836972  20014283  2158-02-13 2:15               0   \n",
      "1    19836972  20014283  2158-02-13 2:20               0   \n",
      "2    19836972  20014283  2158-02-13 2:20               0   \n",
      "3    19836972  20014283  2158-02-13 2:31               0   \n",
      "4    19836972  20014283  2158-02-13 2:31               0   \n",
      "\n",
      "   mortality_pred_proba  next_evt_true  next_evt_pred  ttn_log1p_true  \\\n",
      "0              0.153979              2              3        1.791759   \n",
      "1              0.032441              3              3        0.000000   \n",
      "2              0.025708              2              3        2.484907   \n",
      "3              0.063977              3              3        0.000000   \n",
      "4              0.101775              3              3        1.386294   \n",
      "\n",
      "   ttn_log1p_pred  ttn_minutes_pred  remain_los_true  remain_los_pred  \\\n",
      "0        2.345275          9.436146         9.876681         8.828354   \n",
      "1       -0.213265         -0.192058         9.876425         8.437071   \n",
      "2        1.746982          4.737263         9.876425         8.449415   \n",
      "3       -0.539910         -0.417199         9.875859         8.415306   \n",
      "4        1.117518          2.057256         9.875859         8.576431   \n",
      "\n",
      "   delay_true  delay_pred_label  delay_pred_proba  \n",
      "0           0                 0          0.012875  \n",
      "1           0                 0          0.000629  \n",
      "2           0                 0          0.007484  \n",
      "3           0                 0          0.000994  \n",
      "4           0                 0          0.028866  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    accuracy_score, f1_score,\n",
    "    precision_score, recall_score,\n",
    "    mean_squared_error, mean_absolute_error\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ================================\n",
    "# 0. 설정\n",
    "# ================================\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA_PATH = \"./cohort_ver151_reorder_col.csv\"   # 필요시 수정\n",
    "OUT_PATH  = \"./ppm_pred_results_test.csv\"       # Test 예측 결과 CSV 경로\n",
    "\n",
    "# ================================\n",
    "# 1. 데이터 로딩\n",
    "# ================================\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(\"[LOAD] 데이터 로딩 완료\")\n",
    "print(\" - shape :\", df.shape)\n",
    "\n",
    "# ================================\n",
    "# 2. 전처리\n",
    "#    - race 인코딩\n",
    "#    - time_to_next clip / log1p\n",
    "#    - delay_label 생성\n",
    "# ================================\n",
    "\n",
    "# (1) race 라벨 인코딩\n",
    "if \"race\" in df.columns:\n",
    "    le_race = LabelEncoder()\n",
    "    df[\"race_enc\"] = le_race.fit_transform(df[\"race\"].astype(str))\n",
    "    print(\"[PREP] race -> race_enc 인코딩 완료\")\n",
    "else:\n",
    "    print(\"[WARN] race 컬럼이 없어 race_enc를 만들지 않았습니다.\")\n",
    "\n",
    "# (2) time_to_next clip + log1p\n",
    "if \"target_time_to_next\" not in df.columns:\n",
    "    raise ValueError(\"target_time_to_next 컬럼이 없습니다. cohort를 확인해 주세요.\")\n",
    "\n",
    "clip_value = df[\"target_time_to_next\"].quantile(0.995)\n",
    "df[\"time_to_next_clip\"] = df[\"target_time_to_next\"].clip(upper=clip_value)\n",
    "df[\"time_to_next_log1p\"] = np.log1p(df[\"time_to_next_clip\"])\n",
    "\n",
    "# (3) delay_label 생성 (상위 25% 이상을 지연으로 정의)\n",
    "delay_threshold = df[\"time_to_next_clip\"].quantile(0.75)\n",
    "df[\"delay_label\"] = (df[\"time_to_next_clip\"] > delay_threshold).astype(int)\n",
    "\n",
    "print(f\"[PREP] time_to_next_clip 상한(99.5%): {clip_value:.2f}\")\n",
    "print(f\"[PREP] delay_threshold(75%): {delay_threshold:.2f}\")\n",
    "print(\"[PREP] delay_label 분포:\")\n",
    "print(df[\"delay_label\"].value_counts(normalize=True).rename(\"ratio\"))\n",
    "\n",
    "# ================================\n",
    "# 3. Feature / Target 정의\n",
    "# ================================\n",
    "\n",
    "# ID 컬럼\n",
    "id_cols = [c for c in [\"subject_id\", \"hadm_id\", \"timestamp\"] if c in df.columns]\n",
    "\n",
    "# Target 컬럼 존재 여부 확인\n",
    "required_targets = [\n",
    "    \"target_mortality\",\n",
    "    \"target_next_evt\",\n",
    "    \"target_time_to_next\",\n",
    "    \"target_remain_los\",\n",
    "]\n",
    "for t in required_targets:\n",
    "    if t not in df.columns:\n",
    "        raise ValueError(f\"{t} 컬럼이 없습니다. cohort를 확인해 주세요.\")\n",
    "\n",
    "target_cols = required_targets + [\"delay_label\"]\n",
    "\n",
    "# feature에서 제외할 컬럼\n",
    "exclude_cols = set(id_cols + target_cols + [\n",
    "    \"race\",                 # 문자열 원본\n",
    "    \"time_to_next_clip\",\n",
    "    \"time_to_next_log1p\",\n",
    "])\n",
    "\n",
    "# 기본 feature: object 타입이 아닌 컬럼 중 exclude_cols에 없는 것\n",
    "feature_cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in exclude_cols and df[c].dtype != \"object\"\n",
    "]\n",
    "\n",
    "# race_enc가 있다면 feature에 포함\n",
    "if \"race_enc\" in df.columns and \"race_enc\" not in feature_cols:\n",
    "    feature_cols.append(\"race_enc\")\n",
    "\n",
    "print(\"[INFO] 사용 feature 수:\", len(feature_cols))\n",
    "print(\"[INFO] Feature columns 예시:\", feature_cols[:20])\n",
    "\n",
    "# ================================\n",
    "# 4. hadm_id 기준 Train / Val / Test 분할\n",
    "# ================================\n",
    "def split_by_hadm(df, random_state=42, train_ratio=0.7, val_ratio=0.15):\n",
    "    if \"hadm_id\" not in df.columns:\n",
    "        raise ValueError(\"hadm_id 컬럼이 없습니다. split이 불가능합니다.\")\n",
    "\n",
    "    hadm_ids = df[\"hadm_id\"].unique()\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    rng.shuffle(hadm_ids)\n",
    "\n",
    "    n = len(hadm_ids)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    hadm_train = hadm_ids[:n_train]\n",
    "    hadm_val   = hadm_ids[n_train:n_train + n_val]\n",
    "    hadm_test  = hadm_ids[n_train + n_val:]\n",
    "\n",
    "    df_train = df[df[\"hadm_id\"].isin(hadm_train)].copy()\n",
    "    df_val   = df[df[\"hadm_id\"].isin(hadm_val)].copy()\n",
    "    df_test  = df[df[\"hadm_id\"].isin(hadm_test)].copy()\n",
    "\n",
    "    print(\"[SPLIT] hadm_id 기준 분할 완료\")\n",
    "    print(\" - 전체 hadm_id:\", n)\n",
    "    print(\" - train hadm_id:\", len(hadm_train), \", rows:\", len(df_train))\n",
    "    print(\" - val   hadm_id:\", len(hadm_val),   \", rows:\", len(df_val))\n",
    "    print(\" - test  hadm_id:\", len(hadm_test),  \", rows:\", len(df_test))\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df_train, df_val, df_test = split_by_hadm(df, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "X_val   = df_val[feature_cols]\n",
    "X_test  = df_test[feature_cols]\n",
    "\n",
    "# ================================\n",
    "# 5. LightGBM 학습 함수 (early stopping 없음)\n",
    "# ================================\n",
    "def train_lgbm_binary(X_tr, y_tr, X_va, y_va, model_name, num_boost_round=800):\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data   = lgb.Dataset(X_va, label=y_va)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": [\"auc\", \"binary_logloss\"],\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"num_leaves\": 63,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"max_depth\": -1,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"lambda_l2\": 1.0,\n",
    "        \"verbose\": -1,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n[TRAIN] Binary 모델 학습 시작: {model_name}\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=[\"valid\"]\n",
    "    )\n",
    "\n",
    "    y_pred_proba = model.predict(X_va)\n",
    "    y_pred_label = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    auc  = roc_auc_score(y_va, y_pred_proba)\n",
    "    ap   = average_precision_score(y_va, y_pred_proba)\n",
    "    acc  = accuracy_score(y_va, y_pred_label)\n",
    "    f1   = f1_score(y_va, y_pred_label)\n",
    "    prec = precision_score(y_va, y_pred_label)\n",
    "    rec  = recall_score(y_va, y_pred_label)\n",
    "\n",
    "    print(f\"[EVAL-{model_name}]\")\n",
    "    print(f\"  AUC       : {auc:.4f}\")\n",
    "    print(f\"  AP        : {ap:.4f}\")\n",
    "    print(f\"  Accuracy  : {acc:.4f}\")\n",
    "    print(f\"  Precision : {prec:.4f}\")\n",
    "    print(f\"  Recall    : {rec:.4f}\")\n",
    "    print(f\"  F1-score  : {f1:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lgbm_multiclass(X_tr, y_tr, X_va, y_va, model_name, num_boost_round=800):\n",
    "    num_class = len(np.unique(y_tr))\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data   = lgb.Dataset(X_va, label=y_va)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": num_class,\n",
    "        \"metric\": [\"multi_logloss\"],\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 63,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"max_depth\": -1,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"lambda_l2\": 1.0,\n",
    "        \"verbose\": -1,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n[TRAIN] Multiclass 모델 학습 시작: {model_name} (num_class={num_class})\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=[\"valid\"]\n",
    "    )\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_va), axis=1)\n",
    "    acc = accuracy_score(y_va, y_pred)\n",
    "    macro_f1   = f1_score(y_va, y_pred, average=\"macro\")\n",
    "    macro_prec = precision_score(y_va, y_pred, average=\"macro\")\n",
    "    macro_rec  = recall_score(y_va, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"[EVAL-{model_name}]\")\n",
    "    print(f\"  Accuracy        : {acc:.4f}\")\n",
    "    print(f\"  Macro Precision : {macro_prec:.4f}\")\n",
    "    print(f\"  Macro Recall    : {macro_rec:.4f}\")\n",
    "    print(f\"  Macro F1-score  : {macro_f1:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lgbm_regression(X_tr, y_tr, X_va, y_va, model_name, num_boost_round=800):\n",
    "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data   = lgb.Dataset(X_va, label=y_va)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": [\"rmse\", \"l1\"],\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 63,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"max_depth\": -1,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"lambda_l2\": 1.0,\n",
    "        \"verbose\": -1,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n[TRAIN] Regression 모델 학습 시작: {model_name}\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=[\"valid\"]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_va)\n",
    "\n",
    "    mse  = mean_squared_error(y_va, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_va, y_pred)\n",
    "\n",
    "    print(f\"[EVAL-{model_name}]\")\n",
    "    print(f\"  RMSE : {rmse:.4f}\")\n",
    "    print(f\"  MAE  : {mae:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# 6. 태스크별 모델 학습\n",
    "# ================================\n",
    "\n",
    "# (1) 사망 확률 (binary)\n",
    "y_train_mort = df_train[\"target_mortality\"].values\n",
    "y_val_mort   = df_val[\"target_mortality\"].values\n",
    "y_test_mort  = df_test[\"target_mortality\"].values\n",
    "\n",
    "model_mort = train_lgbm_binary(\n",
    "    X_train, y_train_mort,\n",
    "    X_val, y_val_mort,\n",
    "    model_name=\"Mortality\"\n",
    ")\n",
    "\n",
    "# (2) 다음 event (multiclass, 1~K -> 0~K-1로 shift)\n",
    "y_train_next = df_train[\"target_next_evt\"].values - 1\n",
    "y_val_next   = df_val[\"target_next_evt\"].values - 1\n",
    "y_test_next  = df_test[\"target_next_evt\"].values - 1\n",
    "\n",
    "model_next = train_lgbm_multiclass(\n",
    "    X_train, y_train_next,\n",
    "    X_val, y_val_next,\n",
    "    model_name=\"NextEvent\"\n",
    ")\n",
    "\n",
    "# (3) 다음 event까지 걸리는 시간 (log1p(time_to_next_clip), regression)\n",
    "y_train_ttn = df_train[\"time_to_next_log1p\"].values\n",
    "y_val_ttn   = df_val[\"time_to_next_log1p\"].values\n",
    "y_test_ttn  = df_test[\"time_to_next_log1p\"].values\n",
    "\n",
    "model_ttn = train_lgbm_regression(\n",
    "    X_train, y_train_ttn,\n",
    "    X_val, y_val_ttn,\n",
    "    model_name=\"TimeToNext_log1p\"\n",
    ")\n",
    "\n",
    "# (4) 남은 입원 기간 (remain LOS, regression)\n",
    "y_train_los = df_train[\"target_remain_los\"].values\n",
    "y_val_los   = df_val[\"target_remain_los\"].values\n",
    "y_test_los  = df_test[\"target_remain_los\"].values\n",
    "\n",
    "model_los = train_lgbm_regression(\n",
    "    X_train, y_train_los,\n",
    "    X_val, y_val_los,\n",
    "    model_name=\"RemainLOS\"\n",
    ")\n",
    "\n",
    "# (5) 지연 여부 (delay_label, binary)\n",
    "y_train_delay = df_train[\"delay_label\"].values\n",
    "y_val_delay   = df_val[\"delay_label\"].values\n",
    "y_test_delay  = df_test[\"delay_label\"].values\n",
    "\n",
    "model_delay = train_lgbm_binary(\n",
    "    X_train, y_train_delay,\n",
    "    X_val, y_val_delay,\n",
    "    model_name=\"DelayRisk\"\n",
    ")\n",
    "\n",
    "print(\"\\n[INFO] 모든 모델 학습 완료\")\n",
    "\n",
    "# ================================\n",
    "# 7. 공통 Test 평가 함수\n",
    "# ================================\n",
    "def evaluate_binary(model, X, y, name=\"Binary-Test\"):\n",
    "    pred_proba = model.predict(X)\n",
    "    pred = (pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    auc  = roc_auc_score(y, pred_proba)\n",
    "    ap   = average_precision_score(y, pred_proba)\n",
    "    acc  = accuracy_score(y, pred)\n",
    "    f1   = f1_score(y, pred)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec  = recall_score(y, pred)\n",
    "\n",
    "    print(f\"\\n=== {name} (Binary) ===\")\n",
    "    print(f\"AUC        : {auc:.4f}\")\n",
    "    print(f\"AP         : {ap:.4f}\")\n",
    "    print(f\"Accuracy   : {acc:.4f}\")\n",
    "    print(f\"Precision  : {prec:.4f}\")\n",
    "    print(f\"Recall     : {rec:.4f}\")\n",
    "    print(f\"F1-score   : {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"AUC\": auc,\n",
    "        \"AP\": ap,\n",
    "        \"ACC\": acc,\n",
    "        \"PREC\": prec,\n",
    "        \"REC\": rec,\n",
    "        \"F1\": f1\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_multiclass(model, X, y, name=\"Multiclass-Test\"):\n",
    "    proba = model.predict(X)\n",
    "    pred  = np.argmax(proba, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y, pred)\n",
    "    macro_f1   = f1_score(y, pred, average=\"macro\")\n",
    "    macro_prec = precision_score(y, pred, average=\"macro\")\n",
    "    macro_rec  = recall_score(y, pred, average=\"macro\")\n",
    "\n",
    "    print(f\"\\n=== {name} (Multiclass) ===\")\n",
    "    print(f\"Accuracy         : {acc:.4f}\")\n",
    "    print(f\"Macro Precision  : {macro_prec:.4f}\")\n",
    "    print(f\"Macro Recall     : {macro_rec:.4f}\")\n",
    "    print(f\"Macro F1-score   : {macro_f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"ACC\": acc,\n",
    "        \"PREC\": macro_prec,\n",
    "        \"REC\": macro_rec,\n",
    "        \"F1\": macro_f1\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_regression(model, X, y, name=\"Regression-Test\"):\n",
    "    pred = model.predict(X)\n",
    "\n",
    "    mse  = mean_squared_error(y, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y, pred)\n",
    "\n",
    "    print(f\"\\n=== {name} (Regression) ===\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae\n",
    "    }\n",
    "\n",
    "# ================================\n",
    "# 8. Test 평가\n",
    "# ================================\n",
    "print(\"\\n[INFO] Test 셋 평가 시작\")\n",
    "\n",
    "# Binary\n",
    "evaluate_binary(model_mort,  X_test, y_test_mort,  name=\"Mortality-Test\")\n",
    "evaluate_binary(model_delay, X_test, y_test_delay, name=\"DelayRisk-Test\")\n",
    "\n",
    "# Multiclass\n",
    "evaluate_multiclass(model_next, X_test, y_test_next, name=\"NextEvent-Test\")\n",
    "\n",
    "# Regression\n",
    "evaluate_regression(model_ttn, X_test, y_test_ttn, name=\"TimeToNext_log1p-Test\")\n",
    "evaluate_regression(model_los, X_test, y_test_los, name=\"RemainLOS-Test\")\n",
    "\n",
    "# ================================\n",
    "# 9. Test 예측 및 CSV 저장\n",
    "# ================================\n",
    "print(\"\\n[INFO] Test 예측 및 CSV 저장 시작\")\n",
    "\n",
    "# Mortality\n",
    "test_pred_mort_proba = model_mort.predict(X_test)\n",
    "\n",
    "# Next event\n",
    "test_pred_next_proba = model_next.predict(X_test)\n",
    "test_pred_next_label = np.argmax(test_pred_next_proba, axis=1) + 1  # 다시 1~K로 복원\n",
    "\n",
    "# Time to next\n",
    "test_pred_ttn_log1p = model_ttn.predict(X_test)\n",
    "test_pred_ttn_real  = np.expm1(test_pred_ttn_log1p)\n",
    "\n",
    "# Remain LOS\n",
    "test_pred_los = model_los.predict(X_test)\n",
    "\n",
    "# Delay\n",
    "test_pred_delay_proba = model_delay.predict(X_test)\n",
    "test_pred_delay_label = (test_pred_delay_proba >= 0.5).astype(int)\n",
    "\n",
    "# 결과 DataFrame 구성\n",
    "result_dict = {\n",
    "    \"subject_id\": df_test[\"subject_id\"].values,\n",
    "    \"hadm_id\": df_test[\"hadm_id\"].values,\n",
    "}\n",
    "if \"timestamp\" in df_test.columns:\n",
    "    result_dict[\"timestamp\"] = df_test[\"timestamp\"].values\n",
    "\n",
    "result_dict.update({\n",
    "    \"mortality_true\": df_test[\"target_mortality\"].values,\n",
    "    \"mortality_pred_proba\": test_pred_mort_proba,\n",
    "\n",
    "    \"next_evt_true\": df_test[\"target_next_evt\"].values,\n",
    "    \"next_evt_pred\": test_pred_next_label,\n",
    "\n",
    "    \"ttn_log1p_true\": df_test[\"time_to_next_log1p\"].values,\n",
    "    \"ttn_log1p_pred\": test_pred_ttn_log1p,\n",
    "    \"ttn_minutes_pred\": test_pred_ttn_real,\n",
    "\n",
    "    \"remain_los_true\": df_test[\"target_remain_los\"].values,\n",
    "    \"remain_los_pred\": test_pred_los,\n",
    "\n",
    "    \"delay_true\": df_test[\"delay_label\"].values,\n",
    "    \"delay_pred_label\": test_pred_delay_label,\n",
    "    \"delay_pred_proba\": test_pred_delay_proba,\n",
    "})\n",
    "\n",
    "df_result = pd.DataFrame(result_dict)\n",
    "df_result.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(f\"[SAVE] Test 예측 결과 CSV 저장 완료: {OUT_PATH}\")\n",
    "print(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1508dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f71c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
